To assess the hypothesis that mass engagement affects the engagement of
political principals, I examine the relationship between mass commenting
and the behavior of Members of Congress, while attempting to control for
other reasons that Members of Congress may comment on a proposed rule.
The bold arrow in figure
[\[fig:causal-principals-test\]](#fig:causal-principals-test){reference-type="ref"
reference="fig:causal-principals-test"} indicates the key relationship
that I test in this step. I aim to test the relationship between mass
public engagement and engagement from Members of Congress, who may
receive information about public opinion from mass engagement.

I measure the dependent variables, legislator attention and support,
several ways. First, I count the number of times Members of Congress
engage the agency across rules and before, during, and after comment
periods on rules where lobbying organizations did and did not go public.
By engaging the agency, I mean that Members of Congress raise a rule in
personal correspondence or comments that members send to the agency. I
then code each contact from the member of congress and each coalition
lobbying on the rule on the same three-point scale: are they asking for
the rule to go further, be scaled back, or published as is. This is
similar to other hand-coding approaches to policy demands. Next, I use
text analysis to compare the sentiment and rhetoric (phrases and word
frequencies) used by legislators to that used by each coalition.

### Models testing the relationship between mass engagement and oversight

There are several ways to test for a relationship between mass
engagement and engagement by Members of Congress. The key explanatory
variables of interest are the measures of mass engagement created in
step 1 (how many and what types of comments). For simplicity, in the
equations below, I only include measures related to the number of
comments. Thus $\beta_0$ is the estimate for a rule with no public
comments.

In Model 1, the dependent variable is the total number of comments from
Members of Congress on the rule: *$Y$ = Total comments from Congress*
$\sim$ zero-inflated negative binomial, with one observation per rule.
Let $x$ be the the total number of public comments.

$$\begin{aligned}
    Y \sim \beta_0 + \beta_1x\end{aligned}$$

In Model 2, the dependent variable is the number of comments from
Members of Congress on the rule that support the coalition or
organizations in the coalition: $Y_i$ = *Total comments from Congress
supporting coalition $i$* $\sim$ negative binomial, with one observation
per coalition per rule. Let $x_i$ be the total number of public comments
supporting coalition $i$.

$$\begin{aligned}
    Y_i \sim \beta_0 + \beta_1 x_i\end{aligned}$$

In Model 3, the dependent variable is the share of Congressional
comments supporting the coalition: $Y_i$ = *Share of Members of Congress
supporting coalition $i$* $\sim$ beta, with one observation per
coalition per rule. Let $z_i$ be the *share* of public comments
supporting coalition $i$.

$$\begin{aligned}
    Y_i \sim \beta_0 + \beta_1 z_i\end{aligned}$$

In Model 4, the dependent variable is rhetorical similarity between
comments of each coalition $i$ and each Members of Congress $j$:
$Y_{ij}$ = *Text similarity score between legislator comment and
coalition $i$ texts*, with one observation per legislator comment per
coalition. Let $z_i$ be the share of public comments supporting
coalition $i$.

$$\begin{aligned}
    Y_{ij} ~ \sim \beta_0 + \beta_1 z_i\end{aligned}$$

#### Limitations.

One challenge will be controlling for rule salience, which may affect
both public and legislator attention (indeed, both are endogenous to
rule salience). Another challenge will be controlling for latent public
opinion, which may usually, but not exclusively, be revealed to
legislators through mass engagement.
