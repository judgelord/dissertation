[["index.html", "Public Pressure Campaigns and Bureaucratic Policymaking Introduction Motivation Outline of the book", " Public Pressure Campaigns and Bureaucratic Policymaking Devin Judge-Lord 2021-04-15 Introduction Does civic engagement through public pressure campaigns affect agency rulemaking? I examine who participates in public pressure campaigns and why, whether they affect congressional oversight, and whether they affect policy. Answering these questions informs our understanding of bureaucratic politics and interest group lobbying, organizing, and mobilizing tactics. If ordinary people have a voice in bureaucratic policymaking, I argue, it is through public pressure campaings. Thus, understnding the nature and effects of these campaigns is key to understanding modern democracy. Large democracies face two big problems. First, they are vulnerable to fleeting passions and demagogues. To combat this, many decisions are left to experts who, ideally, exercise judgment loosely guided by the public. Second, everyone cannot vote on every decision. We thus delegate power to representatives (who then delegate it to deputies), create temporary mini-publics, or solicit input from those most affected or moved by a public decision.1 Most policy is then made by bureaucrats, supposedly guided indirectly through elected representatives and directly by limited public input. Of the thousand of policies that the institutoins of government make each year, direct public input tends to be limited to only the very most contentious policy debates. Both of these problems converge in the bureaucracy. Bureacracies are run by experts who are deputized by elected officials (or by their deputy’s deputy’s deputy). Many bureacracies also have procedures that create opportunities for public input, and it is far from clear how bureaucratic decisions are to balance expertise, accountability to elected officials, and responsiveness to public input in decisionmaking. With the rise of the administrative state, U.S. federal agencies have become a major site of policymaking and political conflict. By some estimates, upward of 90% of legally binding U.S. federal policy is now written by agencies. Agency rules are revised much more frequently than statutory law (Wagner et al. 2017). In the years or decades between legislative enactments, federal agencies make legally-binding rules interpreting and reinterpreting old statutes to address emerging issues and priorities. Examples are striking: Many effects of the Dodd-Frank Wall Street Reform and Consumer Protection Act were largely unknown until the specific regulations were written, and it continues to change as these rules are revised. Congress authorizes billions in grants, subsidies, and leases for public lands, but who gets them depends on agency policy. In the decades since the last major environmental legislation, agencies have written thousands of pages of new environmental regulations and thousands more changing tack under each new administration. These revisions significantly shape lives and fortunes. For example, in 2006, citing the authority of statutes last amended in the 1950s, the Justice Department’s Bureau of Prisons proposed a rule restricting eligibility for parole. In 2016, the Bureau withdrew this rule and announced it would require fewer contracts with prison companies, precipitating a 50% loss of industry stock value. Six months later, a new administration announced these policies would again be reversed, leading to a 130% increase in industry stock value. Agency rulemaking matters. Less clear, however, is how the new centrality of agency rulemaking fits with democracy. In addition to the bureaucracy’s complex relationships with the president and Congress, agencies have complex and poorly understood relationships with the public and advocacy groups. Relationships with constituent groups may even provide agencies with a degree of “autonomy” from their official principals (Carpenter 2001). Participatory processes like public comment periods, where government agencies must solicit public input on draft policies, are said to provide political oversight opportunities (Balla 1998; Mccubbins and Schwartz 1984), democratic legitimacy (Croley 2003; Rosenbloom 2003), and new technical information (S. W. Yackee 2006; Nelson and Yackee 2012). While recent scholarship on agency policymaking has shed light on the sophisticated lobbying by businesses and political insiders, we know surprisingly little about the vast majority of public comments which are submitted by ordinary people as part of public pressure campaigns.2 Activists frequently target agency policymaking with letter-writing campaigns, petitions, protests, and mobilizing people to attend hearings, all classic examples of “civic engagement” (Verba and Nie 1987). Yet civic engagement remains poorly understood in the context of bureaucratic policymaking. These occasional bursts of civic engagement in bureaucratic policymaking raise practical and theoretical questions for the practice of democracy.3 These questions, in turn, hinge on unanswered empirical questions: Do these campaigns affect policy? If so, by what mechanisms? Existing research finds that commenters believe their comments matter (Yackee 2015) and that the number of public comments varies across agencies and policy processes (Judge-Lord 2019a; Libgober 2018; Moore 2017), but the relationship between the scale of public engagement and policy change remains untested. Motivation Leading models of influence in bureaucratic policymaking focus on two key political forces: sophisticated interest group lobbying and political oversight. As bureaucrats learn about policy problems and balance interest-group demands, public comment processes allow lobbying organizations to provide useful technical information and inform decisionmakers of their preferences on draft policies. Agencies may then update policy positions within constraints imposed by their political principals. While this may describe most cases of bureaucratic policymaking, these models do not explain or account for the contentious politics that occasionally inspire millions of ordinary people to respond to calls for public input on draft agency policies. Mass engagement in bureaucratic policymaking has thus largely been ignored by political scientists, leaving a weak empirical base for normative and prescriptive work. Like other forms of mass political participation, such as protests and letter writing campaigns, mass public comments on draft agency rules provide no new technical information. Nor do they wield any formal authority to reward or sanction bureaucrats, as comments from a Members of Congress might. The number on each side, be it ten or ten million, has no legal import for an agency’s response. How, if at all, should scholars incorporate mass engagement into models of bureaucratic policymaking? In contrast to political scientists, legal scholars have long debated what to make of mass commenting in rulemaking. Many focus on reforms to help agencies collect more useful information (Farina et al. 2011; Farina, Newhart, and Heidt 2014; Rauch 2016). In 2018, “Public engagement” was main project of the Administrative Conference of the United States (ACUS) committee on Rulemaking: The project “explores agency strategies to enhance public engagement prior to and during informal rulemaking. It seeks to ensure that agencies invest resources in a way that maximizes the probability that rulewriters obtain high-quality public information.” Among other things, this committee is debating how best to gather “quality public information,” how “to get new people/groups into the real or virtual room” (Farina 2018), and whether broad engagement is even desirable on all rules (White 2018). Administrative law scholars have explored these questions theoretically for decades, but only a few offer empirical analysis. Mendelson (2011) finds that agencies often discard non-technical comments but argues that they should be given more weight. Others worry that mass commenting distracts agencies from good policy and the broader public interest (Coglianese 2006). Farina et al. (2012, 112) claims that “[Mass] comments typically are neither factually informative nor reliable indicators of citizens’ informed value preferences.” Some even call them “spam” (Balla et al. 2018; Noveck 2004). In this prevailing view, “high-quality” and “relevant” mean novel technical information, not opinions. Herz (2016, 208) concludes “The goal of e-rulemaking is to more fully capture such credible, specific, and relevant information, not to solicit the views of random, self-nominating members of the public.” Similarly, Epstein, Heidt, and Farina (2014, 4) dismiss mass comments as “effectively, votes rather than informational or analytical contributions. Rulemaking agencies are legally required to make policy decisions based on fact-based, reasoned analysis rather than majority sentiment; hence, even hundreds of thousands of such comments have little value in the rulemaking process.” Notably, the ACUS draft recommendations on “Mass and Fake Comments in Agency Rulemaking” suggests that “effective comments” give “reasons rather than just reactions” (ACUS 2018, 33). If true, most public reactions to proposed rules such as those expressed in mass comments would have no effect in rulemaking. Early optimism among legal scholars that the internet would “change everything” (Johnson 1998) and that “cyberdemocracy” would enable more deliberative rulemaking has faded. While commenting and mobilizing others to comment has become easier, Coglianese (2006) finds that little else has changed. The prediction that the internet would primarily facilitate more of the same kind of engagement among the like-minded (i.e. mass-commenting) (Sunstein 2001) has largely been correct. In this sense, the “quality” of discourse has not improved. Even scholars who suggest reforms aimed at “regulatory democracy” aim to increase the “sophistication” of ordinary peoples’ comments (Cuéllar 2014; Johnson 2013). For example, Beth Simone Noveck (Noveck 2004) is critical of “notice and spam,” arguing instead for “participative practices—methods for ‘doing democracy’ that build the skills and capacity necessary for citizens, experts, and organizations to speak and to be heard. Rulemaking, after all, is a communicative process involving a dialogue between regulators and those affected by regulation” Noveck (2005, 3). This scholarship has improved the theory and practice of policy learning in rulemaking. But a focus on sophisticated deliberation and technical information overlooks the potential role of political information.4 Whereas administrative law scholars have focused on “how technology can connect the expertise of the many to the power of the few” (Noveck 2009), I ask whether it may also connect the power of the many to the decisions of the few. Outline of the book This dissertation explores the effects of public pressure campaigns on agency rulemaking, a technocratic policy process where “public participation” is usually limited to sophisticated lobbying but occasionally includes millions of people mobilized by public pressure campaigns. Public comment periods on proposed policies purport to provide democratic accountability. Yet theories of bureaucratic policymaking largely ignore the occasional bursts of civic engagement that generate the vast majority of public comments on proposed rules. To fill this gap, I build and test theories about the role of public pressure in policymaking. I collect and analyze millions of public comments to develop the first systematic measures of civic engagement and influence in bureaucratic policymaking. Chapter 1 “Agency Rulemaking in American Politics” situates agency rulemaking in the context of American politics. Tracing broad trends over the past 40 years, I show that rulemaking has become a major site of policymaking and political conflict. Chapter 2 “Why Do Agencies (Sometimes) Get So Much Mail?” addresses who participates in public pressure campaigns and why. Are public pressure campaigns, like other lobbying tactics, primarily used by well-resourced groups to create an “astroturf” impression of public support? Or are they better understood as conflict expansion tactics used by less-resourced “grassroots” groups? I find that mass comment campaigns are almost always a conflict expansion tactic. Furthermore, I find no evidence of negativity bias in public comments. Indeed, from 2005 to 2017, most comments supported proposed rules. This is because public comments tend to support Democratic policies and oppose Republican policies, reflecting the asymmetry in mobilizing groups. Chapter 3 “Do Public Pressure Campaigns Influence Congressional Oversight?” examines the effect of public pressure campaigns on whether legislators are more likely to engage in rulemaking. This involves collecting and coding thousands of comments from Members of Congress on proposed rules with and without public pressure campaigns. These data also allow me to assess congressional oversight as a mediator in policy influence, i.e., the extent to which public pressure campaigns affect policy indirectly through their effects on legislators’ oversight behaviors. Chapter 4 “Do Public Pressure Campaigns Influence Policy?” leverages a mix of hand-coding and computational text analysis methods to assess whether public pressure campaigns increase lobbying success. To measure lobbying success, I develop computational methods to identify lobbying coalitions and estimate their effect on each rule posted for comment on regulations.gov. I then validate these methods against a random sample of 100 rules with a mass-comment campaign and 100 rules without a mass-comment campaign, hand-coded for whether each coalition got the policy outcome they sought. Finally, I assess potential mechanisms by which mass public engagement may affect policy. Chapter 5 “The Environmental Justice Movement and Technocratic Policymaking” examines the discursive effects of environmental justice claims both qualitatively and quantitatively. I write about the role of Native activists and environmental groups in shaping federal environmental regulations. Looking across over 20,000 draft regulations that failed to address environmental justice issues, I find that agencies are more likely to add language addressing environmental justice in their final rules when public comments raise environmental justice concerns. References "],["macro.html", "Chapter 1 Agency Rulemaking in American Politics 1.1 Introduction 1.2 Methods and Data 1.3 Policy Substance in Regulations 1.4 Conclusion", " Chapter 1 Agency Rulemaking in American Politics 1.1 Introduction Do the issues that dominate political discourse translate into actual policy? To the extent that broad theories of American politics go beyond the results of elections and attempt to explain the resulting policies, they generally focus on landmark legislation and items at the top of presidential agendas. Yet as the administrative state and our understanding of it have grown, political scientists are increasingly paying attention to policy outputs both for their own sake and how policy outputs shape politics. Agency rules and regulations are where the rubber hits the road for both legislation and presidential agendas (J. W. Yackee and Yackee 2009b). Ninety percent of U.S. law is now written by agencies rather than Congress (West and Raso 2013), and the real impact of most new statutes and executive orders is largely unknown until the ink is dry on the agency rules and regulations that implement them. Legally binding regulations give specific meaning and force to legislation and presidential agendas. As the substantive outputs of policy processes, if changes in public attention or opinion and the priorities of elected leaders matter for policy, we should expect to see these changes borne out in the number and type of agency rules published. Changes in outputs may reflect changes in the substantive inputs—sometimes called the “issue structure”—or changes in how issues are filtered and activated by the institutional structures of policymaking. This chapter martials data on federal agency policymaking from 1980 to 2020 to sketch broad trends in federal policymaking. Broad theories of American politics suggest three types of predictions: (1) patterns in the substantive issues addressed by policy, (2) patterns in the relationship between partisan control and issue attention, and (3) patterns in the pace of policy change. The systematic data on agency rulemaking that I introduce here permit us to assess the extent to which broad theories of American politics explain the substance, timing, and volume of policy outputs. This exercise has two purposes. First, I aim to introduce a large new dataset on federal policymaking and situate these data in the broader context of American politics. Second, I contrast the hard data with broad political science theories. This assessment is descriptive and intended to be provocative—an attempt to stretch the conceptual ground of theories of American politics to include the massive, yet often-neglected, the volume of concrete policy outcomes. The extent to which the match between theory and data is unsatisfying may point toward opportunities for theorizing, a narrow portion of which I take up in the following chapters that focus squarely on expanding theories of bureaucratic policymaking. 1.1.1 Patterns in Policy Issues Following Mayhew (1991, 2008), Claggett and Shafer (2010) argue that the policy issues driving American politics vary over time. Drawing on public opinion polls and presidential platforms, they distinguish four broad categories of political issues: welfare, international relations, civil rights, and cultural issues. These categories are constructed to have policy-relevant content but do not perfectly align with how the government is organized, thus limiting our ability to categorize agency rules by their conceptual scheme. Nevertheless, their findings regarding the issue structure of American politics have observable implications for the quantity and substance of federal rulemaking. Claggett and Shafer (2010) find that National Security was a major issue in 1984 but then faded until it emerged as the dominant issue of the 2004 election. Regarding their relationship with partisan control of the government, opinions on Foreign Engagement reversed the direction of correlation with presidential vote, suggesting that the first Bush and Clinton administrations may be more similar in their attention to foreign policy than the second Bush administration. Welfare was also a top issue in 1984 but continued to be salient and the dominant issue in several subsequent elections. If politics affects the volume of policymaking, agency policymaking (e.g., the number of agency rules) should reflect this finding that social welfare is a major feature of American politics (Sundquist 1968, Claggett and Shafer 2010). Claggett and Shafer found civil rights to be mildly salient in 1988, 1992, and 2000 but not elsewhere. They find cultural issues (operationalized through a concept of “Behavioral Norms”) to be highly salient from 1992 to 2000. Unfortunately, what Claggett and Shafer call behavioral norms is either so distant from policy (e.g., women’s roles) or so fragmented across agencies (e.g., school prayer and abortion) that it is not possible to make predictions of the location of policymaking from patterns on this issue. TODO: Citations for environmental policy salience steadily decreasing in the 80s and 90s, uptick starting around 2010 or so. In sum, if the issue structure of politics shapes policy, past scholarship suggests that social welfare should be the leading policy type over all periods and for both parties. Social welfare is identified as a dominant dimension of party alignment and issue structure in public opinion. 1.1.2 Party Control and Policy Issues The role that parties play in the making of regulations is unclear. Parties may have the greatest effect on agency rules through presidential platforms and agendas (J. W. Yackee and Yackee 2009b). Still, partisan control of Congress also matters (J. W. Yackee and Yackee 2009a), especially when Congress is making policy (West and Raso 2013) or when agencies fear that a hostile Congress will override their policies (Potter 2017b). We may think of agency policymaking as consistently affected by presidential agendas, with Congress providing shocks and constraints. Concerning the anticipated level of attention paid to different policy areas, theories of American politics that focus on substance can be lumped into two types: (1) those that generally predict that both parties pay attention to the same issues at the same time (theories of partisan alignment (e.g., Sundquist) and (2) those that generally predict that parties pay attention to different issues (including both theories of party ideologies (Gerring (1998)) and theories of party coalitions (Schlozman 2015). In each case, the particular issues may vary more or less dramatically depending on how sharply one defines historical periods (compare the issue evolution perspectives (Carmines and Stimson 1989) with critical elections perspectives (Key 1961)). Indeed as Shafer (2016) notes, some periods may end quickly and others slowly. Given the limited time period of this paper, I focus on the dominant policy issues, their relationship to party control, and the pace of policymaking rather than the timing or pace of transition between periods. These two types of theories generate broadly contrasting predictions about what we expect the government to do under various configurations of party control. For partisan alignment theories, we would expect to see agency policymaking dominated by the major issues of the day under both parties. Parties may have opposite positions on these issues leading the agencies to be pulled in opposite directions by political leaders, but the agencies’ set of dominant policy issues demanding attention will remain largely the same. Indeed, the push and pull should lead to sustained high volumes of policy, as presidential administrations and congresses reverse policies made by their predators or by other branches. Occasionally, an agency with somewhat overlapping authority may be given control of a program taken from an adjacent agency (Carpenter 2001), but the broad policy area should be the same. In contrast, for theories of party ideologies and party coalitions, party control should determine which issues are attended to. Thus, partisan control should have a much larger effect on which agencies are making more policy. This may occur through positive agenda control that the President has to direct agency policymaking or negative agenda control the President has through the Office of Information and Regulatory Affairs review (Haeder and Yackee 2015; Potter 2017b). Negative agenda control is likely to dominate in Congress (Cox and McCubbins 2005), but the threat of Congressional action may be sufficient to influence agency policymaking (Potter 2017b). 1.1.2.1 The implications of partisan alignment Partisan alignment theories necessarily identify dominant issue dimensions where each party is doing the opposite of the other. In Sundquist’s model, realignment can occur slowly or rapidly, whereas Manza and Brooks emphasize how social structures, and thus issues, change slowly. Almost all prominent alignment theories, however, identify 1980 through the present as one period (indeed, most see 1936 as the critical election that has oriented the modern era). Thus instead of engaging realignment theories on the issue of realignment, I draw on them for the issues that they claim constitute the dimension of the current alignment. By these theories, the dimensions of substantive conflict and thus the distribution of agency policymaking should be relatively stable over the period considered in this paper. Realignment theories suggest that certain policy areas consistently dominate all others and, while the direction of policy will likely change, the issues will vary little with changes in partisan control. Presidential transitions may be marked by withdrawal or reversal of policies made under the previous administration, and Congress may overturn agency rules. Still, the relevant agencies will be the same, generally those dealing with social welfare. 1.1.2.2 The implications of issue ownership and party coalitions The second type focuses on the differences of party ideologies, and its predictions are less clear. Gerring identifies distinct and consistent ideologies in both parties. Rather than a dominant dimension of conflict where parties respond to each other (as in alignment theories) or an underlying dimension of issue structure (e.g., Claggett and Shafer 2010), for Gerring, party ideologies are the policy agendas of party elites. “Party constituencies were generally conservative forces, whereas party elites were the agents of change” (Gerring 1998, pg. 272). In the current era, Gerring argues, Republicans are driven by Neoliberalism and Democrats by Universalism. Like others, Gerring sees social values (behavioral norms) playing a prominent role in Republican policy agendas from 1980 to when the book was published in 1996 (see pg. 277). Yet, he argues, the core of the platform was neo-liberal opposition to the welfare state and promotion of free markets. In contrast, Gerring identifies the Democratic platform in this period as consistently emphasizing broad unifying issues like Medicare and education. While this more clearly suggests the policy areas likely to receive attention under Democrats than Republicans, it does generally imply that the policy agendas will be different, not simply opposite. Under theories emphasizing party ideologies and interests, the volume of policymaking at different agencies may very well change substantially when a different party captures the presidency. Specifically, if Gerring (1998) correctly identified the party ideologies of the current era, we would expect significantly more civil rights and welfare policymaking under Democratic administrations and more neoliberal economic policy under Republican administrations, especially when presidents’ co-partisans have majorities in Congress. Gerring’s distinction between Democrats statism and Republicans anti-statism may also suggest more rulemaking overall in Democrat administrations. Perspectives focusing on interest groups and coalitions also suggest that issues will vary with party control. If parties contain coalitions of intense policy demanders (Cohen et al. 2008; DiSalvo 2012), the issues to which they attend will reflect these different coalitions. Disalvo shares Gerring’s conclusion regarding the anti-statism of the Republican party. Most clearly, Schlozman (2015) links Democratic politics and labor groups. While Schlozman emphasizes that labor groups frequently fall short of their goals within the Democratic coalition, no other group is a stronger anchor. We thus expect much more labor policy under Democratic administrations. As the interest groups Schlozman identifies anchoring the Republican party are focused on behavioral norms where policymaking is less concentrated in certain agencies, these predictions are less relevant. Again these co-partisans in Congress ought to increase these effects. The above perspectives emphasize party difference, either on ideology (on the same issues for Sundquist, on different issues for Gerring) or anchoring interests. However, the observable implications are different. If party alignment theories explain policy outputs, the volume of agency rules will concentrate on the same agencies and issues, even as parties change. In contrast, if issue ownership and party coalition theories explain policy outputs, the volume of agency rules at different agencies should vary by partisan control. 1.1.3 Policymaking and Policy Outcomes On Different Issues The American Political Pattern: Party Balance, Ideological Polarization, and Substantive Conflict, 1932-2016 (Shafer 2016) attempts to integrate the issue structure of politics and party control of the government. Patterns of the substance of conflict and balance of party control produce patterns of policymaking. Most clearly, Shafer observes a pattern of consistent major policymaking in the years between 1980 and 1992 and a pattern of punctuated equilibrium after 1992. Such patterns of policymaking should be visible in patterns of rulemaking. Importantly, The American Political Pattern discusses not only landmark policies and agendas but also identifies distinct patterns of policymaking. The “Era of Divided Government” (1969-1992) saw a steady flow of major policies, especially regarding the economy and the environment, and was dominated by social welfare and cultural values and cross-partisan coalitions, suggesting that the volume of policy outputs should be concentrated on social policy and civil rights be fairly consistent across configurations of party control. In contrast, the “Era of Partisan Volatility” (1992 through the present) is characterized by periods of policy stability and punctuation. One aim of this chapter is to assess the extent to which patterns of agency policymaking fit these patterns.5 Schafer characterizes this era by long stretches of policy stasis punctuated by spikes of activity. If these broad patterns explain policy outputs, we would expect to see a pattern of lulls and spikes in rulemaking. Furthermore, party control may lead to different types of policymaking moving together depending on partisan control. The observation of punctuated equilibrium in legislative policymaking could also suggest a pattern where, in the absence of new legislation, the President may have a larger effect over patterns of agency rulemaking. Scholarship thus gives us predictions regarding the issues that dominate American politics and how party control will affect the translation of issues into policy. However, the two-fold space for disagreement raises a problem for the focus on policy outputs in the present analysis. If we do not see policymaking on an issue, it could be evidence that the issue was not as important as claimed or that the party in power deemphasized it. Only by assuming a certain issue structure or a certain theory of party effects could we say that an absence of policymaking supports one perspective or another regarding issues or institutional structure. The evidence is sufficient, however, to rule out some explanations. The remainder of the chapter focuses on consistencies and inconstancies between the evidence and theories, with no claim that consistency means the theory is correct. 1.2 Methods and Data This exercise compares research on the social structure and political behavior of the American public and political elites with what government actually does. Agency rulemaking is driven in part by laws passed by Congress and in part by the agenda of the President. Discrepancies may indicate either a true disconnect between electoral politics and executive action or that executive policymaking was constrained by other political forces. Connecting broad theories of the American political landscape to the nuanced daily actions of government is not easy. I focus on relatively fine-grain policy outputs, final rules published by agencies in the Federal Register and reported to the Office of Information and Regulatory Affairs. This approach has the advantage of capturing the making of law as it really is, not how it is framed by elites or thought of by the electorate. The disadvantage is its distance from policy inputs. While public opinion and attention can be connected to voting patterns, it is much more difficult to say how they affect the lawyers sitting at desks in the federal bureaucracy writing the minutiae of the law. The subsequent chapters of this dissertation take up the task of more directly linking policy change to public attention and expressed opinion through public pressure campaigns, congressional oversight, and social movements. For this exercise, I use the Unified Agenda of Regulatory and Deregulatory Actions. These data reflect the magnitude of different types of policymaking but not the direction. As the name suggests, many rules may be reversing a previous rule. However, it does indicate that attention and resources are being devoted to the policy area and thus that it is a salient issue for policymakers. Whether these policy issues align with the issues that are salient to the mass public and political elites is the subject of the present investigation. These data were compiled from two sources published by the White House Office of Information and Regulatory Affairs. Since the Reagan administration, agencies have been required to report their rulemaking activities for semi-annual publication in the Unified Agenda of Regulatory and Deregulatory Actions. Separately, ORIA issues annual reports from the Office of Management and Budget (OMB) regarding the rules it has reviewed. OMB only reviews significant rulemakings (generally those with significant economic impact or affecting other areas of government), but their data helps correct reporting errors and gaps in the Unified Agenda, ensuring that at least significant rules are included and correctly dated. Together these sources yield a dataset of 56,304 unique rulemaking projects as identified by a Regulation Identification Number (RIN). RINs allow us to track a rule from the publication of a draft to the eventual publication of a final rule (or withdrawal). Regulation Identification Numbers are allocated by agency, allowing me to disaggregate the OIRA reports by policy area. I generally followed the policy areas identified by the Policy Agendas Project (Baumgartner et al., 2016). The first two numbers of a RIN generally signify the department, and the next two, the bureau within the department. Many issue areas, like welfare and foreign affairs, cross multiple entire departments while others, like civil rights, are the domain of only a few sub-bureaus. I visually present rulemaking activity over time in three different ways. The simplest visualization is a histogram in Figure 1.1. In these plots, red lines mark transitions to a new Republican president, and blue lines mark transitions to a new Democratic president. Figure 1.1: Number of Final Rules Published per Year 1.2.1 Scatterplots of Rulemaking In addition to histograms of the number of rules, we can see patterns in rulemaking by plotting the date a rule is finalized or withdrawn on a scatterplot. On the y-axis is the Regulation Identification Number (RIN). RIN numbers are assigned in temporal order within each bureau or sub-agency. For example, the lower half of 1.2 shows a high and steady rate of rulemaking by the Centers for Medicare and Medicaid, and the upper half shows a very modest rate of rulemaking at the Social Security Administration until the passage of the 2003 Medicare Modernization Act, which gave it a more prominent role in administering Medicare. Figure 1.2: Number of Final Rules Publishded per Year Other major political events can be seen in the scatterplots of agency rulemaking. For example, the gap in rulemaking activity between 1995-1996 reflects the government shutdown. We also see the abrupt end of agencies and departments, including those in the Department of Justice and Department of Transportation, reflecting their reorganization into the Department of Homeland Security after the attacks of September 11, 2001. This included the Coast Guard and Transportation Security Administration from the Department of Transportation and several agencies, including the Immigration and Naturalization Service from the Department of Justice (see scatterplots in the Appendix). There is a stark increase in the number of rules being withdrawn across policy areas beginning with the election of George W. Bush and continuing into the Obama administration. Withdrawals may indicate that the draft regulations started by the previous administration are being canceled, that new legislation is passed, or, more likely, that there is simply a more systematic practice of reporting withdrawals. In any of these figures, one can observe the general rate of rulemaking in each bureau as the slope of the line of black squares. Points below the line are rules that took longer than usual to finalize. Thus, these figures allow us to see the relative rate of rule finalization and withdrawal as well as the variance in how long agency rules take to work through the policy process. 1.2.2 The Likelihood of Rulemaking over Time Finally, we can estimate statistical trend lines for different policy types. While many statistical approaches may be appropriate, I opt to use a proportional hazard model. This method estimates a baseline hazard rate–the likelihood a rule will be published given the number of days since a draft was released. I then estimate the effect of calendar time on this baseline hazard rate. The effect of calendar time on the likelihood of rule finalization is fit using a smoothing spline for every two years (every Congress) in the dataset. These splines estimate a cubic polynomial function that best captures the effect of a given date on the likelihood of rulemaking over the spline interval (a Congress) while also smoothly connecting to the intervals on either side. This gives us a smoothed function estimating the likelihood of rulemaking over time (Figure ??). Figure 1.3: Smoothed Likelihood that a Rule is Published on a Given Day 1980-2020 By including the date that the draft rule was published, this approach captures two things not well-captured by histograms and scatterplots. First, it accounts for the pace of rulemaking (i.e., the time it takes from draft to completion). Second, it accounts for the likelihood that long-delayed rules will be finalized. Both of these indicate that the issue is politically salient. Compared to the raw number of rules finalized in a year, looking at the likelihood that a rule is finalized accounts for the denominator—the number of rules in progress and yet to be finalized in a given policy space. Two notes are important for interpreting these figures. First, in 1994, President Clinton issued an executive order making only significant rules subject to ORIA review. Unfortunately, this coincides with the dramatic 1994 election that broke Democratic control of Congress, so inferences about this time are limited. It may be safest to assume that the universal dip in the likelihood of policymaking around 1994 is an artifact of this executive order and thus to imagine trend lines going forward from 1994 shifted up to have a mean of the value at 1994 to account for the increase in rules omitted from OIRA data. Second, this method is sensitive to outliers at the ends of the distribution. We should be especially cautious in making inferences from the first years that agencies were required to report these data as they may have been inconsistent. Thus, it is safest to look at the period between 1985 and 2015. 1.3 Policy Substance in Regulations This section presents selected figures and brief commentary on the extent to which patterns observed in rulemaking fit or conflict with those observed elsewhere in the American political system. 1.3.1 Social Policy, Economic Policy, and Foreign Policy I start with the broadest categorizations of social policy and economic policy. My social policy category is not equivalent to “social issues” as described by Shafer and Spady (2014) or Carmines, Ensley, and Wagner (2012). Social policy is also broader than welfare. I include not only Medicare, Medicaid, Social Security, and food and housing assistance but also public education, labor, and civil rights. More specifically, I combine the departments of Education, Health and Human Services, Labor, Veterans Affairs, and Justice, as well as the Social Security Administration, Centers for Medicare and Medicaid, and a variety of other departments dealing with health, poverty, and civil rights. My economic policy category includes the Departments of Commerce, Treasury, Energy, Transportation, Agriculture, and Interior. The likelihood plots in Figure 1.4 are not clear evidence for or against theories that suggest Democrats and Republicans should differ in their emphasis on these two broad categories. On the one hand, the patterns are not noticeably different before the 2000 election, and both George W. Bush and Barack Obama appear to have made more economic policy in their first term than in their second. On the other hand, there is a marked increase in the likelihood of social policy under the Obama administration, as suggested by the party ideology perspective put forward by Gerring (1998) and others. Social policy will be disaggregated to more specifically consider welfare, labor, and civil rights policymaking in the subsections below, but first, I turn to a third broad category of policymaking, foreign policy. Figure 1.4: Social and Economic Policy Final Rules Published per Year 1980-2020 The histogram for foreign affairs (the Department of State and International Trade Administration) in Figure 1.5 differs from the Department of Defense, but the only clear pattern is the increased rulemaking after 1996, predating the dramatic increase in its budget after 2001 and significantly predating the 2004 election when Claggett and Shafer (2010) identify national security as emerging as an issue. The likelihood plot suggests partisan effects with two peaks occurring during the 103rd and 111th Congresses, the only periods where Democrats had control of both houses and the presidency. This aligns with findings by Farhang and Yaver (2016) that rulemaking is more likely to be concentrated in a single agency rather than fragmented across agencies under a unified government. There are smaller bumps that appear to correspond to the reelection of these two presidents when facing an oppositional Congress (but also no longer thinking about reelection). Figure 1.5: Social and Economic Policy Final Rules Published per Year, 1980-2020 1.3.2 Labor and Welfare A connection between labor and the Democratic party (Schlozman 2015) is not obvious in the volume of Department of Labor regulations. If anything, Republican administrations seem to make more labor policy. Looking at the scatterplot in Figure 1.6, policymaking appears remarkably constant across sub-agencies within the Department of Labor, barring a marked pulse of rule withdrawals in 2001. Figure 1.6: Labor Policy Final Rules Published per Year, 1980-2020 Clear peaks in welfare rulemaking (Social Security, Medicare, and Medicaid) reflect the 2003 Medicare Modernization Act and the 2010 Affordable Care Act. The histogram in Figure 1.7 suggests that policymaking both increased and became more variable after 2000. This pattern is most consistent with Shafer’s characterization of the Era of Partisan Volatility. We do not see clear patterns associations with party balance, but this may be because we are looking at the amount of policy rather than its direction. The scatterplot shows significant numbers of rules withdrawn after 2001, which may indicate partisan disagreement. Figure 1.7: Welfare Policy (Social Security, Medicare, and Medicaid) Final Rules 1980-2020 1.3.3 Civil Rights Among others, Mayhew (1991) and Claggett and Shafer (2010) identify civil rights as one of the major new issues on the post-war American policy agenda. Rulemaking, however, likely presents a poor measure of this policy issue, and classifying rules by agency only makes this problem worse. Only a few sub-agencies unambiguously address only civil rights issues. The figures below reflect the Department of Agriculture Office of Civil Rights, The Department of Housing and Urban Development’s Fair Housing and Equal Opportunity bureau, and the Equal Employment Opportunity Commission, none of which make many regulations. Little can be said about so little data, but rulemaking activity does appear to peak near the beginning of the Clinton administration and remain nearly non-existent since the beginning of the George W. Bush administration.6 It is possible that civil rights, anti-discrimination policy issues are meaningful for structuring votes and local policy but still poorly reflected in the volume of federal rules. Figure 1.8: Civil Rights Policy Final Rules, 1980-2020 1.3.4 Environment The cleanest way to capture environmental issues is to focus only on the Environmental Protection Agency. This is what the plots in Figure 1.9. However, environmental issues are also spread throughout the Departments of Agriculture, Energy, Defense, and, increasingly, state. Claggett and Shafer (2010), among others, identify environmental issues as anomalous or off-dimension issues that may not cluster well with other issues. Shafer 2016 identifies environmental issues as a major policy issue until the 1990s. The rulemaking data in Figure 1.9, especially the histogram, do not contradict these interpretations. Unlike any other policy areas, the peak of environmental rules in this timeframe is when Reagan took office (probably capturing the end of the era of new landmark environmental legislation) and declines dramatically by the end of his term to a much lower level for the next three decades. Figure 1.9: Environmental Policy Final Rules, 1980-2020 The likelihood plot in Figure ?? does show peaks in the 103rd and 111th Congresses, suggesting partisan effects. However, this partisan association could be as much an artifact of the agency as the issue. For example, Republicans may be inclined to pursue environmental protection through the Departments of Agriculture, Energy, or Defense in which they may have more trust or better policy vehicles to serve their constituents (see Appendix for additional plots). Alternatively, policymaking in the EPA may be indicative of policymaking in other venues where Democrats may also pay more attention to environmental issues. Future research could analyze the abstracts of rules in more multi-issue agencies to better determine their content. The most pronounced peak may reflect Barack Obama’s executive actions in his second term (for example, his executive order on climate change adaptation (Obama 2013)). 1.4 Conclusion While this exercise did not reveal conclusive evidence regarding the patterns of U.S. policymaking, it does offer some insights. First, welfare is one of the largest topics of executive policymaking, rivaled only by defense. Both of these areas increased dramatically in volume and variability in what Shafer (2016) calls the Era of Partisan Volatility. In contrast, civil rights and environmental policy have seen marked decreases over the same period. In 1980, environmental policy was a top area of executive policymaking, but it was overtaken by defense in 1996. Civil rights, where no year saw more than five rules by my measure, raises the question of what it means for a major issue in mass politics to have few explicit policies (at least within dedicated bureaus). Part of the story may well be that civil rights policy is being made in venues other than the federal agencies. Interestingly, Department of Labor policymaking does not seem to have the partisan linkages one would suspect—another area where this exercise raises questions for future research and theory. Future research could also augment these data on regulations with data on agency budgets, which may reveal different patterns and may better reflect the role of Congress in agencies’ policy agendas (Judge-Lord 2017). It should nevertheless be noted that a great deal of spending is directed by rulemaking. Furthermore, rule publication dates may capture the timing of policy decisions better than other measures of policy priorities (Potter 2017b). Looking at budgets alone, as many scholars have done, risks attributing to present politics decisions made in the past. In the end, the relationships between rulemaking and the nature of change in public opinion and party power over time demands more detailed study. Linking macro-level politics to the concrete substance of policy is not an easy task, but the fruits of such research are critical to understanding which of American politics’ many moving parts most affect the concrete laws that govern daily life and, in many cases, feed back to reshape the terrain of American politics. The following chapters in this dissertaion focus on one narrow peice of this broad project to incorporate burecratic policymaking into theories of American politics. They use similar data, but approach the problem from the other side. I start with theories of bureaucratic policymaking and begin to incorporate theories of civic engagment, pressure politics, legislative behavior, and social movement power in order to explain and account for the occasional bursts of public attention and engagment in agency rulemaking. In these policy fights the politics of agency rulemaking begins to look more like the American politics described above—dominated by durable yet shifting coalitions of social movements, organized interests, politicians, and the attentive public. References "],["whymail.html", "Chapter 2 Public Pressure: Why Do Agencies (sometimes) Get So Much Mail? 2.1 Introduction 2.2 Theory: Why Mobilize? 2.3 Hypotheses About the Drivers of Mass Mobilization 2.4 Types of Public Engagement 2.5 Methods: Measuring Public Pressure and Political Information 2.6 Results: Patterns of Public Engagement in Rulemaking", " Chapter 2 Public Pressure: Why Do Agencies (sometimes) Get So Much Mail? See the working paper version of this chapter here. Abstract I examine who participates in public pressure campaigns and why. Scholars of bureaucratic policymaking have focused on the sophisticated lobbying efforts of powerful interest groups. Yet agencies occasionally receive thousands or even millions of comments from ordinary people. How, if at all, should scholars incorporate mass participation into models of bureaucratic policymaking? Are public pressure campaigns, like other lobbying tactics, primarily used by well-resourced groups to create an impression of public support? Or are they better understood as conflict expansion tactics used by less-resourced groups? To answer these questions, I collect and analyze millions of public comments on draft agency rules. Using text analysis methods underlying plagiarism detection, I match individual public comments to pressure-group campaigns. Contrary to other forms of lobbying, I find that mass comment campaigns are almost always a conflict expansion tactic rather than well-resourced groups creating an impression of public support. Most public comments are mobilized by public interest organizations, not “astroturf” campaigns. Over 80% of the 48 million comments on proposed rules posted to regulations.gov were mobilized by just 100 organizations, 87 of which lobby in coalitions with each other. Contrary to other forms of political participation, I find no evidence of negativity bias in public comments. Indeed, from 2005 to 2017, most comments supported proposed rules. This is because public comments tend to support Democratic policies and oppose Republican policies, reflecting the asymmetry in mobilizing groups. 2.1 Introduction Participatory processes like public comment periods, where government agencies must solicit public input on draft policies, are said to provide political oversight opportunities (Balla 1998; Mccubbins and Schwartz 1984), democratic legitimacy (Croley 2003; Rosenbloom 2003), and new technical information (S. W. Yackee 2006; Nelson and Yackee 2012). While recent scholarship on agency policymaking has shed light on sophisticated lobbying by businesses, we know surprisingly little about the vast majority of public comments, which are submitted by ordinary people as part of public pressure campaigns. Activists frequently target agency policymaking with letter-writing campaigns, petitions, protests, and mobilizing people to attend hearings, all classic examples of “civic engagement” (Verba and Nie 1987). As I show below, most comments submitted to regulations.gov are part of organized campaigns, more akin to petition signatures than “deliberative” participation or sophisticated lobbying. Indeed, approximately 40 million out of 50 million (80%) of these public comments mobilized by just 100 advocacy organizations. Yet civic engagement and organized public pressure remains poorly understood in the context of bureaucratic policymaking. While practitioners and administrative law scholars have long pondered what to make of mass commenting, political scientists have had surprisingly little to say about this kind of civic participation and the role of public pressure in agency rulemaking. The contentious politics that inspire the majority of public comments have no place in leading models of bureaucratic policymaking and have largely been ignored by political scientists. Foundational scholarship on rulemaking (Furlong and Kerwin 2005, @Furlong1997, @Furlong1998, @Kerwin2011) focuses on interest group lobbying. Theoretical models focus on how agencies learn about policy problems, negotiate or avoid accountability to various principals, or balance interest-group demands.7 To the extent that scholars address the input of ordinary people at all, both existing theory and empirical scholarship suggest skepticism that it matters. (By “ordinary” people, I simply mean people who are not professional policy-influencers.) Empirical scholarship finds that economic elites and business groups dominate American politics in general (Jacobs and Skocpol 2005, @Soss2007, Hertel–Fernandez2019, @Hacker2003, @Gilens2014) and rulemaking in particular. While some are optimistic that requirements for agencies to solicit and respond to public comments on proposed rules allow “civil society” to provide public oversight (Michaels 2015; Metzger 2010), most studies find that participants in rulemaking often represent elites and business interests (Seifter 2016; Crow, Albright, and Koebele 2015; Wagner, Barnes, and Peters 2011; West 2009; J. W. Yackee and Yackee 2006; S. W. Yackee 2006; Golden 1998; Haeder and Yackee 2015; Cook 2017, LibgoberCarpenter2018). Becasue scholars are skeptical about rulemaking as a venue for collective action, most dismiss public pressure campaigns as epiphenomenal to bargaining with political principals or interest groups. Indeed, almost all empirical studies of rulemaking discard unsophisticated comments from ordinary people, as evident from a comprehensive review of scholarship on “The Politics of Rulemaking” by Yackee (2019), who finds skepticism about citizen comments, but no studies analyzing public pressure campaigns as a lobbying tactic: “Kerwin and Furlong (2011) point out that a citizen must know not only that a regulation is being formulated but also how and when to participate. This is a high bar for most Americans. Second, to be influential during rulemaking, commenters may require resources and technical expertise. As Epstein, Heidt, and Farina (2014) suggest, agency rule-writers—who are often chosen because of their technical or policy-specific expertise—privilege the type of data-driven arguments and reasoning that are not common to citizen comments.” (p. 10) For any particular lay commenter, this conclusion seems inescapable; individuals acting alone are unlikely to affect policy. As Hacker and Pierson (Forthcoming) observe, “[The United States’] institutional terrain advantages political actors with the capacity to work across multiple venues, over extended periods, and in a political environment where coordinated government action is difficult, and strategies of evasion and exit from regulatory constraints are often successful. These capacities are characteristic of organized groups, not individual voters.” But groups occasionally mobilize a large number of people, usually behind a more sophisticated lobbying effort. Without a systematic understanding of the scale and impact of public participation–group-mediated participation–in rulemaking, it is impossible to answer normative questions about how participatory processes like public comment periods may enhance or undermine various democratic ideals. Scholars’ neglect of public pressure campaigns is surprising given that most people are only aware of agency rulemaking when it is the target of a high-profile mass mobilization campaign.8 While most rules receive little attention, the ease of online mobilizing and commenting has, like other forms of participation (Boulianne 2018), created exponential increases in the number of rules in which thousands and even millions of people engage (see Figure 2.2; note that comments per rule are on a logarithmic scale).9 Occasionally, a large number of people are paying attention. The general failure to explain or account for public pressure campaigns in models of bureaucratic policymaking is also striking in light of how agencies advertise public comment periods as an opportunity for a voice in government decisions.10 Big red letters across the top of the Regulations.gov homepage solicit visitors to “Make a difference. Submit your comments and let your voice be heard” and “Participate today!” (Figure 2.1. A blue “Comment Now!” button accompanies a short description of each draft policy and pending agency action. Public comment periods on proposed agency rules is described as “an important part of democracy” (WSJ 2017), “often held out as the purest example of participatory democracy in actual American governance” (Herz 2016). Rossi (1997) finds that “courts, Congress, and scholars have elevated participation in rulemaking to a sacrosanct status…greater participation is generally viewed as contributing to democracy.” Figure 2.1: Regulations.gov Solicits Public Comments on Draft Agency Rules Figure 2.2: Comments per Proposed Rule and Total Comments per Year While “ordinary” members of the public may occasionally provide novel and useful technical information to expert bureaucrats, such sophisticated means of influencing policy are out of reach for the vast majority of people. Thus, to investigate the potential role of ordinary people in bureaucratic politics I look elsewhere—not because ordinary people never provide novel and useful technical information, but because this is not how most people attempt to influence policy, nor, I argue, how we should expect ordinary people to have influence. Most public comments are, in fact, of the type suggested by the solicitations on Regulations.gov—ordinary people voicing opinions on a proposed policy. They do not provide useful technical information or suggest specific edits to policy texts like the interest group comments that have thus far captured the attention of political scientists. If they add information to rulemaking, it is a different, more political flavor of information. Indeed as Figure 2.2 shows, every year since 2008, most people who comment on draft regulations have done so as a result of a public pressure campaign.11 Public engagement in rulemaking is highly clustered on a few rules made salient by these campaigns. It is plausible that at least some of the time, such campaigns aim to influence policy. It is also plausible that thousands of people engaging may alter the politics of these policy processes, but this hypothesis remains untested. Indeed, we have much to understand about the causes and effects of these campaigns before we are in a position to ask if they are a mechanism for groups to influence policy. Most critically, we must understand who mobilizes and why. The kind of politics created by mass engagement has a few notable features. It is contentious; most ordinary people are not engaging in deliberation; they are simply making demands. Importantly, however, processes like public comment periods channel contentious demands into institutionalized policy processes rather than undermining them. In short, the politics of rulemaking created by public pressure campaigns is much more contentious than most rulemakings, but also much more institutionalized than most contentious politics. Mass engagement in rulemaking thus presents a novel context to examine the consequences of broader public participation in typically insider-dominated policymaking and how public pressure may condition how political decisions are made. Public pressure campaigns expand civic participation in policymaking.12 Surely, those who engage are far from representative of the broader public (Verba and Nie 1987), but in many ways, they must be more representative than the handful of political insiders who participate in most policy processes. If the usual participants have “an upper-class accent” (Schattschneider 1942), does adding thousands of more voices dilute this bias? I argue that the answer depends on how people are mobilized. If public pressure is mobilized by the usual participants to create an impression of public support, it may merely legitimize the demands of powerful interest groups. 2.2 Theory: Why Mobilize? How, if at all, should scholars incorporate mass engagement into models of bureaucratic policymaking? I argue that mass engagement produces potentially valuable political information about the coalition that mobilized it. Political information may play two distinct roles depending on who mobilized it. To the extent that well-resourced groups use public pressure campaigns to create a misleading impression of public support (often called “astroturf”), their role is to strengthen and legitimize demands of the same powerful interests that dominate bureaucratic policymaking (J. W. Yackee and Yackee 2006). Here, just groups with superior resources use them to flood policymakers with technical information (Wagner 2010), astroturf campaigns convert economic resources into political information in the form of an impression of public support generated by signatures or form letters. Even groups with few members or a narrow or non-existent base of support among the public may create the appearance of public support by sponsoring pressure campaigns. Alternatively, to the extent that public interest groups use public pressure campaigns are used as a conflict expansion tactics by less-resourced groups, their role is the opposite: to push back against powerful interests that dominate bureaucratic policymaking. The political information created by conflict expansion can reveal existing and potential support among attentive segments of the public. Through public pressure campaigns, groups that lack financial resources can convert latent public support into concrete political information that may cause policymakers to update their beliefs and change their behavior. The normative and empirical import of mass commenting campaigns thus turns on who is behind them. If it is the powerful business groups that dominate other forms of lobbying, public pressure campaigns (and perhaps public comment periods themselves) are normatively suspect, merely providing a democratic veneer to economic power. Empirically, we would thus expect public pressure campaigns to further advantage well-resourced interests. Alternatively, if mass commenting is mainly a vehicle for public interest groups to convert a latent base of public support into influential political information supporting their representational claims, public comment periods may yet serve some of informing, balancing, and democratic functions that practitioners and normative theorists hoped they would. Empirically, we would then expect public pressure campaigns to disadvantage well-resourced interests that dominate most policy processes. This section offers a theory and hypotheses to explain variation in mass engagement. I argue that we should observe different patterns of engagement depending on whether an organization launches a mobilization campaign as an outside lobbying tactic, to counter such a campaign, or for reasons other than influencing policy. In the next section, I develop methods to measure these patterns. In short, these measures capture similar statistics to questions posed by Verba and Nie (1987, 9): “How much participation is there, what kind is it, and from what segments of society does it come?” As noted above, scholars of bureaucratic policymaking have focused on the sophisticated lobbying efforts of powerful interest groups such as business coalitions. A key insight from this scholarship is that technical information is the currency of insider lobbying. Figure 2.3 illustrates the classic causal model of insider lobbying that describes most rulemakings and nearly all scholarship on lobbying in bureaucratic policymaking to date.13 However, mass engagement has no place in this model. I aim to fill this gap. Figure 2.3: The ‘Classic Model’ of Interest Group Lobbying in Bureaucratic Policymaking First, I offer a framework for assessing the causes of mass engagement. Next, I argue that organizations may mobilize large numbers of people for three reasons with observable implications for observed patterns of mass engagement and theoretical implications for predicted effects on policy. 2.2.1 Incorporating political information into models of lobbying in rulemaking 2.2.1.1 Public pressure campaigns claim to represent and evoke the public interest. The Oceana coalition framed its mass mobilization effort to curb the Bureau of Ocean Energy Management’s 2017 Proposed Offshore Oil and Gas Leasing Program as a “petition signed by 67,275 self-proclaimed United States residents,” suggesting that organizations consider these efforts as akin to petitions. In the same statement, Oceana also claimed the support of “more than 110 East Coast municipalities, 100 Members of Congress, 750 state and local elected officials, and 1,100 business interests, all of whom oppose offshore drilling,” suggesting that claims of public and elected official support aim to provide similar kinds of political information. Appeals to the government are almost always couched in the language of public interest, even when true motivations are private (Schattschneider 1975). When lobbying during rulemaking, groups often make dubious claims to represent broad segments of the public (Seifter 2016). If agency staff do not trust an organizations’ representational claims, engaging actual people may be one of the few credible signals of a broad base of support. Furthermore, if organizations claim to represent people beyond their official members, reforms requiring groups to disclose information about their funding and membership (Seifter 2016) only go part way to assess groups’ claims to represent these broader segments of the public. Indeed, if advocacy group decisions are primarily made by D.C. professionals, these advocates themselves may be unsure how broadly their claims resonate until potentially-attentive publics are actually engaged. Theorists debate whether signing a petition of support without having a role in crafting the appeal is a meaningful voice and whether petitions effectively channel public interests, but, at a minimum, engaging a large number of supporters may help broader interests to distinguish themselves from truly narrower ones. It suggests that the organization is not “memberless” (Skocpol 2003) in the sense that they can demonstrate some verifiable public support.14 2.2.1.2 Public pressure is a political resource. An organization’s ability to expand the scope of conflict by mobilizing a large number of people can be a valuable political resource (Schattschneider 1975). In contrast to scholars who focus on the deliberative potential of public comment processes, I focus on public engagement as a tactic aimed at gaining power. Scholars who understand mobilization as a tactic (Furlong 1997; Kerwin and Furlong 2011) have focused on how organizations mobilize their membership. I expand on this understanding of mobilization as a lobbying tactic to include a campaign’s broader audience, more akin to the concept of an attentive public (Key 1961) or issue public (Converse 1964). Here I build on three insights. First, Furlong (1997) and Kerwin and Furlong (2011) identify mobilization as a tactic. The organizations that they surveyed reported that forming coalitions and mobilizing large numbers of people are among the most effective lobbying tactics. Second, Nelson and Yackee (2012) identify political information as a potentially influential result of lobbying by different business coalitions. While they focus on mobilizing experts, Nelson and Yackee (2012) describe a dynamic that can be extended to mass commenting: “strategic recruitment, we theorize, mobilizes new actors to participate in the policymaking process, bringing with them novel technical and political information. In other words, when an expanded strategy is employed, leaders activate individuals and organizations to participate in the policymaking process who, without the coordinating efforts of the leaders, would otherwise not lobby. This activation is important because it implies that coalition lobbying can generate new information and new actors—beyond simply the ‘usual suspects’—relevant to policy decisionmakers. Thus, we theorize consensus, coalition size, and composition matter to policy change.” I argue that, concerning political information, this logic extends to non-experts. The number and distribution of ordinary supporters may matter because it suggests a public consensus. Instead of bolstering scientific claims, a perceived public consensus bolsters political claims. Finally, Furlong (1998), S. W. Yackee (2006), and others distinguish between direct and indirect forms of interest group influence in rulemaking. This distinction is especially important for political information, which may be most influential through indirect channels, such as through elected officials. In short, to understand how groups lobby in rulemaking, we must understand mass mobilization as a tactic aimed at producing political information that may have direct and indirect impacts on policymaking. While most scholars have emphasized mass comments’ lack of useful technical information, a few have raised their role in creating political information. Cuéllar (2005) calls on agencies to pay more attention to ordinary peoples’ expressions of preference and Rauch (2016) suggests that agencies reform the public comment process to include opinion polls. I build from a similar intuition that mass comment campaigns currently function like a poll or, more accurately, a petition, capturing the intensity of preferences among the attentive public—i.e., how many people are willing to take the time to engage.15 Self-selection may not be ideal for representation, but opt-in participation—whether voting, attending a hearing, or writing a comment—may often be one of the few heuristics decisionmakers have about public preferences. Mobilizing citizens and generating new political information are key functions of interest groups in a democracy (Mansbridge 1992; Mahoney 2007). Campaigns inform agencies about the distribution and intensity of opinions that are often too nuanced to estimate a priori. Many questions that arise in rulemaking lack analogous public opinion polling questions, making mass commenting a unique source of political information. As with public opinion on many specific policy issues, most members of the public and their elected representatives may only learn about the issue and take a position as a result of a public pressure campaign (Hutchings 2003). I thus consider public demands to be a latent factor in my model of policymaking (Figure 2.4. Public demands shape the decisions of groups who lobby in rulemaking. If they believe the attentive public is on their side, groups may attempt to reveal this political information to policymakers by launching a mass mobilization campaign. The public response to the campaign depends on the extent that the attentive public is passionate about the issue. Figure 2.4: Incorporating Political Information into Models of Bureaucratic Policymaking Figure 2.4 amends the “Classic Model” of interest group lobbying (Figure 2.3) to incorporate political information about the attentive public. In addition to providing technical information through sophisticated comments, an organization may mobilize supporters. The more support a group has, the more successful this mobilization effort will be. Large-scale engagement may produce several types of relevant political information. The most direct and obvious is the expressed “public opinion” that policymakers observe.16 The causal process visualized in Figure 2.4 may only operate under certain conditions. The success of a mobilizing effort depends on whether a group’s perception of latent public demands (the diagonal arrow between “Latent Public Demands” and “Lobbying Strategy”) reflects the public response to a mobilizing effort (the horizontal arrow between “Latent Public Demands” and “Mass Engagement”). The influence of political information on policy (the arrow between “Political Information” and “Policy Response”) depends on the institutional processes by which agencies receive and interpret information. We may only expect to observe mass mobilization influencing a particular policy only if the mobilization effort was aimed at influencing that policy, rather than using the public comment the period to build organizational membership or power more generally (see Carpenter and Moore (2014)). 2.3 Hypotheses About the Drivers of Mass Mobilization 2.3.1 Types of campaigns The outcomes of mass mobilization depend, in part, on the aims of a campaign. I distinguish group campaigns by which of three distinct aims they pursue: (1) to win concessions by going public, (2) to disrupt a perceived consensus, or (3) to go down fighting. Going public and disrupting a perceived consensus are forms of proactive and reactive outside lobbying, respectively. Here, going down fighting describes any situation where the organization does not expect to influence policy but mobilizes for other reasons. Going public. Coalitions “go public” when they believe that expanding the scope of conflict gives them an advantage.17 As these are the coalitions that believe they have more intense public support, mass engagement is likely to skew heavily toward this side.18 Indeed, Potter (2017a) finds that advocacy group-driven campaigns mobilize far more people on average than industry-driven campaigns. Additionally, many people may be inspired indirectly (e.g., through news stories) or to engage with more effort (e.g., writing longer comments) than people mobilized by the side with less public support. This is important because political information may be especially influential if decisionmakers perceive a consensus.19 Hypothesis 1a: Lobbying coalitions mobilize mass engagement when they perceive the attentive public is on their side, have sufficient resources, and perceive an opportunity to influence policy. The key part of this hypothesis is that mobilizing is correlated with existing public support, what might be called “grass-roots” support. The converse, that organizations mobilize when they have less public support, could also be true. For example, business groups who are already advantaged in low salience rulemaking may decide to leverage their superior resources further to mobilize support to alter a bad reputation or bolster claims that they represent more than their private interest. If mobilization most often takes this “astroturf” form, this would be evidence against Hypothesis 1a and Schattschneider’s argument that it is the disadvantaged who seek to expand the scope of the conflict. The latter parts of Hypothesis 1a regarding sufficient resources and political opportunity are scope conditions. Most organizations that are disadvantaged in low-salience rulemaking also lack resources to launch mass mobilization campaigns. If an organization does not perceive a lobbying opportunity, it would be incorrect to call mobilization a lobbying strategy. Many factors may contribute to perceived political opportunities. For example, Moore (2017) finds that agencies that use high levels of expertise (as defined by Selin (2015)) receive fewer comments, possibly because mobilizing organizations perceive these rules to be less open to influence. Disrupting a perceived consensus. I theorize that when coalitions with less public support mobilize, it is a reaction to their opponents. Because the impression of consensus is powerful, when a coalition goes public, an opposing coalition may countermobilize. Because I theorize that these are coalitions with less intense public support and its aim is prevent a perceived consensus, I expect such campaigns to engage fewer people, less effort per person, and yield a smaller portion of indirect engagement. Hypothesis 1b: When a lobbying coalition with more intense public support mobilizes successfully in response to an opportunity to influence policy, opposing coalitions with less public support are more likely to countermobilize, but with proportionally smaller results. The first part of Hypothesis 1b would be undermined if lobbying organizations with less public support are no more likely to engage in outside lobbying when their opponents do so. While Potter (2017a) found industry groups were no more likely to advocate for rules to be strengthened, weakened or withdrawn, this does not mean that they are no more likely to mobilize when their opponents do so. The second part of this hypothesis, that countermobilization is proportionally smaller, rests on the intuition that the scale and intensity of public engagement are moderated by preexisting support for the proposition that people are being asked to support. It is possible that the “potentially mobilized” segments of the public are unrelated to public support before being contacted by the campaign, for example, if mobilization is driven more by partisan identities than issue preferences. Going down fighting. Finally, campaigns may target supporters rather than policymakers. Sometimes organizations “go down fighting” to fulfill supporters’ expectations. For example, Carpenter et al. (2020) finds that anti-slavery petitions were this type of campaign where “the most important readers of a petition are its signatories.” In the context of notice and comment rulemaking, after a draft policy is published, failing to secure one’s demands is always a loss, so I use “going down fighting” as shorthand for campaigns aimed primarily at fulfilling member, donor, or supporter expectations and related logics that are internal to the organization, including member retention or recruitment (Carpenter and Moore (2014), Carpenter et al. (2020)), fundraising, or satisfying a board of directors. For example, as Figure 2.5 shows, the Sierra Club uses campaigns to collect contact information of supporters and potential members. In this case, given the executive-branch transition between 2010 when the rule was initiated and 2017 when it was delayed, the Sierra Club may have had little hope of protecting methane pollution standards, but for members of the public who wanted to voice their opinion, the Sierra Club created an easy way to do so, as long as users consented to “receive periodic communication from the Sierra Club.” Figure 2.5: The Sierra Club Collects Contact Information Through Mass Mobilization Campaign While such campaigns may engage many people, they are unlikely to affect policy or to inspire countermobilization. I expect such campaigns to occur on rules that have high partisan salience (e.g., rules following major legislation passed on a narrow vote), rules that propose large shifts on policy issues dear to member-funded public interest groups, or rulemaking started shortly after presidential transitions when executive-branch agendas shift more quickly than public opinion. When a lobbying coalition with more intense public support successfully mobilizes for reasons other than influencing policy, opposing coalitions with less public support are not more likely to countermobilize. Going public and going down fighting may be difficult to distinguish in the observed public response. Indeed, members of the public may poorly understand the different chances of success in each case. However, lobbying organization do likely know their chances of success and should thus invest less in sophisticated insider lobbying under the going down fighting strategy. By identify cases where coalitions engage in large public campaigns without corresponding investment in sophisticated lobbying, I can assess whether countermobilization and is indeed less likely in these cases. Table 2.1 specifies the general pattern of engagement suggested by each of the three reasons behind mass-comment campaigns. Table 2.1: Observable Differences in Lobbying Strategies Inside lobbying (eg., technical information provided) Outside lobbying (e.g., the number of comments from a public pressure campaign) “Normal” lobbying High None “Going public” High High “Disrupting consensus” High Low “Going down fighting” Low High As Table 2.1 suggests, the relevant statistic distinguishing patterns is the relative number of each type of comment on each side on a given rulemaking docket. Even among rules targeted by campaigns, salience varies significantly and thus “high” and “low” numbers of comments will differ across rules. Importantly, even campaigns that achieve very low public response rates appear in these data. Because campaigns aim to collect thousands of comments, it is implausible that even the most unpopular position would achieve no supportive responses. For example, Potter (2017a) found Poultry Producers averaging only 319 comments per campaign. While this is far from the Sierra Club’s average of 17,325 comments per campaign, it is also far from zero. 2.3.1.1 Public and private goods. While coalitions may form around various material and ideological conflicts, those most likely to be advantaged by going public or going down fighting are public interest groups—organizations primarily serving an idea of the public good rather than the material interests of their members.20 Thus, I theorize that mass mobilization is most likely to occur in conflicts of public versus private interests or public versus public interests (i.e., between coalitions led by groups with distinct cultural ideals or desired public goods), provided they have sufficient resources to run a campaign. If true, one implication is that mass mobilization will systematically run counter to concentrated business interests where they conflict with the values of public interest groups with sufficient resources to mobilize. Hypothesis 1c: Public interest group coalitions mobilize more often than business-driven coalitions. Hypothesis 1c posits a conditional logic in the decision to mobilize. If resources purely determined outside lobbying, business-driven coalitions would often dominate, as they do elsewhere. However, I argue, because outside lobbying can alter the decision environment, those who have the advantage in the usual rulemaking process (where a more limited set of actors participate) have little incentive to expand the scope of the conflict. 2.4 Types of Public Engagement I classify supporters into three types that help describe key pieces of political information. I illustrate these types in the context of public comments. Comments that are exact copies of a form letter are akin to petition signatures from supporters who were engaged by a campaign to comment with minimal effort. Commenters that also take time to add text indicate more intense preferences. Finally, commenters who express solidarity in similar but distinct phrases indicate they were engaged indirectly, perhaps by a news story or a social media post about the campaign, as campaign messages spread beyond those initially targeted.21 Because the success of a mobilization effort is moderated by public support, broader public interest group coalitions ought to mobilize more people, more effort per person, and more people indirectly for the same amount of mobilization effort (e.g., spending or solicitations). Public interest group coalitions mobilize more successfully than business-driven coalitions. Indicators of success include (1) the number of comments supporting a coalition (2) the effort per comment (3) the number of comments mobilized indirectly. The size of each group thus offers political information to policymakers, including coalition resources, the intensity of sentiment, and the potential for conflict to spread. The first two types signal two kinds of intensity or resolve. First, they show the mobilizers’ willingness to commit resources to the issue. Second, costly actions show the intensity of opinions among the mobilized segment of the public (Dunleavy 1991). The number of people engaged by a campaign is not strictly proportional to an organization’s investment. The less people care, the more it costs to mobilize them. The third type indicates potential contagion. Indications that messages spread beyond those initially targeted may be especially powerful (Kollman 1998). Information about organizational resolve, the intensity of public demands, and contagiousness are thus produced, but such political information will only influence decisions if these signals are processed in a way that captures this information and relays it to decisionmakers. These organizational processes may vary significantly across agencies. 2.5 Methods: Measuring Public Pressure and Political Information In this section, I develop methods to attribute mass comments to the campaigns that mobilized them and measure the intensity of preferences expressed. To link individual comments to the more sophisticated lobbying efforts they support, I use textual similarity to identify clusters of similar comments, reflecting formal and informal coalitions. Comments with identical text (if any) indicate which groups and coalitions ran a mass comment campaign. Within each campaign, I measure the intensity and potential for the movement to grow. To measure intensity, I examine the ratio of high-effort and low-effort comments. To measure the potential to grow, I measure the number of comments mobilized indirectly by the campaign (i.e., those that support a campaign but do not include text provided by the campaign). The result is several new measures of participation in bureaucratic policymaking. 2.5.1 Data. I collected a corpus of approximately 70 million comments via the regulations.gov API. About 50 million of these comments are on proposed rules (over 16,000 proposed rules from 144 agencies from 2005 to 2018). I then linked these comments to other data on the rules from the Unified Agenda and Office of Information and Regulatory Affairs Reports on draft rules sent to them for review. Summary statistics for these data are available in the Appendix. 2.5.2 Who lobbies? Unfortunately, metadata on the authors of comments and their organizational affiliations are inconsistent and incomplete. As this information is key to identifying influential actors, improving these data was a significant data-organization task. 2.5.2.1 Mobilizing organizations. Through an iterative combination of automated search methods and hand-coding, I identify organizations for over 40 million comments, including all organizations responsible for mobilizing 100 or more comments with repeated text–either identical text or partially unique texts that contain shared language. I then searched comment texts for mentions of these organizations’ names to complete missing information on the mobilizing organization. The top 100 mobilizing organizations each mobilized between 55 thousand and 4.2 million comments. Figure 2.6 shows the top organizers of comments posted to regulations.gov. Figure 2.6: Top mobilizers of comments posted to regulations.gov 2.5.3 Who lobbies together? Having identified who is participating in rulemaking, the next step is to determine who is lobbying together. Studies of rulemaking stress the importance of coalitions (J. W. Yackee and Yackee 2006, Dwidar2019). Scholars have measured coalitions of organized groups but have yet to attribute citizen comments to the coalition that mobilized them. 2.5.3.1 I identify coalitions using text re-use and clustering methods. I identify comments that are not identical but share a 10-word (or “10-gram”) string using a moving window function looping over each possible pair of texts to identify matches.22 When actors sign onto the same comment, it is clear that they are lobbying together. However, various businesses, advocacy groups, and citizens often comment separately, even when they are aligned. Thus, in addition to mapping text re-use, for rules with a large number of comments, I use statistical models of text to classify comments into coalitions. I cluster documents by the frequency with which they use different words. Being classified together does not mean that the documents all address exactly the same distribution of substantive issues, just that they use similar words relative to the full set of documents. I start by modeling all comments on each rule (collapsing identical comments to one document) with two and three clusters, which I then inspect to see how well the comments of named organizations were classified. If the two cluster model most sensibly describes the conflict, I label these clusters “pro” and “con” If the three-cluster model more sensibly describes the conflict, I label these clusters as “pro, con, other.” If neither fits well, I increase the number of clusters as needed. Figure 2.7: K-means clustering fails to capture coalitions when nearly all comments oppose a regulation The asymmetry in expressed support for most rules presents challenges for unsupervised clustering because much of the variation in comment texts is within-coalition variation. For example, one of the most common clustering methods, k-means clustering, often captures within-coalition variation. Figure 2.7 shows k-means clusters based on a normalized measure of word frequency (term-frequency/inverse-document-frequency) compared to two principal components of variation. Neither k-means nor principal components analysis is well suited to identifying the small number of comments supporting the Park Service’s proposed restrictions on protests in Washington DC. Two strategies may improve clustering. First, even partial text re-use generally indicates that comments belong to the same coalition. For example, as seen at the top of Figure 2.7, models may be restricted to cluster the large number of comments beginning with “As a citizen who has frequently participated” in the same coalition even if they go on to add different personal anecdotes about why protest rights are important to them. Thus, clustering methods could be restricted to group partially copied texts, as well as entirely copied texts. Second, Bayesian mixture model may better recover pro and con clusters, especially with strong priors comments using positive and negative sentiment words belong together. 2.5.4 Measuring the volume, intensity, and potential contagion of public engagement. I measure variation in engagement in three ways, corresponding to the three types of comments described above. Volume. First, I measure the total number of comments on the rule. As commenting results from multiple processes: a coalition deciding to lobby at all, a coalition deciding to mobilize, and response to the campaign the distribution contains many cases where groups may have had success mobilizing but never reached the choice of whether to mobilize or not. Perhaps they were unaware of the draft rule. Once the decision to mobilize has been reached and made, the response to mobilizing is a count process. Thus, I expect the count of comments across rules to follow a zero-inflated negative binomial distribution. Effort. I measure effort per comment by the number of words people write, omitting any to text longer than ten words that is not unique, usually because a mobilizing organization provided it. For example, the Sierra Club mobilized more than 47,710 people to submit exactly the same text on the delay of the methane pollution rule, but 7,452 people also took the time to write a personalized comment in addition to the text provided (see Figure 2.5). However, we may not observe people who have low levels of passion for the issue because they either do not cross the effort threshold required to comment or opt to write nothing more than the form letter. Thus, while effort measured by the number of words people write may be normally distributed, I assume that the low end of the observed distribution is truncated. Contagion. Mass-comment campaigns have wildly different results. Some submit a clean 10,000 copies of (signatures on) the same comment. Others “go viral”—inspiring a mess of further engagement where the original messages are translated through social media posts and news stories. To identify people who were plausibly mobilized indirectly by a campaign, I count the number of people who use a similar distribution of words to that of the form letter but fewer than ten words matching any other comment. This is a regular count process. 2.6 Results: Patterns of Public Engagement in Rulemaking 2.6.1 Most comments result from mass-comment campaigns. Figure 2.8 shows all comments posted on regulations.gov over time by whether they are exact or partial copies of another comment or not. I call comments that have between 2 and 99 identical copies, “medium batch” because such comments may reflect coordinated efforts among interest groups that do not include a public pressure strategy that involves mobilizing ordinary people. Even relatively unsuccessful public pressure campaigns yield far more than 99 comments. Comments that have either 100 or more identical copies or were uploaded in bulk batches of at least 100 are then “mass comments” that were certainly mobilized by a public pressure campaign. Figure 2.8 shows that public pressure campaigns mobilize the vast majority of comments. Over 80% of the 48 million comments on proposed rules posted to regulations.gov were mobilized by just 100 organizations. In other words, most comments are from ordinary people mobilized by a few public interest organizations. Figure 2.8: Comments on Draft Rules Posted to Regulations.gov 2006-2018 The right pane of Figure 2.8 shows results from a sample of several million comments for which I have digitized texts. Many of these comments appear to support proposed agency rules. A rough measure of support (whether the comment text includes \" support \" or \" oppose “) shows that many more comments mention support, until 2018 when there is a fairly dramatic reversal in the share of comments mentioning”support \" compared to those mentioning “oppose” (Figure 2.8. This may be a function of the changing regulatory agenda due to the change in presidential administration. However, support and oppose are not used in all comments and do not always indicate support for a rule. 2.6.2 Most comments occur on a small number of salient rules. Approximately one-third of public comments posted to regulations.gov were received on just ten regulations shown in Figure 2.9. Figure 2.9: Top 10 Dockets Receiving the Most Comments on regulations.gov and the top 20 Mobilizers 2.6.3 Is civic engagement resulting from public pressure campaigns better understood as “astroturf” or “grassroots” participation? In short, I find much more evidence of grassroots participation than astroturf participation. 2.6.4 A coalition of public-interest organizations mobilize most comments. As Figure 2.9 shows, the most prolific mobilizers are environmental groups. On five out of the top ten dockets (here including rulemaking and non-rulemaking dockets), a similar coalition of groups mobilized the majority of public comments. In part, this is because the Environmental Protection Agency produces a large share of the substantive rules posted to regulations.gov. However, it is notable that, on the top ten dockets, 19 of the top 20 mobilizers generally lobby together. America’s Energy Cooperatives (AEC), an industry association, stands out as the lone mobilizer on behalf of material interest for its members. Notably, it only mobilized significantly on the Clean Power Plan but not on the subsequent Clean Power Plan repeal. If public interest group mobilizing on the Clean Power Plan was an example of “going public” to pressure the Obama administration and then “going down fighting” in the face of the Trump administration’s repeal, industry counter-mobilization responding to the first, but not the second aligns with Hypothesis 1b. If AEC found their policy goals in the Clean Power Plan rulemaking threatened by the political information being generated by environmental groups, it would make sense to devote resources to their own public pressure campaign to disrupt any perceived consensus. Likewise, if AEC was not concerned that environmental group mobilizing would affect the Clean Power Plan repeal, sponsoring a public pressure campaign would be a poor investment. References "],["policy-influence-do-public-pressure-campaigns-influence-bureaucratic-policymaking.html", "Chapter 3 Policy Influence: Do Public Pressure Campaigns Influence Bureaucratic Policymaking? 3.1 Introduction 3.2 Theory 3.3 Testing the Theory 3.4 Results (SIMULATED) 3.5 Results (hand-coded data) 3.6 Conclusion", " Chapter 3 Policy Influence: Do Public Pressure Campaigns Influence Bureaucratic Policymaking? See the preanalysis plan for this chapter here. Abstract I assess whether public pressure campaigns increase lobbying success in agency rulemaking using a mix of hand-coding and computational text analysis methods. To measure lobbying success, I develop computational methods to identify lobbying coalitions and estimate lobbying success for all rules posted for comment on regulations.gov. These methods are validated against a random sample of 100 rules with a mass-comment campaign and 100 rules without a mass comment campaign that I hand-code for whether each coalition got the policy outcome they sought. I then assess potential mechanisms by which mass public engagement may affect policy. Each mechanism involves a distinct type of information revealed to decisionmakers. Of primary interest is the extent to which public pressure campaigns affect agency decisionmakers directly or indirectly through their effects on elected officials’ oversight behaviors. I assess whether legislators are more likely to engage in rulemaking when advocacy groups mobilize public pressure. I then assess congressional oversight as a causal mediator using a subset of rules where I collect and code correspondence from Member of Congress to agencies about proposed agency rules with and without public pressure campaigns. 3.1 Introduction I assess the relationship between the number of public comments and the amount of change between draft and final policy texts. Next, I assess the relationship between the number of people mobilized by each campaign and whether the campaign achieved its policy goals. Finally, I theorize and test four mechanisms by which public input may affect bureaucratic policymaking. Each mechanism involves a distinct type of information that pressure campaigns may relay to policymakers: technical information, information about the likelihood of political consequences, information about the preferences of elected officials, or information about the preferences of the attentive public. Because scholarship on bureaucratic policymaking has focused on the power of technical information, where insider lobbying is most likely to matter and where outside strategies are least likely to matter, political scientists have largely overlooked mass mobilization as a tactic. I find evidence consistent with the observable implications of mass comment campaigns influencing policymaking through \\[non-null results\\] but no evidence that mass engagement affects rulemaking processes or outcomes through \\[null results\\]. 3.2 Theory 3.2.1 Incorporating political information into formal models of rulemaking Formally, political information requires several crucial amendments to existing information-based models of rulemaking. In the most sophisticated model of notice-and-comment rulemaking to date, Libgober (2018) posits a utility function for agency \\(G\\) as \\(u_G(x_F) = \\alpha_0 x_f^2 + \\sum_{i=1}^N \\alpha_i u_i (x_f)\\) where \\(x_f\\) is the spatial location of the final policy, \\(u_i\\) is the preference of a member of the public or “potential commenter” \\(i\\), and \\(\\alpha\\) is a vector of \"allocational bias\"—i.e. how much the agency cares about its own preferences \\(\\alpha_0\\) relative to accommodating the preferences of others \\(\\alpha_{i=1:N}\\). Bureaucrats balance their own idea of their mission against their desire to be responsive. In Libgober’s model, \\(\\alpha\\) is a fixed “taste” for responsiveness to each member of society, so agency decisions simply depend on their answer to the question “what do people want?” Including political information requires two additional parameters related to a second question “why would the agency care?” First, like other lobbying strategies, going public may shift the strategic environment, leading an agency to shift its allocation in favor of some groups and away from others. Let this strategic shift be a vector \\(\\alpha_s\\). Second, campaigns may directly persuade agencies to adjust their allocational bias, for example by supporting claims about the number of people the group represents or the intensity or legitimacy of their policy demands. Let this direct shift be \\(\\alpha_d\\) and immutable taste now be \\(\\alpha_t\\). Having decomposed an agency’s allocative bias into three parts (its fixed tastes, shifting strategic environment, and potential to be convinced), the agency’s utility function is now \\(u_G(x_F) = (\\alpha_{t0} + \\alpha_{s0} + \\alpha_{d0}) x_f^2 + \\sum_{i=1}^N (\\alpha_{ti} + \\alpha_{si} + \\alpha_{di}) u_i (x_f)\\). If, after the comment period, an agency’s strategic environment is unchanged and it remains unpersuaded about which segments of society deserve favor, \\(\\alpha_s\\) and \\(\\alpha_d\\) are 0, and the model collapses to the original information game based on fixed taste. This less plausible when groups go public and expand the scope of conflict. Incorperating political information allows us to begin formalizing intuitions about mechanisms of influence. For example, Libgober (2018) asks “What proportion of commenting activity can be characterized as informing regulators about public preferences versus attempting to attract attention of other political principals?” (p. 29). Adding political information to the model allows us to formalize this question: Under what conditions does the decision to comment depend on an organization’s beliefs about \\(\\alpha_t\\) versus beliefs about \\(\\alpha_s\\)? Empirically, we may often be able to infer that the difference in commenting can be attributed to group \\(i\\)’s beliefs about \\(\\alpha_{si}\\) if the behavior of political principals varies but other observed parameter values are similar across rules at a given agency. Rational-choice explanations of why organizations comment on proposed rules build on an intuition that potential commenters will comment only when the benefits exceed the costs of doing so. This intuition ought to apply to other lobbying strategies such as mass mobilization as well. Adding an additional lobbying strategy into the model described above is straightforward. In Libgober’s model, a potential commenter has negative quadratic preferences centered on their ideal policy \\(p_i\\) and \\(u_i = -(x_f - p_i)^2\\) where \\(x_f\\) is the final policy chosen by the agency. An organization will comment if the cost of doing so is less than the difference between their utility when the agency selects a policy having been informed about the organization’s ideal point \\(p_i\\) versus when the agency selects a policy having made a guess about the organization’s ideal point, \\(z_i\\). If \\(c_i\\) is organization \\(i\\)’s cost of commenting, then \\(i\\) will comment if it expects to be better off providing information than abstaining \\(E[u_i | p_i] &gt; E[u_i | z_i] + c_i\\). Similarly, an organization will go public when it expects that the cost of running a mass mobilization campaign to be less than the difference in utility when the agency selects a policy having been informed about the intensity of broader public preferences \\(p_{public}\\) versus when the agency selects a policy having made a guess about the intensity of the attentive public’s preferences, \\(z_{public}\\). If \\(c_{campaign, i}\\) is organization \\(i\\)’s cost of running a mass mobilization campaign, then \\(i\\) will launch a campaign if \\(E[u_i | p_{public}] &gt; E[u_i | z_{public}] + c_{campaign, i}\\). This suggests that mass mobilization with the aim of influencing policy, i.e. going public, should be more common when agencies are either poorly informed or distant from public opinion and potentially influenced by the types of political information created by mass engagement. Additionally, an organization may comment or run a mass mobilization campaign if it benefits in ways that are independent of policy outcomes. Strategies such as \"going down fighting\" can be incorporated by adding exogenous benefit parameters to the utility function of the potential commenter/mobilizer. Let \\(v_i\\) be the benefit of commenting independent of its effect on the policy outcome, such as pleasing members or to reserving the right to sue. Let \\(w_i\\) be the benefit of running a mass mobilization campaign independent of its effect on the outcome of the policy at hand, such as fulfilling expectations of existing members or recruiting new members. An organizations utility function would then be \\(u_i = -(x - p_i)^2 + v_i + w_i\\). Adding these parameters also resolves a puzzling result of Libgober’s model. Empirically, rules that receive comments do not always change. This result is impossible in a model where bureaucrats only have known fixed tastes and potential commenters only seek changes in policy. For policy seeking organizations to lobby but fail to influence policy requires that they may either be wrong about an agency’s allocative bias or their ability to shift it. Incorporating political information allows change and uncertainty in an agency’s biases. The result of commenting without rule change also becomes possible if commenters are allowed a strategy of “going down fighting” and incentives to do so. 3.2.2 Congressional oversight as a mediator of interest-group influence When George W. Bush replaced Bill Clinton as president, career bureaucrats at the Federal Trade Commission knew that this meant a change in policy priorities. Many rulemaking projects initiated under the Clinton administration were likely to be withdrawn or put on hold. They also knew that the new administration wanted to be perceived as advancing a new policy agenda, not merely undoing Clinton-era regulations. Entrepreneurs within the agency saw a political window of opportunity to initiate a new regulatory agenda aimed at curbing a growing volume of telemarketing calls. This initiative seemed likely to be popular with voters but, even with a supportive president, would be difficult to advance over the objections of the telemarketing industry whose campaign donations had earned them many powerful allies in Congress. Agency officials report being pessimistic about the FTC’s telemarketing effort succeeding over opposition from Congress. When the draft “Telemarketing Sales Rule” (also known as the “Do Not Call” rule) was published, however, public support and engagement were overwhelming. The rule received thousands of supportive comments from frustrated members of the public who were encouraged to comment by advocacy groups like the Consumer Federation of America. Agency officials report that the volume of public response not only encouraged the agency and the administration but, more importantly, “scared off” Members of Congress who the industry was relying on to kill or reverse the rule. Once it became clear that the public was paying attention and sufficiently mobilized to act on the issue, elected officials became much less willing to take unpopular positions supporting industry donors. Instead, Congress ended up codifying the agency’s authority to implement the Do Not Call regulations with legislation the following year. The story of the Do Not Call rule suggests that public engagement in rulemaking may occasionally be influential because it affects the behavior of elected officials who have the power to provide key support or opposition to a proposed rule. Political oversight of bureaucracies has long concerned both practitioners and theorists. Political scientists often model the relationship between elected officials and bureaucrats as a principal-agent problem. For example, an agency may have a preferred policy but, upon observing the preferences of principals, may change the rule or delay its publication. Agencies may do this to avoid political consequences such as having their policies reversed (Potter 2017b) or because they perceive elected officials as representing public demands (Cuéllar 2005). While it is widely accepted that agency officials take the positions of their principals into account, the mechanisms by which this occurs and the empirical conditions for political control are debated. Because I focus on influence in the period between the publication of draft and final rules, I focus on information about principals’ preferences revealed to the agency in this period. Oversight during rulemaking is a form of ex-post control (Epstein and O’Halloran 1994), in this case, after the proposed rule is published. Upon learning the content of a draft rule, an official with power over the agency may choose to signal their demands to the agency. There is an ongoing debate among scholars over how political oversight operates–i.e., how principals’ observable behaviors actually inform agency decisions. McCubbins, Noll, and Weingast (1987) suggest two oversight mechanisms. Principals may proactively attend to agency activities, like a “police patrol,” or they may rely on bureaucrats’ fear of sanction when attentive interest groups alert principals about agency activities, more like a “fire alarm.” Administrative procedures like mandatory public comment periods thus offer opportunities for direct oversight and to be alerted to oversight opportunities (Balla 1998). 3.2.3 Incorporating political information into models of political oversight In addition to interest groups directly alerting elected officials to oversight opportunities as in the “fire alarm” model, the political information signaled by public pressure campaigns may alert elected officials to political risks (like a “warning sign”) or, conversely, to encourage the agency to hold course (like a “beacon”) attracting positive attention and credit claiming opportunities for their oversight work. In the case of the FTC’s “Do Not Call” rule and subsequent legislation, mass engagement functioned more as a “warning” for would-be opponents and a “beacon” for potential allies, effectively enabling and empowering rather than restraining the agency as the classic “fire alarm” concept suggests. Agency officials credit the public support mobilized by mass comment campaigns with the political momentum needed to hold course. Figure 3.1: Incorporating Congressional Oversight into Model of Bureaucratic Policymaking Mass engagement in bureaucratic policymaking may affect the behavior of an agency’s principals because the shadow of public sanction hangs over elected officials (Arnold 1979; Mayhew 2000). Moore (2018) finds that agencies that receive more comments per rule are also subject to more congressional hearings. When the public is more attentive, it is more important for officials to take popular positions and avoid unpopular ones. Thus, when a coalition goes public, especially if it generates a perceived consensus in expressed public sentiments, elected officials ought to be more likely to intervene on their behalf and less likely to intervene against them. 3.2.4 Hypotheses about the relationship between mass engagement and oversight It may be the case that both principals and the majority of commenters hold the same position simply because it is popular. Thus, to assess the “fire-alarm,” “beacon,” and “warning sign” mechanisms, it is important to condition on principals’ existing policy positions and to control for their baseline rates of commenting. I estimate principals’ baseline rates of commenting using legislators’ comments on similar rules that did not receive a mass comment campaign. Hypothesis 2: Elected officials’ advocacy is moderated by mass engagement. \\[hyp:beacon\\] Mass commenting attract oversight from allies. The more comments supporting a position, the more likely principals holding that position are to engage. \\[hyp:warning\\] Mass commenting reduces oversight from opponents. The more comments opposing a position, the less likely principals holding that position are to engage. Hypothesis \\[hyp:beacon\\] implies that \\(\\beta_1\\) is positive and Hypothesis \\[hyp:warning\\] \\(\\beta_2\\) is negative in this statement: Pr(Principal Comments \\(|\\) Principal Position \\(i\\)) \\(\\sim \\beta_0 + \\beta_1\\)Comments supporting \\(i + \\beta_2\\)Comments opposing \\(i\\) If Hypothesis \\[hyp:beacon\\] is correct, it would suggest an addendum to Hall and Miler’s (2008) finding that legislators are more likely to engage in rulemaking when they have been lobbied by a like-minded interest group: When interest groups lobby elected officials to engage in rulemaking, they may be more likely to engage when aligned with the majority of commenters than when opposed to them. If elected officials learn from political information, they will be even more likely to engage when lobbied by a coalition that includes public interest groups running a mass-comment campaign, and less likely to engage when opposed by a large mass comment campaign.23 Alternatively, the effect of mass engagement on political principals may be asymmetric. Mass engagement may only mobilize or only demobilize. For example elected officials may be attracted to oversight opportunities but not dissuaded by mobilization on the other side because they assume their voters share their position. Or, if elected officials are risk adverse, they may avoid engaging in contentious rulemaking processes regardless of the balance of comments. Each of these results would be evidence against hypothesis \\[hyp:warning\\] or \\[hyp:beacon\\] respectively. I thus build on the classic model of political oversight in two ways. First, I suggest that elected officials’ comments are a particularly relevant oversight behavior and a mechanism by which bureaucrats learn and update beliefs about their principals’ demands. Second, I suggest that such oversight behaviors may be affected by public pressure because of the impressions of public opinion (i.e., the political information) it creates. 3.3 Testing the Theory 3.3.1 Data I create an original dataset that combines several sources of data on U.S. federal agency rulemaking. The core data are the texts of draft and final rules and public comments on these proposed rules. This includes all 16 thousand proposed rules from 144 agencies (as defined by regulations.gov) that were open for comment on regulations.gov between 2005 and 2018, that received at least one comment from an organization, and that saw a final agency action between 2005 and 2019. There are over 50 million comments on this set of rules. I scrape draft and final rule texts from federalregister.gov and comments submitted as attachments or by mail from regulations.gov. I retrieve comments submitted directly on regulations.gov and metadata on rules and comments (such as the dates that the proposed rule was open for comment and whether the agency identified the organization submitting the comment) from the regulations.gov API. I add additional metadata on rules (such as whether the rule was considered “significant”) from the Unified Agenda published by the Office of Information and Regulatory Affairs (reginfo.gov). The combined dataset has over 50 million observations of one public or legislator comment on a proposed rule. I attempt to identify the organization(s) that submitted or mobilized each comment by extracting all organization names from the comment text. For comments that do not reference an organization, I am often able to identify organizations with an internet search using the comment’s text. I then identify lobbying coalitions by clustering comments that use similar phrases or word frequencies. Co-signed comments are always assigned to the same coalition. Likewise, form-letter comments are always assigned to the same coalition.24 Because my hypotheses are about the influence of organizations and coalitions, for analysis, I collapse these data to one observation per organization or coalition per proposed rule and identify the main substantive comment submitted by each organization’s staff or lawyers, which are usually much longer than supporting comments like form letters. For hand-coding, I first select a random sample of 100 proposed rules with a mass-comment campaign and then selecting a matched sample of 100 proposed rules without a mass comment campaign. Matching prioritizes, presidential administration, policy area (following Policy Agendas Project coding), rule significance, department, agency, subagency, and proposed rule length, respectively.25 This hand-coded sample is several times larger than leading studies using hand-coding and includes rules with very large and small numbers of comments that previous studies exclude. The full sample is four hundred times larger.26 The most direct way to assess the hypothesis that mass engagement increases lobbying success is to assess the magnitude of the relationship between the number of comments that a coalition mobilizes and its lobbying success. However, public pressure campaigns may only be effective under certain conditions. Thus, I first assess the main relationship and then assess evidence for or against different potential causal pathways of influence. 3.3.2 The Dependent Variable: Lobbying Success The dependent variable is the extent to which a lobbying coalition got the policy outcome they sought, which I measure in three ways. First, on a sample of rules, I hand-code lobbying success for each lobbying coalition, comparing the change between the draft and final rule to each organization’s demands on a five-point scale from “mostly as requested” to “significantly different/opposite than requested.” To do this, I first identify organizational comments. For each organization, I identify the main overall demand and the top three specific demands and the corresponding parts of the draft and final rule texts.27 I then code overall lobbying success and lobbying success on each specific demand for each organization and coalition. Both the overall score and average score across specific demands both fall on the interval from -1 (“significantly different”) to 1 (“mostly as requested”). Second, I use methods similar to automated plagiarism detection algorithms to identify changes between a draft and final rule that were suggested in a comment. Specifically, I count the number of words in phrases of at least ten words that appear in the comment and final rule, but not the draft rule. To do this, I first identify new or changed text in the final rule by removing all 10-word or longer phrases retained from the draft rule. I then search each comment for any 10-word or longer phrases shared with the new rule text and count the total number of shared words in these shared phrases. Finally, I normalize this count of “copied” words across shorter and longer comments by dividing it by the total number of words in the comment. This measure falls between 0 (zero percent of words from the comment added to the final rule) and 1 (100 percent of words from the comment added to the final rule). As a robustness check, I also use the non-normalized version of this variable, i.e. the raw number of “copied” words. Third, I capture a broader dimension of lobbying success by modeling the similarity in word frequency distributions between comments and changes to the rule. New or changed text is identified as described above, except that I also include the rule’s preamble and the agency’s responses to comments. Agencies write lengthy justifications of their decisions in response to some comments but not others. By including preambles and responses to comments, this measure captures attention to a comment’s demands and the extent to which the agency adopts a comment’s discursive framing (i.e. the distribution of words it uses). I us cosign similarity to scale the word frequencies used by each comment relative to those in changes between draft and final rule.28 This measure falls between 0 (no common words) and 1 (exactly the same distribution of words). To assess the performance of these automated methods (text-reuse and word-frequency similarity), I calculate the correlation between these scores and my hand-coded 5-point scale for rules in the hand-coded sample where a final rule was published. As the automated methods apply at the organization-level, coalition scores are those from the lead organization–by default, the organization(s) with the longest comment. At the coalition level, the correlation between hand-coded influence is __ with the text-reuse method and __ with the word-frequency method. 3.3.3 The Main Predictor Variable The number of supportive comments generated by a public pressure campaign (the main variable of interest) is a tally of all comments mobilized by each organization or coalition that ran a mass-comment campaign on a proposed rule. Because the marginal impact of additional comments likely diminishes, the number of comments is logged. This does not include the main substantive comments submitted by an organization’s staff or lawyers. Nor does it include comments that are not affiliated with the organization or coalition. If an organization mobilizes more than 1000 comments or 100 identical comments on a proposed rule, I code that organization, its coalition, and the proposed rule as having a mass comment campaign. Where organizational comments are not supported by a mass comment campaign log mass comments takes a value of 0. 3.3.4 Explanatory variables Other predictors of lobbying success in the models below are the length of the (lead) organization’s comment, whether the coalition lobbies unopposed, the size of the lobbying coalition, and whether the coalition is business-led. Comment length is normalized by dividing the number of words in the comment by the number of words in the proposed rule, thus capturing the complexity of the comment relative to the complexity of the proposed rule. The number and type(s) of organization(s) is an attribute of each coalition (e.g. a business-led coalition with N organizational members). Coalition size is the number of distinct commenting organizations in the coalition (including those that co-sign a comment). For organizations lobbying alone, coalition size is 1. A coalition is unopposed when no opposing organizations comments. I code a coalition as business-led if the majority of commenting organizations are for-profit businesses, or if upon investigation, I find it to be primarily led or sponsored by for-profit businesses.29 3.3.5 Examples of hand-coded lobbying success 2015 Waters of the United States Rule: In response to litigation over which waters were protected by the Clean Water Act, the Environmental Protection Agency and Army Corp of Engineers proposed a rule based on a legal theory articulated by Justice Kennedy, which was more expansive than Justice Scalia’s. The Natural Resources Defense Council submitted a 69-page highly technical comment “on behalf of the Natural Resources Defense Council…, the Sierra Club, the Conservation Law Foundation, the League of Conservation Voters, Clean Water Action, and Environment America” supporting the proposed rule: “we strongly support EPA’s and the Corps’ efforts to clarify which waters are protected by the Clean Water Act. We urge the agencies to strengthen the proposal and move quickly to finalize it…” I coded this as support for the rule change, specifically not going far enough. I also coded it as requesting speedy publication. NRDC makes four substantive requests: one about retaining language in the proposed rule (“proposed protections for tributaries and adjacent waters…must be included in the final rule”) and three proposed changes (“we describe three key aspects of the rule that must be strengthened”).30 These demands provide specific keywords and phrases for which to search in the draft and final rule text. A coalition of 15 environmental organizations mobilized over 944,000 comments, over half (518,963) were mobilized by the four above organizations: 2421,641 by Environment America, 108,076 by NRDC, 101,496 by clean water action, and 67,750 by the Sierra Club. Other coalition partners included EarthJustice (99,973 comments) and Organizing for Action (formerly president Obama’s campaign organization, 69,369 comments). This is the upper tail end of the distribution. This coalition made sophisticated recommendations and mobilized a million people. The final rule moved in the direction requested by NRDC’s coalition, but to a lesser extent than requested–what I code as “some desired changs.”\" As NRDC et al. requested, the final rule retained the language protecting tributaries and adjacent waters and added some protections for “other waters” like prairie potholes and vernal pools, but EPA did not alter the exemptions for ditches and waste treatment systems. Comparing the draft and final with text reuse allows us to count the number words that belong to 10-word phrases that appear in both the draft and final, those that appear only in the draft, and those that appear only in the final. For the 2015 Waters Of The U.S. rule, 15 thousand words were deleted, 37 thousand words were added, and 22 thousand words were kept the same. This means that more words “changed” than remained the same, specifically 69% of words appearing in the draft or final were part were either deleted or added. For this coalition, the dependent variable, coalitions success is 1, coalition size is 15, business coalition is 0, comment length is 69/88, 0.78, and log mass comments is log(943,931), 13.76. 2009 Fine Particle National Ambient Air Quality Standards: In 2008, the EPA proposed a rule expanding air quality protections. Because measuring small particles of air pollution was once difficult, measurements of large particulates were allowed as a surrogate measure for fine particles under EPA’s 1977 PM10 Surrogate Policy. EPA proposed eliminating this policy, thus requiring regulated entities and state regulators to measure and enforce limits on much finer particles of air pollution. EPA received 163 comments on the rule, 129 from businesses, business associations such as the American Petroleum Institute and The Chamber of Commerce, and state regulators that opposed the rule. Most of these were short and cited their support for the 63-page comment from the PM Group, “an ad hoc group of industry trade associations” that opposed the regulation of fine particulate matter. Six state regulators, including Oregon’s, only requested delayed implication of the rule until they next revised their State Implementation Plans (SIPs) for Prevention of Significant Deterioration (PSD). EarthJustice supported the rule but opposed the idea that the cost of measuring fine particles should be a consideration. On behalf of the Sierra Club, the Clean Air Task Force, EarthJustice commented: “We support EPA’s proposal to get rid of the policy but reject the line of questioning as to the benefits and costs associated with ending a policy that is illegal.” The EarthJustice-led coalition also opposed delaying implementation: “EPA must immediately end any use of the Surrogate Policy – either by”grandfathered\" sources or sources in states with SIP‐approved PSD programs – and may not consider whether some flexibility or transition is warranted by policy considerations.\" The final rule did eliminate the Surrate Policy but allowed states to delay implementation and enforcement until the next scheduled revision of their Implementation Plans. I code this as the EarthJustice coalition getting most of what they requested, but not a complete loss for the regulated coalition. For the PM Group coalition, the dependent variable, coalitions success is -1, coalition size is 129, business coalition is 1, comment length is 63/85, 0.74, and log mass comments is 0. For the State of Oregon’s coalition, the dependent variable, coalitions success is 2, coalition size is 6, business coalition is 0, comment length is 5/85, 0.06, and log mass comments is 0. For the EarthJustice coalition, the dependent variable, coalitions success is 1, coalition size is 3, business coalition is 0, comment length is 7/85, 0.08, and log mass comments is 0. 3.3.6 Limitations The two main limitations of this design both bias estimates of public pressure campaign influence toward zero. First, lobbying success may take forms other than changes in policy texts. Agencies may speed up or delay finalizing a rule, extend the comment period, or delay the date at which the rule goes into effect. Indeed, commentors often request speedy or delayed rule finalization, comment period extensions, or delayed effective dates. I capture these potential outcomes in my hand-coding but not in the two automated methods, which apply only to observations with a final rule text. Likewise, there there is no change between draft and final rule, both automated methods necessarily record lobbying success as 0, even if a comment asks an agency to publish a rule without change.31 Second, bureaucrats may anticipate public pressure campaigns when writing draft rules, muting the observed relationship between public pressure and rule change at the final rule stage of the policy process. 3.3.7 Modeling the direct relationship For all three measures of lobbying success, I assess the relationship between lobbying success and mass comments by modeling coalition \\(i\\)’s lobbying success, \\(y_i\\) as a combination of the relative length of the (lead) organizations comment, whether the coalition is unopposed, the coalition’s size, whether it is a business coalition, and the logged number of mass comments. I estimate OLS32 regression: \\[ y_i = \\beta_0 + \\beta_1 log(comments_i) + \\beta_2 length_i + \\beta_3 unopposed_i + \\beta_4 size_i + \\beta_5 business_i + \\epsilon_i \\] 3.3.8 Modeling mediated relationships To estimate mediated effects, I estimate the average conditional marginal effect (ACME) and the proportion of the total effect attributed to mediation through congressional support (comments or other communication from Members of Congress supporting the coalition’s position on the proposed rule). As developed by Imai et al. (2010), this involves first estimating a model of the proposed mediator as a combination of covariates, \\(X\\) (length, unopposed, size, and business) and then the outcome as a combination of the mediator, congressional support, and covariates, \\(X\\). Mediator model: \\[ congressional\\ support_i = \\beta_0 + \\beta_1 log(comments_i) + \\beta_{2-n} X_i + \\epsilon_i \\] Outcome model: \\[ y_i = \\beta_0 + \\beta_1 log(comments_i) + \\beta_2 congressional\\ support_i + \\beta_{3-n} X_i + \\epsilon_i \\] 3.3.9 A Census of Comments from Members of Congress in Agency Rulemaking Through an iterative combination of automated search methods and hand-coding, I identify the elected official or organization that submitted each comment. Figure 3.2 shows the number of comments from members of Congress received during rulemaking by a sample of federal agencies. Oversight letters are frequently co-signed by multiple members from the Senate, House, or both chambers. Figure 3.2: Number of Letters from Members of Congress Received During Rulemaking per Year To assess the hypothesis that mass engagement affects the engagement of political principals, I examine the relationship between mass commenting and the behavior of members of Congress, while attempting to control for other reasons that members of Congress may comment on a proposed rule. The bold arrow in figure \\[fig:causal-principals-test\\] indicates the key relationship that I test in this step. I aim to test the relationship between mass public engagement and engagement from members of Congress, who may receive information about public opinion from mass engagement. Figure 3.3: The Relationship Between Public Pressure and Congressional Oversight I measure the dependent variables—legislator attention and support—in several ways. First, I count the number of times members of Congress engage the agency across rules and before, during, and after comment periods on rules where lobbying organizations did and did not go public. By engaging the agency, I mean that members of Congress raise a rule in personal correspondence or comments that members send to the agency. I then code each contact from the member of Congress and each coalition lobbying on the rule on the same three-point scale: are they asking for the rule to go further, be scaled back, or published as-is. This is similar to other hand-coding approaches to policy demands. Next, I use text analysis to compare the sentiment and rhetoric (phrases and word frequencies) used by legislators to the language used by each coalition. 3.3.10 Models testing the relationship between mass engagement and congressional oversight There are several ways to test for a relationship between mass engagement and engagement by Members of Congress. The key explanatory variables of interest are the measures of mass engagement created in step 1 (how many and what types of comments). For simplicity, in the equations below, I only include measures related to the number of comments. Thus \\(\\beta_0\\) is the estimate for a rule with no public comments. In Model 1, the dependent variable is the total number of comments from Members of Congress on the rule: \\(Y\\) = Total comments from Congress \\(\\sim\\) zero-inflated negative binomial, with one observation per rule. Let \\(x\\) be the the total number of public comments. \\[\\begin{aligned} Y \\sim \\beta_0 + \\beta_1x\\end{aligned}\\] In Model 2, the dependent variable is the number of comments from Members of Congress on the rule that support the coalition or organizations in the coalition: \\(Y_i\\) = Total comments from Congress supporting coalition \\(i\\) \\(\\sim\\) negative binomial, with one observation per coalition per rule. Let \\(x_i\\) be the total number of public comments supporting coalition \\(i\\). \\[\\begin{aligned} Y_i \\sim \\beta_0 + \\beta_1 x_i\\end{aligned}\\] In Model 3, the dependent variable is the share of Congressional comments supporting the coalition: \\(Y_i\\) = Share of Members of Congress supporting coalition \\(i\\) \\(\\sim\\) beta, with one observation per coalition per rule. Let \\(z_i\\) be the share of public comments supporting coalition \\(i\\). \\[\\begin{aligned} Y_i \\sim \\beta_0 + \\beta_1 z_i\\end{aligned}\\] 3.4 Results (SIMULATED) SIMULATED DATA AND RESULTS FROM PREANALYSIS PLAN WILL BE MOVED TO AN APPENDIX 3.4.1 Simulated Data To illustrate my planned analysis, I simulate data for each variable described above. Dependent variable: Coalition success is drawn from a descrete distribution {-1, -.5, 0, .5, 1}. Explanatory variables: Coalition size (a count) is drawn from a Poisson distribution. Business colation is binomial. In reality, business coalitions are more common than non-business coalitions, but here I estimate a balanced sample. I set rule pages constant at 85 and draw comment lengths from a Poisson distribution. While in reality, less than one percent of coalitions lobbying in rulemaking opt for a mass-comment campaign, I aim to gather a balanced sample, so half of the simulated data are assumed to have no mass comment campaign (comments = 1, log(comments) = 0) and the other half have a number of comments drawn from a Zero-Truncated Poisson distribution, which is then transformed to a log scale. Table 3.1 shows ten rows of simulated data. Table 3.1: Simulated data rule_id coalition_id coalitions coalition_unopposed coalition_success coalition_size coalition_business comment_length comments cong_support 1258 40 2 1 -0.5 4 0 11.8 1 0 1123 1235 2 1 -0.5 7 1 9.4 1 5 1368 118 2 1 0.5 16 0 8.2 1 0 690 584 1 0 0.5 11 1 14.1 20097 1 826 936 1 0 1.0 24 1 14.1 33186 6 390 1317 1 0 -0.5 3 1 8.2 128703 0 1056 146 2 1 0.5 7 1 12.9 190945 0 1007 1014 2 1 -1.0 20 1 14.1 1 1 201 1966 1 0 0.5 3 0 12.9 1 9 1478 421 2 1 0.0 6 1 5.9 1 0 3.4.2 Simulated Results Unsurprisingly this model yields no significant results (Figure 3.4, Table 3.2). With lobbying success as the dependent variable, the coefficient on the main variable of interest would be interpreted as a \\(\\beta_{logmasscomments}\\) increase in the five-point influence scale of lobbying success for each one-unit increase in the logged number of comments. Figure 3.4: OLS model of coalition lobbying sucess with simulated data To assess congressional support as a mediator in the influence of public pressure campaigns on rulemaking, I estimate the average conditional marginal effect (ACME, conditional on the number of comments from Members of Congress) and average direct effect (ADE) of mass comments using mediation analysis. Model 3 in table 3.2 replaces the dependent varible (lobbying success) with the mediator variable (the number of supportive members of Congress). Table 3.2: Lobbying success and congressional support with simulated data 1 2 3 Dependent Variable Lobbying Success Lobbying Success Members of Congress in Coalition (Intercept) 0.072 0.070 2.083*** (0.059) (0.059) (0.308) log(comments) 0.000 0.000 0.005 (0.002) (0.002) (0.013) comment_length -0.002 -0.002 0.002 (0.004) (0.004) (0.020) coalition_business -0.035 -0.035 -0.054 (0.030) (0.030) (0.157) coalition_size 0.003 0.003 0.005 (0.002) (0.002) (0.011) coalition_unopposed 0.001 0.001 0.049 (0.027) (0.027) (0.143) cong_support 0.001 (0.004) Num.Obs. 2000 2000 2000 R2 0.002 0.002 0.000 R2 Adj. 0.000 -0.001 -0.002 AIC 3702.1 3704.0 10322.9 BIC 3741.3 3748.8 10362.1 Log.Lik. -1844.058 -1844.014 -5154.433 F 0.870 0.739 0.122 * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01 The average effect of the logged number of comments, conditional on letters from members of congress (the ACME) is 0, with a p value of 0.94. The average direct effect (ADE) of the logged number of comments on lobbying success is 0, with a p value of 0.91 The Total Effect of a one-unit increase in the logged number of comments is 0, with a p value of 0.9. 0 of this is mediated through mobilizing congressional attention (p-value = 0.98). 3.5 Results (hand-coded data) IN PROGRESS Currently, these data only include rules where there was a mass-comment campaign, which likely explains why business coalitions are less successful than public interest coalitions. I anticipate the sign on that coeficient to be posive in the sample of rules that did not see a mass comment campaign. The contentious nature of this sample also means that there is no variation the coalition_unopposed variable (no coalitions in the sample with mass comment campaigns lobbied unoppossed). 3.5.1 Hand-coded Data Dependent variable: Coalition success is the mean of hand-coded lobbying success on a five-point scale ({-2, -1, 0, 1, 2}, recoded to {-1, -.5, 0, .5, 1} for more straightforward model interpretation). Explanatory variables: Coalition size (a count) is the number of organizations lobbying on the rule. Business colation is binomial. Comments is the total number of comments (including mass comments) mobilized by members of the coalition, which I transform to a log scale for modeling. Table 3.3 shows ten rows of coded data, summarized at the coalition level. Table 3.3: Coded data docket_id coalition_id coalition_comment coalition_unopposed cong_support coalition_size coalition_business coalition_success comments CFPB-2016-0025 70 TRUE FALSE 0 18 TRUE -0.6428571 18 CFPB-2016-0025 19 CUNA, CCUL FALSE 0 5 TRUE 0.8000000 5 CFPB-2019-0006 70 TRUE FALSE 0 79 TRUE -1.1176471 79 CFPB-2019-0006 70 TRUE FALSE 0 79 FALSE -1.1176471 79 DEA-2018-0005 33 HSCA FALSE 0 9 FALSE -1.7777778 9 DEA-2018-0005 4 AMA FALSE 0 2 FALSE 2.0000000 2 DO-2007-0015 103 TRUE; other banks FALSE 0 3 TRUE 0.6666667 3 DO-2007-0015 111 TRUE;Greyhound racing industry FALSE 0 1 TRUE 1.0000000 1 DOI-2015-0005 64 SUPPORT AND ASSIST FALSE 0 11 FALSE 2.0000000 11 DOI-2015-0005 8 BLANKET CREW FALSE 0 11 FALSE 2.0000000 11 FEMA-2016-0003 58 Pew FALSE 0 223 FALSE -1.8918919 2982 FEMA-2016-0003 34 IAEM-USA FALSE 0 23 FALSE 2.0000000 23 MSHA-2011-0001 55 OIAA FALSE 0 1 TRUE -2.0000000 1 MSHA-2011-0001 77 TRUE-EP Minerals FALSE 0 1 TRUE -2.0000000 1 NPS-2018-0007 70 TRUE FALSE 0 35 TRUE 1.9687500 35 NPS-2018-0007 70 TRUE FALSE 0 35 FALSE 1.9687500 35 USCBP-2007-0064 22 EBAA FALSE 0 5 FALSE -1.2000000 5 USCBP-2007-0064 6 BBP FALSE 0 20 FALSE -1.2000000 20 USCG-2010-0990 49 NMMA FALSE 0 4 FALSE 2.0000000 4 USCG-2010-0990 44 NBF FALSE 0 2 FALSE -2.0000000 2 3.5.2 Results The results of this model (Figure 3.5, Table 3.4) show that ________. With lobbying success as the dependent variable, the coefficient on the main variable of interest would be interpreted as a \\(\\beta_{logmasscomments}\\) increase in the five-point influence scale of lobbying success for each one-unit increase in the logged number of comments. Figure 3.5: OLS model of coalition lobbying sucess with hand-coded data To assess congressional support as a mediator in the influence of public pressure campaigns on rulemaking, I estimate the average conditional marginal effect (ACME, conditional on the number of comments from Members of Congress) and average direct effect (ADE) of mass comments using mediation analysis. Model 3 in table 3.4 replaces the dependent varible (lobbying success) with the mediator variable (the number of supportive members of Congress). Table 3.4: Lobbying success and congressional support 1 2 3 Dependent Variable Lobbying Success Lobbying Success Members of Congress in Coalition (Intercept) 0.262 -0.028 0.074 (0.220) (0.419) (0.059) log(comments) 0.428** 0.372 -0.013 (0.181) (0.242) (0.035) coalition_businessTRUE -0.953*** -0.011 -0.062 (0.288) (0.449) (0.064) coalition_size -0.025** -0.023** 0.000 (0.010) (0.011) (0.002) coalition_unopposedTRUE NA NA NA () () () cong_support 1.778* (1.027) Num.Obs. 130 50 50 R2 0.148 0.142 0.021 R2 Adj. 0.128 0.066 -0.043 AIC 489.5 182.9 -12.1 BIC 503.8 194.4 -2.6 Log.Lik. -239.752 -85.443 11.073 F 7.294 1.861 0.327 * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01 Mediation analysis will require adding cases where coalitions lobbied unopposed, which we are much more likely to see in the sample of rules without mass comments. The average effect of the logged number of comments, conditional on letters from members of congress (the ACME) is 0, with a p value of 0.94. The average direct effect (ADE) of the logged number of comments on lobbying success is 0, with a p value of 0.91 The Total Effect of a one-unit increase in the logged number of comments is 0, with a p value of 0.9. 0 of this is mediated through mobilizing congressional attention (p-value = 0.98). 3.5.3 Preliminary findings I find that more public pressure correlates with more congressional oversight. This includes comments from legislators both for and against proposed rules. For example, when the Department of the Treasury published draft rules implementing the Unlawful Internet Gambling Act of 2006, the proposal generated unusually high levels of public attention. As a result, two bipartisan groups of legislators submitted comments on the rule. One, led by the chair of the House Judiciary Subcommittee on Commercial and Administrative Law, raised concerns about the Department’s implementation of the Administrative Procedures Act. The other group of legislators, led by Senator Mike Pence, pushed back against interest-group opposition to the rule and urged the Department to go forward with the implementing rules. This case illustrates several broader trends that I observe. Members of Congress are more likely to engage in oversight when interest groups and the public pay more attention to an issue. When legislators do engage in rulemaking, they often engage on both sides of the issue, raising process or policy concerns that may push agencies in multiple directions. 3.6 Conclusion TODO References "],["the-environmental-justice-movement-and-technocratic-policymaking.html", "Chapter 4 The Environmental Justice Movement and Technocratic Policymaking 4.1 Introduction 4.2 Theory 4.3 Testing the Theory 4.4 Results 4.5 Conclusion", " Chapter 4 The Environmental Justice Movement and Technocratic Policymaking See the working paper version of this chapter here. Abstract Social movements play a critical role in advancing landmark statutes recognizing new rights and social values. Likewise, a lack of movement pressure is a leading explanation for the failure of policy efforts. Yet, we have little systematic evidence about the impact of social movements on policy. To what extent do movements shape the thousands of policies that governments make every year? I examine how social movements affect policymaking by assessing the environmental justice movement’s impact on 25,000 policy documents from 40 U.S. federal agencies from 1993 to 2020. Leveraging a new dataset of 42,000,000 public comments on these policies, I find that when public comments raise environmental justice concerns, these concerns are more likely to be addressed in the final rule. Effect sizes vary across agencies, possibly due to the alignment of environmental justice aims with agency missions., The magnitude of public pressure also matters. When more groups and individuals raise environmental justice concerns, policy texts are more likely to change, even when controlling for overall levels of public attention. These findings suggest that distributive justice claims and levels of public attention and pressure systematically affect policymaking. 4.1 Introduction Social movements like the civil rights movement and the environmental movement are understood to have played a critical role in advancing landmark statutes recognizing new rights and social values. Likewise, a lack of movement pressure is a leading explanation for the failure of policy efforts to address issues like climate change (Skocpol 2013). Yet, we have little systematic evidence about the impact of social movements on modern policymaking. To what extent do movements shape the thousands of policies the government makes every year? I examine how social movements affect policymaking by assessing the environmental justice movement’s impact on 25 thousand policy processes in 40 U.S. federal agencies from 1993 to 2020. Environmental justice concerns focus on unequal access to healthy environments and protection from harms caused by things like pollution and climate change (Bullard 1993). The environmental justice movement illustrates how activists attempt to inject ideas directly into the policymaking process. Systematic data on how policy documents address (or fail to address) environmental justice allow empirical tests of theories about when institutions will address claims raised by activists. I focus on the environmental justice movement because it offers a broad but tractable scope for analysis and illuminates what is at stake in the politics of agency policymaking. Policies have distributive consequences. How policy documents address distributive issues highlights how policy processes construct communities of “relevant” stakeholders and “appropriate” criteria to evaluate policy consequences. Raising environmental justice concerns in policy debates is an example of how social movement organizations mobilize norms and evaluative frameworks that interact with organizational identities, mission, and reputations and, thus, impact policy decisions (Carpenter 2001). Tracing ideas like environmental justice (EJ) through policy processes reveals the mechanisms by which social movements succeed or fail to influence policy. If draft policies do not mention EJ concerns, but activists raise EJ concerns and policymakers then address in the final policy, this may be evidence that public pressure mattered. Likewise, when draft policies do address EJ, if groups comment on it and then policymakers change how the final policy addresses EJ, this may be evidence that public pressure mattered. I assess the impact of the EJ movement qualitatively and quantitatively. Tracing the evolution of EJ analyses through several policy processes shows that the concept is hotly contested and rarely addressed by agencies in ways that activists find acceptable. Activist pressure affected how policies addressed EJ in some cases but failed to affect other policies. Examining all rules published by 40 agencies to regulations.gov between 1993 and 2020, I find that activist mobilization affected policy discourse, even under administrations that were explicitly hostile to their cause. When public comments raise EJ concerns, these concerns are more likely to be addressed in policy documents. Specifically, the number of comments mobilized (both overall and by EJ advocates specifically) is positively correlated with agencies adding language addressing EJ to policies where the draft policy did not mention EJ. When comments raise EJ concerns, sections of policies that do address EJ are also more likely to change. Furthermore, the correlation between EJ activist mobilization and policy changes is largest for agencies with missions focused on “environmental” and distributive policy—the kinds of policymakers we may expect to have institutional and cognitive processes primed to be most responsive to EJ concerns. 4.2 Theory Participatory processes like public comment periods, where policymakers must solicit public input on draft policies, are said to provide democratic legitimacy (Croley 2003; Rosenbloom 2003), new technical information (S. W. Yackee 2006; Nelson and Yackee 2012), and political oversight opportunities (Balla 1998; Mccubbins and Schwartz 1984). While recent scholarship on agency policymaking has shed light on sophisticated lobbying by businesses, we know surprisingly little about the vast majority of public comments on proposed agency rules, which are submitted as part of public pressure campaigns.33 Activists frequently target agency policymaking with letter-writing campaigns, petitions, protests, and mobilizing people to attend hearings, all classic examples of “civic engagement” (Verba and Nie 1987). Yet civic engagement remains poorly understood in the context of bureaucratic policymaking. While practitioners and administrative law scholars have long pondered what to make of activists’ mass comment campaigns, political scientists have had surprisingly little to say about this kind of civic participation. 4.2.1 Social Movements and Policy Change Social movement pressure is a major driver of policy change (Dahl 1956; Piven &amp; Cloward 1977; Lipsky 1968; Tarrow 1994; Andrews 1997; McAdam 1982, 2001; McAdam &amp; Su 2002, McCammon et al. 2011; Cress &amp; Snow 2000; Weldon 2002). This is especially true for policies that redistribute wealth or other social privileges. “From the very beginning, redistributive policies have been associated with social classes and social movements” (Lowi and Nicholson 2015). The organizational forms that mobilize and channel movement pressure (often called social movement organizations by those who study their organization and advocacy organizations or pressure groups by those that study their effects) are essential features of modern politics and lawmaking (Baumgartner and Leech 2001; Coglianese 2001). Conversely, the lack of broad-based support for and movement pressure can be the failure of a policy effort (Skocpol 2013). Scholars have also shown the effect of specific pressure tactics. For example, protests affect policy (Gillion 2013). Petition campaigns can build the organizational capacity to affect policy (Carpenter, n.d.). Activists reshape political parties to enact new policy agendas (Schattschneider 1942; Cohen et al. 2008; Schlozman 2015; Skocpol and Williamson 2016). Studies of social movements tend to explain social movement emergence rather than specific impacts (see reviews by Meyer (2004) and Mcadam (2017)). Reviews of the social movement literature find “limited research on [social movement] influence” (Andrews and Edwards 2004). Studies that do focus on policy influence tend to focus on landmark policies like the Civil Rights Act (Gillion 2013) or case studies of local policy issues (e.g., Bullard 1993; Rochon and Mazmanian 1993). Reviewing the specificity of measures used to assess the impact of advocacy campaigns, Burstein (2020) concludes that “In contrast to those studying opinion and policy, however, researchers studying advocacy and policy rarely discuss levels of specificity.” In addition to measures of advocacy and influence, there are issues with case selection. Leech (2010) argues that the influence of advocacy campaigns is overstated because scholars focus on issues where impact is especially likely–issues characterized by a lot of advocacy and recent or impending policy change. Lowery (2013) voices the opposite concern, that high-salience issues that scholars select are the cases least likely to observe advocacy success. In short, studies often select cases on the dependent variable. While large-scale and longitudinal studies have become more common (Hojnacki et al. 2012), the dependent variable is rarely systematic impact across the thousands of non-landmark policies that governments make every year. To address this gap, I focus on systematic impacts on specific policy documents over time. Specifically, I assess the impact of the environmental justice movement on bureaucratic policymaking. 4.2.2 Technical Information: the Currency of Lobbying Dominant theories of bureaucratic policymaking have little room for social movements and political pressure. Instead, they focus on how agencies learn about policy problems and solutions (Kerwin and Furlong 2011). Leading formal models are information-based models where sophisticated lobbying groups affect policy by revealing information to the agency (Gailmard and Patty 2017; Libgober 2018), and empirical studies support the conclusion that information is the currency of lobbying in rulemaking (Yackee 2012; Cook 2017; Gordon and Rashin 2018; Walters 2019). Agency rulemaking is an especially technocratic and legalistic form of policymaking that explicitly privileges scientific and legal facts as the appropriate basis for decisions. Procedural requirements to consider relevant information create incentives for lobbying groups to overwhelm agencies with complex technical information, making rulemaking obscure to all but the most well-informed insiders (Wagner 2010). As Yackee (2019) notes: “to be influential during rulemaking, commenters may require resources and technical expertise. As Epstein, Heidt, and Farina (2014) suggest, agency rule-writers–who are often chosen because of their technical or policy-specific expertise–privilege the type of data-driven arguments and reasoning that are not common to citizen comments.” (p. 10) The result is that rulemaking is dominated by sophisticated and well-resourced interest groups capable of providing new technical or legal information. Empirical scholarship finds that economic elites and business groups dominate American politics in general (Jacobs and Skocpol 2005; Soss, Hacker, and Mettler 2007; Hertel-Fernandez 2019; Hacker 2003; Gilens and Page 2014) and rulemaking in particular. While some are optimistic that requirements for agencies to solicit and respond to public comments on proposed rules allow “civil society” to provide public oversight (Michaels 2015; Metzger 2010), most studies find that participants in rulemaking often represent elites and business interests (Seifter 2016; Crow, Albright, and Koebele 2015; Wagner, Barnes, and Peters 2011; West 2009; J. W. Yackee and Yackee 2006; S. W. Yackee 2006; Golden 1998; Haeder and Yackee 2015; Cook 2017; Libgober and Carpenter 2018). To the extent that scholars address public pressure campaigns, both existing theory and empirical scholarship suggest skepticism that it matters. For example, Balla et al. (2018) find that “legal imperatives trump political considerations.” 4.2.3 Political Information While social movement organizations do engage in fights over technical reports and scientific studies, the information that activists provide is often more overtly political. Nelson and Yackee (2012) identify political information as a potentially influential result of groups expanding their lobbying coalition. While they focus on mobilizing experts, Nelson and Yackee (2012) describe a dynamic that can be extended to mobilizing public pressure: “strategic recruitment, we theorize, mobilizes new actors to participate in the policymaking process, bringing with them novel technical and political information. In other words, when an expanded strategy is employed, leaders activate individuals and organizations to participate in the policymaking process who, without the coordinating efforts of the leaders, would otherwise not lobby. This activation is important because it implies that coalition lobbying can generate new information and new actors—beyond simply the ‘usual suspects’ —relevant to policy decisionmakers.” I argue that, concerning political information, this logic extends to non-experts in at least two ways. First, mobilizing new actors to participate in the policymaking process may yield information about a policy’s disparate effects. Second, levels of public pressure can be a political resource, allowing groups to change policymakers’ perceptions of their political environment and the political consequences of their decisions. 4.2.3.1 Information About a Policy’s Disparate Effects First, while specific data on disparate impacts of policy may require expertise, anyone can highlight a community of concern and potential distributive effects of a policy. Just as Nelson and Yackee (2012) found regarding the mobilizing of diverse experts, mobilizing diverse communities affected by a policy may introduce new claims from new actors about how the communities that a policy may benefit or harm should be constructed. Indeed, telling a policymaker how a particular set of stakeholders will be affected or what they think is a lobbying tactic. Instead of bolstering scientific claims, such comments focusing on a policy’s disparate impacts bolster political claims about who counts and even who exists as a distinct, potentially affected group that deserves policymakers’ attention. The political construction of policy-relevant groups through the policy process has long interested administrative law scholars. Gellhorn (1972) argues that “individuals and groups willing to assist administrative agencies in identifying interests deserving protection” (p. 403) improve the policy process. Seifter (2016) argues that policymaker’s beliefs about who is lobbying them and who those groups represent ought to be (and likely is) key to how they respond. The politics and outcomes of policymaking depend on how the relevant groups are defined (Lowi 1964). The power of groups to affect policy depends on their recognition by formal and informal institutions. Public comment periods in agency rulemaking are formally more “identity neutral” than policy processes with procedural rights reserved for certain interests (Feinstein 2021). This means that the political construction of relevant groups depends on who participates and the identities they mobilize or claim to represent. As Yackee (2019) and others note, the information costs mean that individuals rarely participate. Instead, groups claim to represent various constituencies. “Because the costs of individualized participation in policy decision making are often excessive, informal representatives are prevalent as a form of participation in agency decisions” (Rossi 1997, pg. 194). Bureaucratic policymaking in the United States is dominated by cost-benefit analysis, which requires defining groups that are benefited or harmed by a policy and may even weigh or prioritize benefits or costs to certain groups. Agencies have many reasons to consider the distributional effects of policy and often do. Thus comments raising distributive concerns provide potentially influential political information. This distributive information raises claims of distributive justice. Public comment periods are celebrated as “a crucial way to ensure that agency decisions are legitimate, accountable, and just” (Bierschbach and Bibas 2012). “Public participation can force agencies to rethink initial inclinations” (Seifter 2016)—for example, which social groups are relevant or deserve special attention. Courts purportedly review policy decisions made through rulemaking with a particular eye toward whether they foster “fairness and deliberation” (United States v. Mead Corp., 533 U.S. 218 2001), though empirical evidence suggests skepticism about the importance of policy processes for judicial review (Judge-Lord 2016). 4.2.3.2 Public pressure as a political resource Second, the number of supporters may matter because it indicates support among relevant communities or the broader public. Again, instead of bolstering scientific claims, perceived levels of public support bolster political claims. Like other forms of political participation, such as protests and letter-writing campaigns, public pressure campaigns provide no new technical information. Nor do they wield any formal authority to reward or sanction bureaucrats. The number on each side, be it ten or ten million, has no legal import for an agency’s response. However, an organization’s ability to expand the scope of conflict by mobilizing a large number of people can be a valuable political resource (Schattschneider 1975). Furlong (1997) and Kerwin and Furlong (2011) identify mobilization as a tactic. The organizations they surveyed believed that forming coalitions and mobilizing large numbers of people were among the most effective lobbying tactics. While Furlong (1997) and Kerwin and Furlong (2011) focused on how organizations mobilize their members, I expand on this understanding of mobilization as a lobbying tactic to include a campaign’s broader audience, more akin to the concept of an attentive public (Key 1961) or issue public (Converse 1964). While scholars have generally distinguished the participation of groups from individual citizens (see Yackee (2019) for a review), “it can be difficult to distinguish an individual’s independent contribution from an interest-group-generated form letter” (Seifter 2016, pg. 1313). I argue that we should view the participation of individuals as a direct result of interest group mobilization. As (Rossi 1997, pg. 194) argues, “individuals are most likely to participate in agency decisions by virtue of their membership in interest groups.” Indeed, nearly all individual comments on proposed policies are mobilized by interest groups (Judge-Lord 2019b). The small number of unaffiliated individuals, disconnected from any organized lobbying effort, can be safely ignored empirically. Interest groups are the unit of analysis, and individual participants are best understood as measuring an amplitude of support for their efforts. Because many politically active groups are “memberless” or run by professionals who lobby with negligible input from their members (Baumgartner and Leech 2001; Skocpol 2003; Schlozman, Verba, and Brady 2012), evidence of an actual constituency is valuable political information. Petition signatures and form letters are among the only ways that a pressure group can demonstrate an engaged and issue-specific constituency on whose behalf they claim to advocate. While lobbying disclosure requirements could provide other information about how well groups represent the constituencies they claim to represent (Seifter 2016), letter-writing campaigns are one of the only strategies currently available to demonstrate issue-specific congruence between the positions of groups and the people they claim to represent (Judge-Lord 2019b). Finally, expanding the scope of conflict by mobilizing public attention to rulemaking may shift policymakers’ attention away from the technical information provided by the “usual suspects” and toward the distributive effects of policy. The “fire alarm” role that interest groups play in the policy process (Mccubbins and Schwartz 1984) may have different effects when sounding the alarm also involves “going public” (Judge-Lord 2019b). 4.2.4 Hypotheses The existing literature on bureaucratic policymaking in general—and EJ advocacy in particular—presents competing intuitions about the effect of EJ activists and the broader public in rulemaking. From the above discussion political information, I distill five hypotheses —three about distributive information and two about public pressure. I posit hypotheses in the direction that these advocacy groups do affect rulemaking while also noting equally plausible intuitions for the opposite conclusions. Because of the general skepticism and empirical work that has found that advocacy groups and public pressure campaigns have little to no effect on rulemaking, I set the empirical bar low: do EJ advocates and public pressure campaigns have any effect at all on policy documents. 4.2.4.1 Distributive Information Hypotheses Distributive Information Hypothesis: Policymakers are more likely to change whether or how policies address distributive justice when commenters raise distributive justice concerns. As discussed above, agency policymakers have incentives to address distributive concerns, especially environmental justice, due to E.O. 12898 and judicial review of compliance with the Administrative Procedures Act. By raising EJ concerns, commenters draw attention to the distribution of policy impacts—who a policy may affect. Asserting definitions and categories of stakeholders and affected groups is one type of policy-relevant information. Repeated Information Hypothesis: Policymakers are more likely to change whether or how policies address concerns when more commenters raise them. Scholarship on lobbying in rulemaking emphasizes the value of repeated information and coalition size (Mendelson 2011; Nelson and Yackee 2012). This implies that the more unique comments raise EJ concerns, the more likely the coalition will influence policy.34 Competing intuitions and other prior studies oppose both the Distributive and Repeated Information Hypotheses. Formal models and empirical scholarship on lobbying in rulemaking emphasize the importance of novel science and technical information—things unknown to agency experts (Wagner 2010). Furthermore, scholarship finds business commenters are influential, and public interest groups are not (J. W. Yackee and Yackee 2006; Haeder and Yackee 2015). Furthermore, policymakers may be more likely to anticipate EJ concerns when they are more salient to interest groups. This would mean that rules where commenters raise EJ concerns may be the least likely to change whether or how EJ is addressed because policymakers are more likely to have already considered these issues and stated their final position in the draft rule. Policy Receptivity Hypothesis: Policymakers that more frequently address concerns like environmental justice will be more responsive to commenters raising those concerns. Bureaucracies are specialized institutions built to make and implement certain kinds of policies based on certain goals and types of facts. Each agency’s distinct norms and epistemic community determine whether policymakers see issues as “environmental” and whether they have disparate impacts that demand consideration of distributive “justice.” Some policymakers may see their policy area as more related to environmental justice than others and thus be more receptive to commenter concerns. The competing intuition to the Policy Receptivity Hypothesis is that policymakers familiar with EJ concerns are the least likely to respond to EJ concerns because they anticipate these concerns—they are not novel to them. If so, agencies that rarely consider EJ may be more easily influenced by commenters who present somewhat novel information and concerns. These policymakers may be less likely to have preempted EJ critiques in the draft policy. 4.2.4.2 Public Pressure Hypotheses General Pressure Hypothesis: Policies are more likely to change when they receive more public attention (e.g., more public comments). If policymakers respond to public pressure, policy should be more likely to change when more people comment on a draft policy. This follows the intuition that policy is most likely to move in high-salience policy processes (Leech 2010). The competing intuition against the General Pressure Hypothesis is again that large numbers of comments indicate policy processes that were already salient before the public pressure campaign. Policymakers anticipate public scrutiny and are thus more likely to have stated their final position in the draft policy. If this is the case, policies with more public comments should be less likely to change. Public attention could also be unrelated to policy change, meaning that policymakers are neither anticipating nor responding to public attention in writing or revising policy documents. Specific Pressure Hypothesis: Policies are more likely to address an issue when they receive more public attention (e.g., more public comments) and at least one comment raises that issue. This hypothesis asserts that the overall level of public attention will condition policy responses to specific claims–it is the interaction between the number of total public comments and at least one of those comments raising EJ concerns that makes policy more likely to address EJ. The competing intuition against the Specific Pressure Hypothesis is again that large numbers of comments indicate high-salience rulemakings where policymakers are more likely to anticipate public scrutiny, including how they did or did not address specific issues like environmental justice. If policymakers anticipate public scrutiny, they may be more likely to preempt EJ concerns and state their final position in the draft policy. 4.3 Testing the Theory 4.3.1 “Environmental Justice” as a Boundary-drawing Tool The politics of environmental justice has several convenient properties for studying the policy impact of social movements. First, discourse around policies framed as “environmental” issues are, unlike issues like civil rights and immigration, inconsistently racialized and, unlike issues like taxes and spending, inconsistently focused on distributions of costs and benefits. This means that policies may or may not be framed in environmental justice terms. Despite policy almost always having disparate impacts, an “environmental” frame often creates a human-environment distinction and shifts attention to non-human objects such as air, water, food, or landscapes and away from the distribution of access to them or protection from them when they are contaminated. By focusing on distributions of costs and benefits, fights over EJ analyses differ from more traditional utilitarian or preservationist analyses. Second, compared to other ideas around which people mobilize, “environmental justice” is a fairly distinctive phrase. Most people who use this phrase share a general definitional foundation. Even attempts to reframe the term (e.g., to focus on class rather than race or jobs rather than health) come about as dialectical moves related to the term’s historical uses. Thus, when “environmental justice” appears in a text, it is rarely a coincidence of words; its appearance is a result of the movement or reactions to it. Third, this phrase appears frequently when the idea is discussed. There are few synonyms. Groups raising equity concerns on “environmental” issues commonly use the phrase “environmental justice.” Those who use narrower, related terms–including the older concept of “environmental racism” and the newer concept of “climate justice”–almost always use “environmental justice” in their advocacy as well. Finally, the term is relevant to rulemaking records in particular because Executive Order 12898 issued in 1994 by President Clinton—“Federal Actions to Address Environmental Justice in Minority Populations and Low-Income Populations”—directs all agencies to consider EJ implications of their actions and policies. Executive Orders from Presidents Obama and Biden and statements from agency heads in every administration have since interpreted and reinterpreted parts of this Order, all with direct implications for rulemaking. This does not mean that all draft or final rules address EJ, but they tend to cite Executive Order 12898 and explicitly discuss environmental justice when they do. For the same reason, commenters who critique draft rules also cite this Executive Order and use this language. Again, this is true both for movement activists and reactionary efforts to redefine the term. While EO 12898 does not itself create a right to sue agencies, courts may strike down rules for failing to comply with procedural requirements of the Administrative Procedures Act (APA) and National Environmental Policy Act (NEPA) if the agency fails to “examine the relevant data” or “consider an important aspect of the problem” (Motor Vehicle Mfrs. Ass’n v. State Farm Mut. Auto. Ins. Co., 1983). This can include an agency’s 12898 EJ analysis: “environmental justice analysis can be reviewed under NEPA and the APA” (Communities Against Runway Expansion, Inc. v. FAA, 2004). The legal salience of the phrase “environmental justice” means that advocates attempting to frame policies in distributive terms tend to use the phrase, and agencies also tend to use it if they respond to these concerns. 4.3.2 Data To examine whether EJ activists and public pressure campaigns shape policy documents, I collect the text of all draft rules, public comments, and final rules from regulations.gov. Then, I select rulemaking documents from agencies that published at least one rule explicitly addressing EJ from 1993 to 2020. This yields over 25,000 rulemaking dockets from 40 agencies. 12,257 of these have both a proposed and final rule.35 Despite E.O. 12898, most rules do not address EJ. Figure 4.1 shows that most draft and final rules (about 90%) do not mention “environmental justice.” Interestingly, the total number of final rules and the percent of the total addressing EJ have remained relatively stable for the period where regulations.gov data are complete (after 2005). From 2006 to 2020, these agencies published between 2000 and 3000 final rules per year, of which between 200 and 300 addressed EJ. Figure 4.1: Proposed and Final Rules by Whether they Address Environmental Justice. Even at the Environmental Protection Agency (EPA), where most policies are clearly framed as “environmental” issues, a consistent minority of rules address EJ. Many agencies that make policy with apparent EJ effects almost never address EJ. These include the Fish and Wildlife Service (FWS), Department of Housing and Urban Development (HUD), National Oceanic and Atmospheric Administration (NOAA), Nuclear Regulatory Commission (NRC), and the Office of Surface Mining (OSM). A majority of rules addressed EJ only in a few years at a few agencies that publish relatively few rules, including the Council on Environmental Quality (CEQ), Army Corps of Engineers (COE), Federal Emergency Management Agency (FEMA), Forest Service (FS), and several Department of Transportation agencies (the Federal High Way Administration (FHWA), Federal Motor Carrier Safety Administration (FMCSA), Federal Railroad Administration (FRA), and Federal Transit Administration (FTA)). Figure 4.2 shows the number of rulemaking projects over time by whether they ultimately addressed EJ at agencies that either published more than ten rules addressing EJ or receiving over 100 comments raising EJ concerns. Figure 4.2: Number of Proposed and Final Rules Addressing Environmental Justice at the Council on Environmental Quality (CEQ), Army Corps of Engineers (COE), Department of Transportation (DOT), Environmental Protection Agency (EPA), Federal Emergency Management Agency (FEMA), Federal High Way Administration (FHWA), Federal Motor Carrier Safety Administration (FMCSA), Federal Railroad Administration (FRA), Forest Service (FS), Federal Transit Administration (FTA), Fish and Wildlife Service (FWS), Department of Housing and Urban Development (HUD), National Highway Transportation Saftey Administration (NHTSA), National Oceanic and Atmospheric Administration (NOAA), Nuclear Regulatory Commission (NRC), and Office of Surface Mining (OSM) 4.3.2.1 Comments Figure 4.3 shows the number of comments on each proposed rule published between 1993 and 2020. Light red circles indicate rules where no commenters raised EJ concerns. Dark blue Triangles indicate rules where they did. The bottom row shows the subset of rules where “environmental justice” appeared in neither the draft nor the final rule. The middle row shows rules where “environmental justice” appeared in the final but not the draft. My first analysis compares these two subsets. The top row shows rules where “environmental justice” appeared in both the draft and final rule. My second analysis assesses change in this subset of rules. Predictably, commenters most often raised EJ concerns on rules in the first row, but many rules that did not initially address EJ still received comments raising EJ concerns. Figure 4.3: Number of Comments on Proposed and Final Rules and Whether Comments Raised Environmental Justice Concerns 4.3.2.2 Interest Groups and Second-order Representation When lobbying during rulemaking, groups often make dubious claims to represent broad segments of the public (Seifter 2016). Thus, to interpret substantive results or the normative import of any findings in this analysis, it is insufficient to know which groups participate. We also need to know who these groups claim to represent and whether those people are actually involved in the organization’s decisions. As Seifter argues: “the expertise a group claims is often based on its ability to convey a particular constituency’s perspective, experience, or concerns…A group that does not have or engage with a membership cannot reliably convey those sorts of constituency-based insights. Moreover, even when a group’s assertions seem independent of a constituency—say, the results of a scientific study—information about second-order participation matters. Understanding the group’s sources, funding, and potential biases is important to assessing the reliability of its information and its contribution to agency expertise” (Seifter 2016, pg. 1306). Examining second-order representation is thus required to assess “what contemporary participation does and does not achieve” (Seifter 2016, pg. 1306)—for example, the extent to which EJ concerns (and any potential policy response) indicate genuine social movement advocacy and influence. Recall that EJ is a contested concept used to evoke different distributive claims by different groups. The prevalence and impact of EJ concerns in the policy process is only meaningful against the backdrop of who exactly is using EJ rhetoric. I examine who is raising EJ concerns in two ways. First, I identify the top organizational commenters such as tribes, businesses, and nonprofits using EJ language and investigate whom these groups represent. Second, for comments where a commenter signed their name, I compare surnames to their racial and ethnic identity propensities in the U.S. Census. Together these two pieces of information allow me to comment on “second-order” representation, i.e., the extent to which public comments are representative of the groups they claim to represent (Seifter 2016). 4.3.2.2.1 Which Organizations Most often Raise EJ Concerns? To explore who raises EJ concerns, I first identify the organization behind each comment through a mix of hand-coding and text analysis. This includes organizational comments on signed letterhead and individuals who use the text of a form letter provided by an organization. I then investigated the top 20 organizations that mobilized the most comments (form letters) mentioning “environmental justice” and all organizations that raised EJ concerns on more than one policy. The top mobilizer of comments mentioning “environmental justice” between 1993 and 2020 was the Sierra Club, with over 340,000 comments mentioning EJ on dozens of rules. The Sierra Club a membership organization whose members pay dues, elect the leaders of local chapters, and have some say in local advocacy efforts. However, its policy work is directed by a more traditional national advocacy organization funded by donations, including over $174 million from Bloomberg Philanthropies that funded several of the public pressure campaigns in these data. The Sierra Club does have a major program arm dedicated to Environmental Justice that works with local partners “to foster the growth of the environmental justice movement so that oppressed communities will find justice and everyone can experience the benefits of a healthy and sustainable future.” The extent to which those individuals have a formal say in the national organization’s lobbying decisions varies across campaigns. The National Board of Directors adopted a statement on social justice in 1993 and principles on environmental justice in 2001. The national website does contain regular Spanish language content. As a federated organization with many local efforts, it is difficult to generalize about second-order representation. The second most prolific organizer of EJ comments was Earthjustice, with over 175,000 comments on many of the same rules that the Sierra Club lobbied on. Earthjustice is primarily engaged in litigation on behalf of environmental causes. Their website boasts 2.2 million supporters, but it is not clear who they are or if they play any role in the advocacy strategy. A search on the website returns 360 results for “Environmental Justice,” with the top results from staff biographies who work on more local or targeted campaigns, such as environmental conditions for the incarcerated. The EJ language used on the main page is relatively vague. For example, “We are fighting for a future where children can breathe clean air, no matter where they live.” (Earthjustice 2017). The website does contain some Spanish language content. The Natural Resources Defense Council is similar to Earthjustice–a national nonprofit funded by donations and focused on litigation–but they also lobby and organize public pressure campaigns, including over 160,000 comments mentioning environmental justice. CREDO Action and MoveOn are more generic progressive mobilizers who lack a systematic focus on EJ issues, but occasionally leverage their vast membership and contact lists to support EJ campaigns led by others. The Alliance for Climate Protection is more of an elite political group founded by former Vice President Al Gore. We Act and Communities for a Better Environment both have environmental justice in their central mission statement. Community leaders founded We Act in Harlem, New York, to advocate against environmental racism and poor air quality (WEACT 2017). Communities for a Better Environment has projects throughout California but is particularly active in Oakland (CBECAL 2017). Much of the content of their website is in both English and Spanish. Both organizations focus primarily on “low-income communities of color” and frame their work primarily in terms of race and class. While both organizations participated in national policymaking, We Act is more focused on communities in Harlem and New York, whereas Communities for a Better Environment casts a broader frame: “CBE’s vision of environmental justice is global–that’s why the organization continues to participate in such international efforts as the Indigenous Environmental Network and the Global Week of Action for Climate Justice” (CBECAL 2017). While not a large portion of EJ comments, companies repeatedly raise research about the unequal impacts of policy to frame these issues as a legitimate but unresolved scientific debate that is not yet conclusive enough to base regulations on, mirroring the way tobacco and fossil fuel companies have emphasized scientific uncertainty in their lobbying efforts.&lt;!-TODO CITE–&gt; For example, in one comment, the Southern Company wrote: “People with lower SES are exposed to almost an order of magnitude more traffic near their homes (Reynolds et al., 2001), and live closer to large industrial sites and are exposed to more industrial air pollution (Jerrett et al., 2001). Legitimate health concerns must be addressed. But adopting standards with a scientific basis so uncertain that health improvement cannot be assured is not sound public health policy.” Like many companies, they claim to represent their customers: “electric generating companies and their customers are expected to bear much of the burden” of regulations (Hobson 2004). Yet, customers have little say in companies’ decisions. Overall, regarding second-order representation, it appears that the groups most often using the language of environmental justice may do so sincerely but generally represent affected communities in a surrogate capacity (Mansbridge 2003). Several groups representing local communities and led by community leaders have participated, but not nearly as often or with the same intensity as the “big greens.” The domination of large advocacy organizations highlights the importance of resources as a condition for lobbying and mobilizing. Not all groups who may benefit from generating political information can leverage it because they lack the resources to fund a campaign or even comment on relevant policies. However, smaller, more member-driven groups may partner with national groups that have more resources to mobilize on their behalf. Finally, a third, much less common type of commenter raises EJ issues to reframe them as ongoing debates and thus undermine their urgency. I call this reason for engaging an attempt to “break a perceived consensus.” In a way, the fact that energy companies felt compelled to acknowledge and question EJ concerns suggests their importance for policy outcomes. 4.3.2.2.2 Commenter Race To estimate the racial distribution of commenters using EJ language, I select commenters who signed with a surname appearing in census records. Figure 4.4 shows a probabilistic racial distribution of commenters who raise EJ concerns in their comments based on the distribution of self-reported racial identities associated with surnames as recorded in the 2010 census.36 I estimate this distribution using the proportion of people with a given surname identified as belonging to each racial category (from this limited set of options). This approach does not assign specific individuals to racial categories. Instead, it represents each commenter as a set of probabilities adding up to 1. The estimated racial distribution of the sample is the sum of individual probabilities. Figure 4.4: Estimated Racial Distribution from Census Surnames of Commenters raising “Environmental Justice” Concerns in Rulemaking Compared to the overall distribution in the 2010 census, this sample of commenters appears to be disproportionately Black and less than proportionately Latinx or Asian, with just slightly fewer Whites relative to the national population. This distribution makes sense given that environmental justice African Americans have led theorizing and activism (Bullard 1993). 4.3.3 Tracing Ideas Through Rulemaking: “Environmental Justice” as a Contested Concept Using an environmental justice frame does not always imply the same communities of concern. Environmental justice emerged from movements against environmental racism, especially the disposal of toxic materials in predominantly Black neighborhoods (Bullard 1993). However, the term quickly took on other meanings, encompassing various marginalized groups. President Clinton’s 1994 Executive Order on Environmental Justice required all parts of the federal government to make “addressing disproportionately high and adverse human health or environmental effects of programs, policies, and activities on minority populations and low-income populations” a core aspect of their mission. This meant considering disproportionate effects of policies by race and income during rulemaking. In 2005, Environmental Protection Agency (EPA) political appointees reinterpreted the Order, removing race as a factor in identifying and prioritizing populations. This move was criticized by activists and two reports by EPA’s own Office of Inspector General. President Obama’s EPA Administrators reestablished race as a factor. They named EJ as one of their top priorities, but they also faced criticism from activists for paying lip service to environmental racism without adequate policy changes. In an October 2017 proposed rule to repeal restrictions on power plant pollution, the Trump EPA acknowledged that “low-income and minority communities located in proximity to [power plants] may have experienced an improvement in air quality as a result of the emissions reductions.” Because the Obama EPA discussed EJ when promulgating the Clean Power Plan rule— stating that “climate change is an environmental justice issue” —, the Trump EPA attempted to reframe rather than ignore environmental justice. The Trump EPA contended that the Obama EPA “did not address lower household energy bills for low-income households [and that] workers losing jobs in regions or occupations with weak labor markets would have been most vulnerable” (EPA 2017). Like regulated industry commenters, these statements frame the distribution of jobs and electricity costs as EJ issues to push back against policies that would equalize the distribution of health impacts from pollution. The central conflict over the role of race in policy analyses is just one of many conflicts that the environmental justice movement has caused to be fought somewhat on its terms. The next section briefly reviews the decades-long policy fight over regulating Mercury pollution to illustrate how these definitional conflicts shape rules and rulemaking. This case and other examples in this article emerged from reading hundreds of rulemaking documents where agencies did and did not respond to comments raising EJ concerns. Their purpose is to assess whether the cases in the quantitative analysis are plausibly what they appear to be: that changes in rule text are, sometimes, causally related to public comments and that non-changes are cases of agencies disregarding comments, not some accident of the data or measures. The qualitative reading also confirmed other key assumptions, such as the fact that advocates do, in fact, use “environmental justice” when they raise distributional concerns, even on many rules that are not about issues traditionally considered “environmental.” 4.3.3.1 The Evolving Distributional Politics of Mercury Pollution Definitions of the public good and minority rights are implicit in most policy documents, including agency rules. The public comment process offers an opportunity to protest these definitions. Protest is one way that marginalized groups can communicate opinions on issues to government officials (Gillion 2013). In the EPA’s Mercury Rules, two definitional issues were decisive. First, as with many forms of pollution, mercury-emitting power plants are concentrated in low-income and non-White communities. Second, some populations consume much more locally-caught freshwater fish, a major vector of Mercury toxicity. Studies inspired by the political controversy around the Mercury Rules found high risk among certain communities, including “Hispanic, Vietnamese, and Laotian populations in California and Great Lakes tribal populations (Chippewa and Ojibwe) active on ceded territories around the Great Lakes” (EPA 2012). Thus the standards that EPA chooses depend on whom the regulation aims to protect: the average citizen, local residents, or fishing communities. This decision has disparate effects based on race and class because of disparate effects based on geography and cultural practices. In December 2000, when the EPA first announced its intention to regulate Mercury from power plants, the notice published in the Federal Register did not address EJ issues, such as the disparate effects of mercury on certain populations; it only discussed anticipated impacts in reference to “the U.S. population” (EPA 2000). When the first draft rule was published, it only discussed the effects of the rule on regulated entities, noting that “Other types of entities not listed could also be affected” (EPA 2002). Commenting on this draft, Heather McCausland of the Alaska Community Action on Toxics (ACAT) wrote: “The amount of methyl-mercury and other bioaccumulative chemicals consumed by Alaskans (especially Alaskan Natives) could potentially be much higher than is assumed… [This could increase] the Alaskan Native mortality rate for babies, which according to the CDC, is 70% higher than the United States average. Indigenous Arctic &amp; Alaskan Native populations are some of the most polluted populations in the world. Global transport &amp; old military sites contaminate us too.” By citing the CDC, McCausland’s comment provided both technical and distributive information. As allies mobilized, public pressure mounted to address the disparate impacts of mercury levels. After receiving hundreds of thousands of comments and pressure from tribal governments and organizations, a revised proposed rule echoed McCausland’s comment noting that “Some subpopulations in the U.S., such as Native Americans, Southeast Asian Americans, and lower-income subsistence fishers may rely on fish as a primary source of nutrition and/or for cultural practices. Therefore, they consume larger amounts of fish than the general population and may be at a greater risk of the adverse health effects from Hg due to increased exposure” (EPA 2004). After nearly a million additional public comments, a further revised proposed rule ultimately included five pages of analysis of the disparate impacts on “vulnerable populations” including “African Americans,” “Hispanic,” “Native American,” and “Other and Multi-racial” groups (EPA 2011). In the final rule, “vulnerable populations” was replaced with “minority, low income, and indigenous populations” (EPA 2012). The EPA had also conducted an analysis of sub-populations with particularly high potential risks of exposure due to high rates of fish consumption as well as additional analysis of the distribution of mortality risk by race. Of this second round of comments, over 200 unique comments explicitly raised EJ issues. The Little River Band of Ottawa Indians expressed the Tribe’s “frustration at trying to impress upon the EPA the multiple and profound impacts of mercury contamination from a Tribal perspective. Not to mention the obligations under treaties to participate with tribes on a ‘Government to Government’ basis. At present, no such meetings have occurred in any meaningful manner with EPA Region V, the EPA National American Indian Environmental Office, nor the State of Michigan’s Department of Environmental Quality…Although EPA purported to consider environmental justice as it developed its Clean Air Mercury Rule, it failed utterly. In this rulemaking, EPA perpetuated, rather than ameliorated, a long history of cultural discrimination against tribes and their members” (Sprague 2011). Did comments like these play a role in EPA’s changed analysis of whom Mercury limits should aim to protect? Given the many potential sources of influence, it may be difficult to attribute causal effects of particular comments on a given policy. However, comments may serve as a good proxy for the general mobilization of groups and individuals around an administrative process, and it is not clear why the EPA would not address EJ in the first draft of a rule and then add it to subsequent drafts in the absence of activist pressure. Electoral politics does not offer an easy explanation. The notice proposing the Mercury Rule was issued by the Clinton administration, the same administration that issued the Executive Order on Environmental Justice, and the subsequent drafts that did address EJ issues were published by the Bush administration, which had a more contentious relationship with EJ advocates, while Republicans controlled both houses of Congress. The expansion of the analysis from one draft to the next seems to be in response to activist pressure. 4.3.4 Measuring Policy Change Having shown how public comments and pressure can influence policy texts, I assess the general relationship between comments and policy change across all rules. I use two indicators of policy change to model the effect of public comments on policy: whether a rule addresses EJ and change in how it addresses EJ, i.e., change in portions of the text discussing EJ. Both measures represent a relatively low bar, indicating whether the agency explicitly paid any attention to EJ. This is appropriate given that prior research shows little to no effect of public comments from advocacy groups and little attention to EJ in particular. Examples in the previous section illustrate how text mentioning “environmental justice” might be added or change. Carefully tracing a few rulemaking processes also helped to avoid analytic pitfalls. For example, one case where an agency did an EJ analysis and then appeared not to respond to a comment discussing EJ was, in fact, due to the fact that the commenter included an annotated version of the draft rule their comment, adding only “no comment” next to the 12898 section. To correct this, I removed text copied from the proposed rule from comments in pre-processing. 4.3.4.1 Measure 1: Adding Text Addressing EJ to Final Rules For the subset of draft rules that did not address EJ, I measure whether agencies added any mention of “environmental justice” in the final rule. Such additions usually take the form of an “E.O. 12898” section where the agency justifies its policy changes with respect to some concept(s) of environmental justice. The next most common addition occurs in the agency’s response to comments, explaining how the rule did not have disparate effects or that they were insignificant. Agencies may both respond to a comment and add a 12898 section. For example, the EPA responded to several commenters, including Earthjustice, the Central Valley Air Quality Coalition, the Coalition for Clean Air, Central California Environmental Justice Network, and Central California Asthma Collaborative: “EPA agrees it is important to consider environmental justice in our actions and we briefly addressed environmental justice principles in our proposal.” As the commenters noted, the EPA had not, in fact, addressed environmental justice in the proposed rule, which approved California rules regulating particulate matter emissions from construction sites, unpaved roads, and disturbed soils in open and agricultural areas. EPA did add a fairly generic 12898 section to the final rule but did not substantively change the rest of the policy. Less frequently, an agency may explicitly dismiss a comment and decline to add a 12898 section. For example, EPA responded to a comment on another rule, “One commenter stated that EPA failed to comply with Executive Order 12898 on Environmental Justice…We do not believe that these amendments will have any adverse effects on…minority and low-income populations…Owners or operators are still required to develop SSM plans to address emissions…The only difference from current regulations is that the source is not required to follow the plan” (71 FR 20445). As these examples illustrate, agencies may add text addressing environmental justice that would not satisfy critics. This measure merely indicates whether the agency engaged with the claims. Most frequently, agencies neither responded to comments nor added a 12898 section. 4.3.4.2 Measure 2: Changing Text Addressing EJ in Final Rules Where draft rules did address EJ, I measured whether a rule changed how it discussed “environmental justice” between its draft and final publication.37 When an agency addresses EJ in the draft rule, it is almost always in a section about how it addressed E.O. 12898. In many cases, much of the text of final rules, including 12898 sections, remain exactly the same between draft and final versions. To measure change, I parse draft and final rules into sentences and identify sentences containing the phrase “environmental justice.” If an agency leaves these sentences unchanged between the draft and final rule and adds no new sentences mentioning EJ, this suggests that the agency did not engage with comments raising EJ concerns.38 4.4 Results 4.4.1 Are final rules more likely to address environmental justice after comments do so? Where environmental justice is not addressed in the draft rule, a higher percent of rules add EJ language when comments raise EJ concerns. Descriptively, there is a large difference in the rate of addressing EJ between rules where commenters and did (33%) and did not raise EJ concerns (4%). However, in most cases (67%), agencies did not respond at all when commenters raised EJ concerns. Rates of adding EJ in rules without EJ comments decreased over time, leveling out at 3% during the Obama and Trump presidencies. Rates of adding EJ when commenters raised EJ concerns are consistently much higher, but it also decreases over time, from 57% under G.W. Bush to 26% under Trump. EPA had a relatively high baseline rate of change (10%), which increased to 52% when comments raised EJ concerns. Most other agencies also added EJ at a higher rate when comments raised EJ concerns; indeed, most agencies almost never do so when comments did not raise EJ concerns. To account for differences across presidents, agencies, and the number of comments, I estimate logit regression. For models 1 and 2 in Table 4.1, the outcome is whether the agency added environmental justice to the final rule. The predictors are whether comments raised EJ concerns, the number of unique (non-form letter) comments addressing EJ, the total number of comments (including form letters), and the interaction between the total number of comments and whether any comments raised EJ concerns. Models 3 and 4 are the same as models 1 and 2, except that the outcome is whether the policy text changed how EJ is discussed (described in the next section). All models include fixed effects for the presidential administration. Models 2 and 4 also include fixed effects for agency. Thus, estimates in Models 1 and 3 include variation across agencies, whereas estimates in models 2 and 4 only rely on variation within agencies. All estimates rely on variation within each presidential administration. All predicted probabilities shown below include agency fixed effects, models 2 and 4. Table 4.1: Logit Regression Predicting Change in Rule Text 1 2 3 4 Dependent Variable EJ Added EJ Added EJ Changed EJ Changed EJ Comment 3.363*** 2.414*** 0.717*** 0.748*** (0.221) (0.240) (0.243) (0.246) Log(Comments+1) 0.068** 0.232*** -0.147*** -0.156*** (0.028) (0.036) (0.032) (0.033) Unique EJ Comments 0.005 0.227*** 0.032** 0.036** (0.006) (0.068) (0.014) (0.014) EJ Comment*Log(Comments+1) -0.227*** -0.226*** 0.071 0.069 (0.052) (0.072) (0.050) (0.051) President FE X X X X Agency FE X X Num.Obs. 11721 11721 1885 1885 AIC 3868.6 3125.6 2180.4 2166.5 BIC 3927.5 3464.6 2224.7 2327.2 Log.Lik. -1926.296 -1516.818 -1082.192 -1054.252 * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01 4.4.1.1 The Predicted Probability of Added Text As logit coefficients are not easily interpretable, Figures 4.5, 4.6, and 4.7 show the predicted probability of a final rule addressing environmental justice when the draft rule did not. Controlling for average rates of policy change per agency and the number of comments, Figure 4.5 shows a large increase in the probability of policy change when comments raise EJ concerns. This supports the Distributive Information Hypothesis. When comments raise distributive justice concerns, they are more likely to be addressed in the final policy. Rates of adding EJ language decrease after the G.W. Bush Administration, but differences between presidents are small compared to the difference between rules that did and did not receive EJ comments. Other variables are held at their modal values: the EPA, zero additional EJ comments, and one comment total.39 Figure 4.5: Probability that “Environmental Justice” is Added Between Draft and Final Rules by President Figure 4.6 shows the probability that an agency will add EJ language given different total numbers of comments. At low numbers of comments, anyone comment raising environmental justice has a strong relationship with policy change. For rules with less than ten comments (most rules), one comment mentioning EJ is associated with a 30% increase in the probability that EJ will be addressed in the final rule. This supports the Distributive Information Hypothesis. However, the probability that an agency will add EJ language is still below 50%—even when comments raise EJ concerns, agencies tend not to address them. As the number of comments increases, the probability that a rule will add text addressing EJ increases. This supports the General Pressure Hypothesis—policy change is more likely when there is more public attention to a policy process. Simultaneously, there is a negative interaction between the number of comments and EJ comments—the more comments, the smaller the relationship between comments raising EJ and agencies addressing EJ in the rule. In the small-portion of highly salient rules with 10,000 or more, the presence of comments raising EJ concerns no longer has a statistically significant relationship with agencies adding EJ to the text. With or without EJ comments, these rules have about the same probability of change as those with just one EJ comment, just under 50%. This is evidence against the Specific Pressure Hypothesis—the number of comments matters (i.e., the scale of public attention) matters regardless of whether these comments explicitly raise EJ concerns. However, as shown in Figure 4.3, few rules with 10,000 or more comments do not have at least one comment mentioning EJ, so we are highly uncertain about estimates of the impact of EJ comments with high levels of public attention. We can be much more confident about the relationship between comments raising EJ concerns and rule change at lower, more typical levels of public attention. The probability of “environmental justice” appearing in the final rule also increases with the number of unique comments mentioning “environmental justice” in models 2, 3, and 4. Overall this supports the Repeated Information Hypothesis. Figure 4.6: Probability Environmental Justice is Added Between Draft and Final Rules by Number of Comments Figure 4.7 shows estimated variation in rates of adding EJ to final rules across agencies. Agencies with the largest average rates of adding EJ language are the agencies we would expect to be more receptive to EJ claims. While many agencies make policies that could be framed as “environmental,” and all policy decisions have distributive consequences, institutions have norms and procedures that lead policymakers to see problems in different ways. For example, some agencies have dedicated staff and prominent internal guidance on EJ analysis in rulemaking, including the Environmental Protection Agency and the Department of Transportation (which includes the Federal Railroad Administration (FRA), Department of Transportation, Federal Motor Carrier Safety Administration (FMCSA), and the Federal Highway Administration (FHWA)). These agencies are among the most responsive to commenters raising EJ concerns. However, differences among agencies are fairly uncertain due to the small number of rules where EJ was added at most agencies. Thus, there is more support for the Policy Receptivity Hypothesis than against it, but differences between agencies with different missions and institutional practices regarding EJ are not clear cut. Figure 4.7: Probability Environmental Justice is Added Between Draft and Final Rules by Agency 4.4.2 Are rules more likely to change how they address environmental justice when comments mention it? Turning to rules that do address EJ in the draft, we also see responsiveness to comments raising EJ concerns, now measured as whether any sentences containing “environmental justice” changed between draft and final rule. Models 3 and 4 in Table 4.1 are the same as Models 1 and 2, except that the dependent variable is now whether any sentences mentioning EJ changed between the draft and final rule. Most rules that addressed EJ in the draft were published by the EPA. The EPA had a high rate of baseline change, which increased when comments raised EJ concerns. Other agencies had too few draft rules mentioning EJ to make strong inferences, but many changed how they discussed EJ 100% of the time when comments raised EJ concerns, while inconsistently doing so when comments did not. 4.4.2.1 The Predicted Probability of Changed Text Controlling for average rates of change per agency and the number of comments, Figure 4.8 shows little difference in baseline rates of changing EJ language across the Bush, Obama, and Trump presidencies. All are significantly lower than the Clinton administration’s rate, which could be related to Clinton’s Executive Order on environmental justice or simply an artifact of the limited sample of rules posted to regulations.gov before the mid-2000s. Figure 4.8: Predicted Change in How Environmental Justice is Addressed Between Draft and Final Rules by President For draft rules that already addressed EJ, the relationship between the total number of comments and policy change is in the opposite direction posited by the General Pressure Hypothesis. The logged total number of comments is inversely related to change in the final rule text. The more comments on a proposed rule, the less likely it is to change. Rules are more likely to change when they receive fewer comments. Thus, the total number of comments has the opposite relationship to how rules that already addressed EJ changed as it did to whether rules added any EJ text. While the General Pressure Hypothesis explained adding EJ text where none existed in the draft, the opposite is true for changing a text that already addressed EJ. Instead, this result supports the competing intuition that more salient rules may be harder to change because the agency has anticipated public scrutiny. Their position stated in the draft is more likely to be the position of the final rule. As shown in Figure 4.9, EJ comments have a small but discernable relationship to the probability of rule change at typical (low) numbers of comments. As the total number of comments increases, the estimated difference between policies that did and did not receive EJ comments increases. When no comments mention EJ, a rule that receives 10,000 comments is much less likely to change than a rule that received 10,000. When comments do raise EJ concerns, more public attention has a smaller impact on the probability of policy change. Figure 4.9: Predicted Change in How Environmental Justice is Addressed Between Draft and Final Rules by Number of Comments 4.5 Conclusion This analysis presents a rare, systematic account of a social movement’s impact on specific policy outcomes across institutions and over time. It illustrates the importance of ideas in policymaking and how social movements can affect policy, even in technocratic processes like rulemaking, where most U.S. law is now made. When activists raise issue frames like environmental justice, there is a higher probability that policymakers engage in discourse that highlights the distributive effects of policy. However, baseline rates of addressing environmental justice in rulemaking are so low that, even when activists raise EJ concerns, most policy documents pay no explicit attention to EJ. We see this general lack of attention across agencies and across the G.W. Bush, Obama, and Trump administrations. Indeed, I find surprisingly small differences across administrations in both baseline rates of considering EJ and the relationship between public pressure and policy change. There is a great deal of variation across agencies, suggesting that policy receptivity and responsiveness to public input are conditional on an institutional factors. The policy outcomes suggested by an environmental justice analysis depend on how the populations of concern are defined. In some cases, those raising environmental justice concerns present it as an economic inequality issue, leading policy to account for disparate impacts on low-income populations. In other cases, groups raise claims rooted in cultural practices, such as fish consumption among certain tribes. As occurred in the Mercury Rule, the analysis in subsequent drafts of the policy used evaluative criteria specific to these communities. Thus, policy outcomes will depend on the specific environmental justice concerns raised. Future research should assess the relationship between specific EJ claims and corresponding policy changes. Which communities and concerns are raised by activist campaigns depend on second-order representation—who makes decisions in the organizations that mobilize public pressure. Examining which groups raise environmental justice concerns and second-order participation in these organizations’ advocacy decisions validates some of the skepticism about who is able to participate and make their voice heard. Elite groups dominate policy lobbying, even for an issue like environmental justice. National advocacy organizations frequently request that regulators protect “all people” or even “low-income communities of color.” However, this more generic advocacy may not lead to the same outcomes as participation b groups that can present more specific local environmental justice concerns unique to a community. In between generic progressive advocacy organizations and community-based organizations are high-capacity organizations like the Sierra Club and Earthjustice, which frequently partner with local organizations for more place-based litigation and campaigns and may be more likely to raise these local concerns in national policymaking. Given the importance of federal policy for local environmental outcomes, and advocacy organizations’ potential to draw policymakers’ attention to environmental justice issues, future research should examine the quality of partnerships between frontline communities and national advocacy organizations. In the end, the above analysis offers some clarity on two poorly understood and rarely linked features of American politics: the policy impact of social movements and the role of public pressure in bureaucratic policymaking. It offers some hope that policymakers may address concerns raised through direct democracy mechanisms like public comment periods. At the same time, it highlights how policymakers rarely explicitly address the disparate impacts of policy, even when directly confronted with distributive justice concerns. Social movements do affect policy, but there are steep odds to overcome. References "],["reforming-the-policy-process.html", "Chapter 5 Reforming the Policy Process", " Chapter 5 Reforming the Policy Process Each week, students in my public policy class must write to an elected official or comment on a proposed agency rule and then post about it in the class forum. But college students should not be the target demographic for notice and comment rulemaking–they are too informed and have too much time to write thoughtful comments. If we wish to realize the ideals of the APA, we must broaden participation. Can we do this? Is it worthwhile? Many scholars assume not, but the data offer some hope. This chapter reviews proposed reforms in light of the empirical evidence in the previous chapters. I start with a short outline of the various positions staked out by administrative law scholars, each rooted in different theories of democracy. I then review several specific challenges and reform proposals. 5.0.1 The Debate in Administrative Law Participatory democracy optimists Optimists see notice and comment as the “purest example of participatory democracy in actual American governance.” The process is technically open to anyone with an opinion to offer, and agencies are, to an extent, required to respond to substantive ideas. “Regulatory democracy” reformers Cuéllar (2014) argues that rulemaking could be more discursive. Mendelson (2011) found that agencies often discard non-technical comments but argues that they shouldn’t because mass comments contain valuable information. For this camp, the quality of the public debate is more important than the total number of people, their affiliations, or their biases. They emphasize the transformative power of discourse. Pluralist reformers A different brand of reformer focuses less on discourse and more on interest group representation. Pluralist reformers argue that lobbying groups should be required to disclose their membership, funding, and decision-making processes (Seifter 2016). In this view, organized groups, not individuals, are the central actors in public comment processes. However, because agencies often lack information about groups, it is difficult to know how well they represent the people they claim to. Interest groups’ faithful representation of their members is crucial to pluralist ideas of democracy. Rational pluralists Another group of scholars sees organized interest groups and experts that can provide credible information. In this view, random or self-selecting members of the general public are not appropriate participants. “The goal of e-rulemaking is to more fully capture such credible, specific, and relevant information, not to solicit the views of random, self-nominating members of the public” (Herz 2016). Speaking on the topic of mass comment campaigns, Oliver Sherouse, a regulatory economist at the Small Business Administration, expressed the same sentiment: “It’s worth remembering why we have a public comment process in the first place, which is that the public has knowledge that regulators do not have and that they need to do their jobs well…how do the poor quality mass comments affect small businesses in the comment process? The most obvious problem would be if legitimate small business concerns are just lost in the flood.” (GSA 2019a, p. 31-32) Sharehouse raised an additional concern that mass-comment campaigns might distract people from writing their own, more informative comments. While recognizing that “not everyone who does not sign onto that kind of [mass] comment would be willing to write a high-quality one,” the tradeoff of a few “quality” comments for many “poor quality” comments is worthwhile. (GSA 2019a, p. 32) However, Sherouse was also wary about dismissing mass comments. &gt; “A good point is not less of a good point because 10,000 people happen to agree with it.” (GSA 2019a, p. 32) Skeptics The most skeptical camp goes even further, arguing that open solicitations to the general public should be abolished. 5.0.2 Challenges Fraud (The Wall Street Journal](https://www.wsj.com/articles/many-comments-critical-of-fiduciary-rule-are-fake-1514370601) reported that 40% of comments on one Department of Labor rule used fraudulent identities. 5.0.3 Reforms Can the unwashed masses provide useful information to agencies? My answer is yes. Will this information be biased? Yes, but all information provided by lobbying groups has a bias, the task is to make biases transparent, and reforms could do this. First, we must dispense with the idea that agencies merely implement the law. The APA provides for public participation because the ideal of direct democracy might affect the important substantive policy made by agencies. Indeed, agencies are often seeking comment on revisions to rules based on authority delegated decades ago. Agency must make policy to satisfy their mandates. The present question is one of process. Calling for greater congressional oversight or presidential control sidesteps the issue–by what process should agencies make policy? (Indeed, Potter et al. (2019) shows us that agencies often sidestep oversight, making their procedural rules all the more important.) Critics may argue that opening the door wider to petition campaigns lets in biases. Indeed we know that people who opt to participate are disproportionately privileged. In an unequal society, we have unequal participation, but higher barriers to entry only make this worse. More problematic is the idea that a well-funded group who typically dominates rulemaking (J. W. Yackee and Yackee 2006) will sponsor astroturf campaigns, thus creating a false impression of public support. This is a real concern. If dark money can secretly drive impressions of support for a policy, the case for expanding participation is weekend. Hopefully, my analysis suggests that this is uncommon. the fast The fact that we do not observe it now does not mean it will not occur, but agencies could b Reforms along the lines have been suggested. ___ would like polls. Nationally representative polling may be a good investment for some rules, but we know from polling research that individuals do not always have clearly formed opinions, and much depends on question wording. The reality is that American politics is animated through groups–people rely on organizations they trust to keep them informed and engaged. In classic pluralist fashion, organizations claim to represent segments of the population in rulemaking. &lt;1–Because these organizations Raso suggests similar reforms. as others have pointed out As the moderator of my class’s forum, I can co-sign research on discursive democracy initiatives that realizing transformative discourse is difficult. The ideal of “transformed into something” is laudable, but people are busy, and any barrier to participation will massively reduce participation. Participation already follows a log scale distribution, with most rules receiving no comments–even major rules, on average, receive less than 10. –&gt; #### Aims of reform {-} Lower barriers to participation. The main barrier to participation in rulemaking is information. Even people with relatively high social capital, like small business owners, rarely participate because they do not know about the opportunity or lack the time necessary to engage. “they might only find out about a proposed regulation when they’re presented with one of these mass comments. And they might not have time to go back and investigate and then write a full comment letter right before the comment period is going to close. Because there aren’t a lot of small business owners who read the Federal Register every day…writing a detailed comment letter is hard work.” - Oliver Sherhouse (GSA 2019a, p. 33) Increase transparency. Reduce the cost of extracting information from comments. Reformers often highlight the value of linking comments to particular questions or sections of a draft rule. Technology can certainly improve sophisticated debates about a rule’s technical provisions. Indeed, sophisticated commentors have adopted track-changes technology to provide marked-up versions of draft rules. New technologies may provide an even more important role in gleaning political information from the “torrents of email” and “vexing challenge” posed by mass comment campaigns. Gaurd against fraud. Parsing the questions Agencies often specifically ask questions and solicit comments on specific topics in an NPRM. These topics offer an initial structure to allow commenters to self-identify the topics of their comments. The American Bar Association’s Section of Administrative Law and Regulatory Practice recommends “technology that would allow agencies to identify categories that commenters could select when submitting comments.” To stay open to new ideas, lobbying groups should be allowed to petition the agency to add topics to the menu or ask additional questions. For example, agencies may encourage groups to mobilize in support of the groups’ answers to the questions that agencies ask. Given past trends, this will likely take the form of petition campaigns, and agencies should have a mechanism to receive those comments as such. Offering answers Agencies could also lower the bar to participation by posting answers to their questions from different organizations and allow people to co-sign them or disagree with them. This is both easier for participants and requires less work for agencies to interpret where the commenter stands. The risk of astroturf is real under any public comment system (including the current one), but transparency requirements can go a long way. Organizations or individuals acting in their professional capacity as organizations (not individuals) should be required to disclose where the money they paid for them to produce their comments came from. Likewise, organizations running campaigns should disclose the sources of funding for the campaigns and how much they spent mobilizing public support. These numbers will provide a helpful denominator for agencies to gauge public enthusiasm. ACUS Report Increasing transparency and public participation (GSA-2019-02) On January 30th, 2020, the Government Services Administration held a hearing on the topic of mass comments. The three invited speakers represented the National Association of Manufacturers, the Small Business Administration, and MITRE. A federally funded technology research and development. These three guests embody important aspects of how public comment is seen. First, public comment is most often utilized by business groups like NAM (“power users of the regulatory process,” as Hedern put it) and thus represents the users for whom public comment technology is designed. NAM does not sponsor mass comment campaigns. Perhaps they have a stake in delegitimizing mass comment campaigns that occasionally mobilized on the opposing side, but the reason they are on this panel is simply that they are the archetypical user. Second, agencies like the Small Business Administration are the ones who must deal with the “challenge” of mass comment campaigns. Third, technology consultants represent the way in which mass comment campaigns are primarily viewed as a technological challenge. Another important feature of this policy area is its tight-knit epistemic community. As observed by Mr. Hedren: “it’s a little alarming to me in some respects to see that, looking out into the crowd, I think I know about half of you on a first-name basis. So, we probably need a little bit more fresh blood in this regulatory nerd community.” - Patrick Hedren, National Association of Manufacturers. Gaurding against fraud As with any form of public participation, fraud merits attention. If organizations submit comments on behalf of people who do not exist or did not consent, this is akin to fraudulent petition signatures or fake constituent letters being sent to Members of Congress. Authentication. Matt Cutts (acting director of the U.S. Digital Service) suggests CAPTCHAS, email confirmations, and multi-factor authentication. If comments are allowed to be collected by third parties like the Sierra Club, the government can encourage, but may not be able to enforce the use of CAPTCHAS. Requiring confirmation or authentication by email or phone alone would be a barrier to participation. Requiring both could be prohibitive. The most secure approach that allows third parties to gather comments may be to authenticate each comment by asking each commenter to provide an email address or phone number at which to receive a message asking them to confirm the text of their comment. Asking for a second interaction with the agency raises the cost of participation but may also make participation a slightly richer experience (as Dan Walters suggested on Twitter). People may be more likely to feel that their voice was heard. Of course, many people will fail to confirm their authenticate their comment, but like mass comments themselves, the number of people willing to take the time to authenticate offers information on the intensity of genuine support. Unauthenticated comments need not be discounted, but authenticated comments may indicate stronger preferences. More importantly, authentication guards against identity theft. It is difficult to provide a large number of fake phone numbers, and real phone numbers used fraudulently would likely generate complaints, alerting the agency that the campaign may be engaging in fraud. Again, fraud complaints need not discount an entire campaign. Opponents of a campaign by the Sierra Club, for example, could submit fraudulent comments through their system in order to complain when asked to authenticate and thus cast doubt over the campaign. However, a legitimate campaign will also have a portion that will authenticate, allowing rough estimates of the scale of true support versus fraud. Some means of authentication, such as email, may be slightly more open to fraud than others, like texts, but the benefits to lower barriers to participation may outweigh the greater risk of fraud. Because mass comment campaigns include a fairly large number of individuals, especially if the barriers to participation are lower, there are many opportunities to identify fraud of any significant scale, and the stakes of a few fraudulent comments slipping through the cracks are low. Should agencies accept anonymous comments? There are good reasons to accept technical information from anonymous sources. For example, they may fear retaliation. However, anonymous comments should not be used to infer political information. This distinction supports two tracks with distinct requirements. An agency may want to allow sophisticated anonymous comments to be co-signed by large numbers of authenticated supporters, thus allowing insiders with the necessary knowledge to make sophisticated arguments, but also much to lose to put ideas into public and the agency to gauge public reaction to those ideas. References "],["conclusion-3.html", "Chapter 6 Conclusion", " Chapter 6 Conclusion The legitimacy of bureaucratic policymaking is said to depend on the premise that rulemaking provides for public voice (Croley 2003, @Rosenbloom2003). Yet we lack an empirical base necessary to evaluate whether any legitimacy the public comment process may provide is deserved. If input solicited from ordinary people has little effect on policy outcomes, directly or indirectly, it may be best understood as providing a veneer of democratic legitimacy on an essentially technocratic and/or elite-driven process. I have made a few initial steps toward better understanding actual public engagement in bureaucratic policymaking. If public pressure campaigns do shape agency decisions, a new research program will be needed to investigate who exactly these campaigns mobilize and represent. References "],["references.html", "References", " References "]]
