[["index.html", "Public Pressure Campaigns and Bureaucratic Policymaking Introduction Motivation Outline of the book", " Public Pressure Campaigns and Bureaucratic Policymaking Devin Judge-Lord 2021-04-10 Introduction Does civic engagement through public pressure campaigns affect agency rulemaking? I examine who participates in public pressure campaigns and why, whether they affect congressional oversight, and whether they affect policy. Answering these questions informs our understanding of bureaucratic politics and interest group lobbying, organizing, and mobilizing tactics. If ordinary people have a voice in bureaucratic policymaking, I argue, it is through public pressure campaings. Thus, understnding the nature and effects of these campaigns is key to understanding modern democracy. Large democracies face two big problems. First, they are vulnerable to fleeting passions and demagogues. To combat this, many decisions are left to experts who, ideally, exercise judgment loosely guided by the public. Second, everyone cannot vote on every decision. We thus delegate power to representatives (who then delegate it to deputies), create temporary mini-publics, and solicit input from those most affected or moved by a public decision.1 Most policy is then made by bureaucrats, supposedly guided indirectly through elected representatives and directly by limited public input (mostly limited to more contentious policy debates). Both of these problems converge in the bureaucracy, run by experts who are deputized by elected officials (or by their deputy’s deputy’s deputy) and with procedures that create opportunities for public input. It is far from clear how bureaucratic decisions are to balance expertise, accountability to elected officials, and responsiveness to public input in decisionmaking. With the rise of the administrative state, U.S. federal agencies have become a major site of policymaking and political conflict. By some estimates, upward of 90% of legally binding U.S. federal policy is now written by agencies. Agency rules are revised much more frequently than statutory law (Wagner et al. 2017). In the years or decades between legislative enactments, federal agencies make legally-binding rules interpreting and reinterpreting old statutes to address emerging issues and priorities. Examples are striking: Many effects of the Dodd-Frank Wall Street Reform and Consumer Protection Act were largely unknown until the specific regulations were written, and it continues to change as these rules are revised. Congress authorizes billions in grants, subsidies, and leases for public lands, but who gets them depends on agency policy. In the decades since the last major environmental legislation, agencies have written thousands of pages of new environmental regulations and thousands more changing tack under each new administration. These revisions significantly shape lives and fortunes. For example, in 2006, citing the authority of statutes last amended in the 1950s, the Justice Department’s Bureau of Prisons proposed a rule restricting eligibility for parole. In 2016, the Bureau withdrew this rule and announced it would require fewer contracts with prison companies, precipitating a 50% loss of industry stock value. Six months later, a new administration announced these policies would again be reversed, leading to a 130% increase in industry stock value. Agency rulemaking matters. Less clear, however, is how the new centrality of agency rulemaking fits with democracy. In addition to the bureaucracy’s complex relationships with the president and Congress, agencies have complex and poorly understood relationships with the public and advocacy groups. Relationships with constituent groups may even provide agencies with a degree of “autonomy” from their official principals (Carpenter 2001). Participatory processes like public comment periods, where government agencies must solicit public input on draft policies, are said to provide political oversight opportunities (Balla 1998; Mccubbins and Schwartz 1984), democratic legitimacy (Croley 2003; Rosenbloom 2003), and new technical information (S. W. Yackee 2006; Nelson and Yackee 2012). While recent scholarship on agency policymaking has shed light on the sophisticated lobbying by businesses and political insiders, we know surprisingly little about the vast majority of public comments which are submitted by ordinary people as part of public pressure campaigns.2 Activists frequently target agency policymaking with letter-writing campaigns, petitions, protests, and mobilizing people to attend hearings, all classic examples of “civic engagement” (Verba and Nie 1987). Yet civic engagement remains poorly understood in the context of bureaucratic policymaking. These occasional bursts of civic engagement in bureaucratic policymaking raise practical and theoretical questions for the practice of democracy.3 These questions, in turn, hinge on unanswered empirical questions: Do these campaigns affect policy? If so, by what mechanisms? Existing research finds that commenters believe their comments matter (Yackee 2015) and that the number of public comments varies across agencies and policy processes (Judge-Lord 2019a; Libgober 2018; Moore 2017), but the relationship between the scale of public engagement and policy change remains untested. Motivation Leading models of influence in bureaucratic policymaking focus on two key political forces: sophisticated interest group lobbying and political oversight. As bureaucrats learn about policy problems and balance interest-group demands, public comment processes allow lobbying organizations to provide useful technical information and inform decisionmakers of their preferences on draft policies. Agencies may then update policy positions within constraints imposed by their political principals. While this may describe most cases of bureaucratic policymaking, these models do not explain or account for the contentious politics that occasionally inspire millions of ordinary people to respond to calls for public input on draft agency policies. Mass engagement in bureaucratic policymaking has thus largely been ignored by political scientists, leaving a weak empirical base for normative and prescriptive work. Like other forms of mass political participation, such as protests and letter writing campaigns, mass public comments on draft agency rules provide no new technical information. Nor do they wield any formal authority to reward or sanction bureaucrats, as comments from a Members of Congress might. The number on each side, be it ten or ten million, has no legal import for an agency’s response. How, if at all, should scholars incorporate mass engagement into models of bureaucratic policymaking? In contrast to political scientists, legal scholars have long debated what to make of mass commenting in rulemaking. Many focus on reforms to help agencies collect more useful information (Farina et al. 2011; Farina, Newhart, and Heidt 2014; Rauch 2016). In 2018, “Public engagement” was main project of the Administrative Conference of the United States (ACUS) committee on Rulemaking: The project “explores agency strategies to enhance public engagement prior to and during informal rulemaking. It seeks to ensure that agencies invest resources in a way that maximizes the probability that rulewriters obtain high-quality public information.” Among other things, this committee is debating how best to gather “quality public information,” how “to get new people/groups into the real or virtual room” (Farina 2018), and whether broad engagement is even desirable on all rules (White 2018). Administrative law scholars have explored these questions theoretically for decades, but only a few offer empirical analysis. Mendelson (2011) finds that agencies often discard non-technical comments but argues that they should be given more weight. Others worry that mass commenting distracts agencies from good policy and the broader public interest (Coglianese 2006). Farina et al. (2012, 112) claims that “[Mass] comments typically are neither factually informative nor reliable indicators of citizens’ informed value preferences.” Some even call them “spam” (Balla et al. 2018; Noveck 2004). In this prevailing view, “high-quality” and “relevant” mean novel technical information, not opinions. Herz (2016, 208) concludes “The goal of e-rulemaking is to more fully capture such credible, specific, and relevant information, not to solicit the views of random, self-nominating members of the public.” Similarly, Epstein, Heidt, and Farina (2014, 4) dismiss mass comments as “effectively, votes rather than informational or analytical contributions. Rulemaking agencies are legally required to make policy decisions based on fact-based, reasoned analysis rather than majority sentiment; hence, even hundreds of thousands of such comments have little value in the rulemaking process.” Notably, the ACUS draft recommendations on “Mass and Fake Comments in Agency Rulemaking” suggests that “effective comments” give “reasons rather than just reactions” (ACUS 2018, 33). If true, most public reactions to proposed rules such as those expressed in mass comments would have no effect in rulemaking. Early optimism among legal scholars that the internet would “change everything” (Johnson 1998) and that “cyberdemocracy” would enable more deliberative rulemaking has faded. While commenting and mobilizing others to comment has become easier, Coglianese (2006) finds that little else has changed. The prediction that the internet would primarily facilitate more of the same kind of engagement among the like-minded (i.e. mass-commenting) (Sunstein 2001) has largely been correct. In this sense, the “quality” of discourse has not improved. Even scholars who suggest reforms aimed at “regulatory democracy” aim to increase the “sophistication” of ordinary peoples’ comments (Cuéllar 2014; Johnson 2013). For example, Beth Simone Noveck (Noveck 2004) is critical of “notice and spam,” arguing instead for “participative practices—methods for ‘doing democracy’ that build the skills and capacity necessary for citizens, experts, and organizations to speak and to be heard. Rulemaking, after all, is a communicative process involving a dialogue between regulators and those affected by regulation” Noveck (2005, 3). This scholarship has improved the theory and practice of policy learning in rulemaking. But a focus on sophisticated deliberation and technical information overlooks the potential role of political information.4 Whereas administrative law scholars have focused on “how technology can connect the expertise of the many to the power of the few” (Noveck 2009), I ask whether it may also connect the power of the many to the decisions of the few. Outline of the book This dissertation explores the effects of public pressure campaigns on agency rulemaking, a technocratic policy process where “public participation” is usually limited to sophisticated lobbying but occasionally includes millions of people mobilized by public pressure campaigns. Public comment periods on proposed policies purport to provide democratic accountability. Yet theories of bureaucratic policymaking largely ignore the occasional bursts of civic engagement that generate the vast majority of public comments on proposed rules. To fill this gap, I build and test theories about the role of public pressure in policymaking. I collect and analyze millions of public comments to develop the first systematic measures of civic engagement and influence in bureaucratic policymaking. Chapter 1 “Agency Rulemaking in American Politics” situates agency rulemaking in the context of American politics. Tracing broad trends over the past 40 years, I show that rulemaking has become a major site of policymaking and political conflict. Chapter 2 “Why Do Agencies (Sometimes) Get So Much Mail?” addresses who participates in public pressure campaigns and why. Are public pressure campaigns, like other lobbying tactics, primarily used by well-resourced groups to create an “astroturf” impression of public support? Or are they better understood as conflict expansion tactics used by less-resourced “grassroots” groups? I find that mass comment campaigns are almost always a conflict expansion tactic. Furthermore, I find no evidence of negativity bias in public comments. Indeed, from 2005 to 2017, most comments supported proposed rules. This is because public comments tend to support Democratic policies and oppose Republican policies, reflecting the asymmetry in mobilizing groups. Chapter 3 “Do Public Pressure Campaigns Influence Congressional Oversight?” examines the effect of public pressure campaigns on whether legislators are more likely to engage in rulemaking. This involves collecting and coding thousands of comments from Members of Congress on proposed rules with and without public pressure campaigns. These data also allow me to assess congressional oversight as a mediator in policy influence, i.e., the extent to which public pressure campaigns affect policy indirectly through their effects on legislators’ oversight behaviors. Chapter 4 “Do Public Pressure Campaigns Influence Policy?” leverages a mix of hand-coding and computational text analysis methods to assess whether public pressure campaigns increase lobbying success. To measure lobbying success, I develop computational methods to identify lobbying coalitions and estimate their effect on each rule posted for comment on regulations.gov. I then validate these methods against a random sample of 100 rules with a mass-comment campaign and 100 rules without a mass-comment campaign, hand-coded for whether each coalition got the policy outcome they sought. Finally, I assess potential mechanisms by which mass public engagement may affect policy. Chapter 5 “The Environmental Justice Movement and Technocratic Policymaking” examines the discursive effects of environmental justice claims both qualitatively and quantitatively. I write about the role of Native activists and environmental groups in shaping federal environmental regulations. Looking across over 20,000 draft regulations that failed to address environmental justice issues, I find that agencies are more likely to add language addressing environmental justice in their final rules when public comments raise environmental justice concerns. References "],["agency-rulemaking-in-american-politics.html", "Chapter 1 Agency Rulemaking in American Politics", " Chapter 1 Agency Rulemaking in American Politics See the working paper version of this chapter here. Abstract "],["whymail.html", "Chapter 2 Public Pressure: Why Do Agencies (sometimes) Get So Much Mail? 2.1 Introduction 2.2 Theory: Why Mobilize? 2.3 Hypotheses About the Drivers of Mass Mobilization 2.4 Types of public engagement 2.5 Methods: Measuring Public Pressure and Political Information 2.6 Results: Patterns of Public Engagement in Rulemaking", " Chapter 2 Public Pressure: Why Do Agencies (sometimes) Get So Much Mail? See the working paper version of this chapter here. Abstract I examine who participates in public pressure campaigns and why. Scholars of bureaucratic policymaking have focused on the sophisticated lobbying efforts of powerful interest groups. Yet agencies occasionally receive thousands or even millions of comments from ordinary people. How, if at all, should scholars incorporate mass participation into models of bureaucratic policymaking? Are public pressure campaigns, like other lobbying tactics, primarily used by well-resourced groups to create an impression of public support? Or are they better understood as conflict expansion tactics used by less-resourced groups? To answer these questions, I collect and analyze millions of public comments on draft agency rules. Using text analysis methods underlying plagiarism detection, I match individual public comments to pressure-group campaigns. I find that most public comments are mobilized by a few public interest organizations. Over 80% of the 48 million comments on proposed rules posted to regulations.gov were mobilized by just 100 organizations, 87 of which lobby in coalitions with each other. Contrary to other forms of lobbying, I find that mass comment campaigns are almost always a conflict expansion tactic, rather than well-resourced groups creating an impression of public support. Contrary to other forms of political participation, I find no evidence of negativity bias in public comments. Indeed, from 2005 to 2017, most comments supported proposed rules. This is because public comments tend to support Democratic policies and oppose Republican policies, reflecting the asymmetry in mobilizing groups. 2.1 Introduction Participatory processes like public comment periods, where government agencies must solicit public input on draft policies, are said to provide political oversight opportunities (Balla 1998; Mccubbins and Schwartz 1984), democratic legitimacy (Croley 2003; Rosenbloom 2003), and new technical information (S. W. Yackee 2006; Nelson and Yackee 2012). While recent scholarship on agency policymaking has shed light on sophisticated lobbying by businesses, we know surprisingly little about the vast majority of public comments, which are submitted by ordinary people as part of public pressure campaigns.5 Activists frequently target agency policymaking with letter-writing campaigns, petitions, protests, and mobilizing people to attend hearings, all classic examples of “civic engagement” (Verba and Nie 1987). Yet civic engagement remains poorly understood in the context of bureaucratic policymaking. While practitioners and administrative law scholars have long pondered what to make of mass commenting, political scientists have had surprisingly little to say about this kind of civic participation. The contentious politics that inspire the majority of public comments have no place in leading models of bureaucratic policymaking and have largely been ignored by political scientists. Foundational scholarship on rulemaking (Furlong and Kerwin 2005, @Furlong1997, @Furlong1998, @Kerwin2011) focuses on interest group lobbying. Theoretical models focus on how agencies learn about policy problems, negotiate or avoid accountability to various principals, or balance interest-group demands.6 Most scholars are skeptical that public pressure can affect rulemaking. To the extent that scholars address the input of ordinary people at all, both existing theory and empirical scholarship suggest skepticism that it matters. (By “ordinary” people, I simply mean people who are not professional policy-influencers.) Empirical scholarship finds that economic elites and business groups dominate American politics in general (Jacobs and Skocpol 2005, @Soss2007, Hertel–Fernandez2019, @Hacker2003, @Gilens2014) and rulemaking in particular. While some are optimistic that requirements for agencies to solicit and respond to public comments on proposed rules allow “civil society” to provide public oversight (Michaels 2015; Metzger 2010), most studies find that participants in rulemaking often represent elites and business interests (Seifter 2016; Crow, Albright, and Koebele 2015; Wagner, Barnes, and Peters 2011; West 2009; J. W. Yackee and Yackee 2006; S. W. Yackee 2006; Golden 1998; Haeder and Yackee 2015; Cook 2017, LibgoberCarpenter2018). Scholars are thus skeptical about rulemaking as a venue for collective action. As a result, public pressure campaigns are dismissed as epiphenomenal to bargaining with political principals or interest groups. Indeed, almost all empirical studies of rulemaking discard unsophisticated comments from ordinary people, as evident from a comprehensive review of scholarship on “The Politics of Rulemaking” by Yackee (2019), who finds skepticism about citizen comments, but no studies analyzing public pressure campaigns as a lobbying tactic: “Kerwin and Furlong (2011) point out that a citizen must know not only that a regulation is being formulated but also how and when to participate. This is a high bar for most Americans. Second, to be influential during rulemaking, commenters may require resources and technical expertise. As Epstein, Heidt, and Farina (2014) suggest, agency rule-writers—who are often chosen because of their technical or policy-specific expertise—privilege the type of data-driven arguments and reasoning that are not common to citizen comments.” (p. 10) For any particular lay commenter, this conclusion seems inescapable; individuals acting alone are unlikely to affect policy. As Hacker and Pierson (Forthcoming) observe, “[The United States’] institutional terrain advantages political actors with the capacity to work across multiple venues, over extended periods, and in a political environment where coordinated government action is difficult, and strategies of evasion and exit from regulatory constraints are often successful. These capacities are characteristic of organized groups, not individual voters.” But groups occasionally mobilize a large number of people, usually behind a more sophisticated lobbying effort. Without a systematic understanding of the scale and impact of public participation–group-mediated participation–in rulemaking, it is impossible to answer normative questions about how participatory processes like public comment periods may enhance or undermine various democratic ideals. Scholars’ neglect of public pressure campaigns is surprising given that most people are only aware of agency rulemaking when it is the target of a high-profile mass mobilization campaign.7 While most rules receive little attention, the ease of online mobilizing and commenting has, like other forms of participation (Boulianne 2018), created exponential increases in the number of rules in which thousands and even millions of people engage (see Figure 2.2; note that comments per rule are on a logarithmic scale).8 Occasionally, a large number of people are paying attention. The general failure to explain or account for public pressure campaigns in models of bureaucratic policymaking is also striking in light of how agencies advertise public comment periods as an opportunity for a voice in government decisions.9 Big red letters across the top of the Regulations.gov homepage solicit visitors to “Make a difference. Submit your comments and let your voice be heard” and “Participate today!” (Figure 2.1. A blue “Comment Now!” button accompanies a short description of each draft policy and pending agency action. Public comment periods on proposed agency rules is described as “an important part of democracy” (WSJ 2017), “often held out as the purest example of participatory democracy in actual American governance” (Herz 2016). Rossi (1997) finds that “courts, Congress, and scholars have elevated participation in rulemaking to a sacrosanct status…greater participation is generally viewed as contributing to democracy.” Figure 2.1: Regulations.gov Solicits Public Comments on Draft Agency Rules Figure 2.2: Comments per Proposed Rule and Total Comments per Year While “ordinary” members of the public may occasionally provide novel and useful technical information to expert bureaucrats, such sophisticated means of influencing policy are out of reach for the vast majority of people. Thus, to investigate the potential role of ordinary people in bureaucratic politics I look elsewhere—not because ordinary people never provide novel and useful technical information, but because this is not how most people attempt to influence policy, nor, I argue, how we should expect ordinary people to have influence. Most public comments are, in fact, of the type suggested by the solicitations on Regulations.gov—ordinary people voicing opinions on a proposed policy. They do not provide useful technical information or suggest specific edits to policy texts like the interest group comments that have thus far captured the attention of political scientists. If they add information to rulemaking, it is a different, more political flavor of information. Indeed as Figure 2.2 shows, every year since 2008, most people who comment on draft regulations have done so as a result of a public pressure campaign.10 Public engagement in rulemaking is highly clustered on a few rules made salient by these campaigns. It is plausible that at least some of the time, such campaigns aim to influence policy. It is also plausible that thousands of people engaging may alter the politics of these policy processes, but this hypothesis remains untested. Indeed, we have much to understand about the causes and effects of these campaigns before we are in a position to ask if they are a mechanism for groups to influence policy. Most critically, we must understand who mobilizes and why. The kind of politics created by mass engagement has a few notable features. It is contentious; most ordinary people are not engaging in deliberation; they are simply making demands. Importantly, however, processes like public comment periods channel contentious demands into institutionalized policy processes rather than undermining them. In short, the politics of rulemaking created by public pressure campaigns is much more contentious than most rulemakings, but also much more institutionalized than most contentious politics. Mass engagement in rulemaking thus presents a novel context to examine the consequences of broader public participation in typically insider-dominated policymaking and how public pressure may condition how political decisions are made. Public pressure campaigns expand civic participation in policymaking.11 Surely, those who engage are far from representative of the broader public (Verba and Nie 1987), but in many ways, they must be more representative than the handful of political insiders who participate in most policy processes. If the usual participants have “an upper-class accent” (Schattschneider 1942), does adding thousands of more voices dilute this bias? This depends on how people are mobilized. If public pressure is mobilized by the usual participants to create an impression of public support, it may merely legitimize the demands of powerful interest groups. 2.2 Theory: Why Mobilize? How, if at all, should scholars incorporate mass engagement into models of bureaucratic policymaking? I argue that mass engagement produces potentially valuable political information about the coalition that mobilized it. Thus, depending on how agencies process political information, “going public” may occasionally be an effective strategy for organizations to influence policy, both directly and indirectly. However, influencing policy may not be the only reason to mobilize. This section offers a theory and hypotheses to explain variation in mass engagement. I argue that we should observe different patterns of engagement depending on whether an organization launches a mobilization campaign as an outside lobbying tactic, to counter such a campaign, or for reasons other than influencing policy. In the next section, I develop methods to measure these patterns. In short, these measures capture similar statistics to questions posed by Verba and Nie (1987, 9): “How much participation is there, what kind is it, and from what segments of society does it come?” As noted above, scholars of bureaucratic policymaking have focused on the sophisticated lobbying efforts of powerful interest groups such as business coalitions. A key insight from this scholarship is that technical information is the currency of insider lobbying. Figure 2.3 illustrates the classic causal model of insider lobbying that describes most rulemakings and nearly all scholarship on lobbying in bureaucratic policymaking to date.12 However, mass engagement has no place in this model. I aim to fill this gap. Figure 2.3: The ‘Classic Model’ of Interest Group Lobbying in Bureaucratic Policymaking First, I offer a framework for assessing the causes of mass engagement. Next, I argue that organizations may mobilize large numbers of people for three reasons with observable implications for observed patterns of mass engagement and theoretical implications for predicted effects on policy. 2.2.1 Incorporating political information into models of lobbying in rulemaking 2.2.1.1 Public pressure campaigns claim to represent and evoke the public interest. The Oceana coalition framed its mass mobilization effort to curb the Bureau of Ocean Energy Management’s 2017 Proposed Offshore Oil and Gas Leasing Program as a “petition signed by 67,275 self-proclaimed United States residents,” suggesting that organizations consider these efforts as akin to petitions. In the same statement, Oceana also claimed the support of “more than 110 East Coast municipalities, 100 Members of Congress, 750 state and local elected officials, and 1,100 business interests, all of whom oppose offshore drilling,” suggesting that claims of public and elected official support aim to provide similar kinds of political information. Appeals to the government are almost always couched in the language of public interest, even when true motivations are private (Schattschneider 1975). When lobbying during rulemaking, groups often make dubious claims to represent broad segments of the public (Seifter 2016). If agency staff do not trust an organizations’ representational claims, engaging actual people may be one of the few credible signals of a broad base of support. Furthermore, if organizations claim to represent people beyond their official members, reforms requiring groups to disclose information about their funding and membership (Seifter 2016) only go part way to assess groups’ claims to represent these broader segments of the public. Indeed, if advocacy group decisions are primarily made by D.C. professionals, these advocates themselves may be unsure how broadly their claims resonate until potentially-attentive publics are actually engaged. Theorists debate whether signing a petition of support without having a role in crafting the appeal is a meaningful voice and whether petitions effectively channel public interests, but, at a minimum, engaging a large number of supporters may help broader interests to distinguish themselves from truly narrower ones. It suggests that the organization is not “memberless” (Skocpol 2003) in the sense that they can demonstrate some verifiable public support.13 2.2.1.2 Public pressure is a political resource. An organization’s ability to expand the scope of conflict by mobilizing a large number of people can be a valuable political resource (Schattschneider 1975). In contrast to scholars who focus on the deliberative potential of public comment processes, I focus on public engagement as a tactic aimed at gaining power. Scholars who understand mobilization as a tactic (Furlong 1997; Kerwin and Furlong 2011) have focused on how organizations mobilize their membership. I expand on this understanding of mobilization as a lobbying tactic to include a campaign’s broader audience, more akin to the concept of an attentive public (Key 1961) or issue public (Converse 1964). Here I build on three insights. First, Furlong (1997) and Kerwin and Furlong (2011) identify mobilization as a tactic. The organizations that they surveyed reported that forming coalitions and mobilizing large numbers of people are among the most effective lobbying tactics. Second, Nelson and Yackee (2012) identify political information as a potentially influential result of lobbying by different business coalitions. While they focus on mobilizing experts, Nelson and Yackee (2012) describe a dynamic that can be extended to mass commenting: “strategic recruitment, we theorize, mobilizes new actors to participate in the policymaking process, bringing with them novel technical and political information. In other words, when an expanded strategy is employed, leaders activate individuals and organizations to participate in the policymaking process who, without the coordinating efforts of the leaders, would otherwise not lobby. This activation is important because it implies that coalition lobbying can generate new information and new actors—beyond simply the ‘usual suspects’—relevant to policy decisionmakers. Thus, we theorize consensus, coalition size, and composition matter to policy change.” I argue that, concerning political information, this logic extends to non-experts. The number and distribution of ordinary supporters may matter because it suggests a public consensus. Instead of bolstering scientific claims, a perceived public consensus bolsters political claims. Finally, Furlong (1998), S. W. Yackee (2006), and others distinguish between direct and indirect forms of interest group influence in rulemaking. This distinction is especially important for political information, which may be most influential through indirect channels, such as through elected officials. In short, to understand how groups lobby in rulemaking, we must understand mass mobilization as a tactic aimed at producing political information that may have direct and indirect impacts on policymaking. While most scholars have emphasized mass comments’ lack of useful technical information, a few have raised their role in creating political information. Cuéllar (2005) calls on agencies to pay more attention to ordinary peoples’ expressions of preference and Rauch (2016) suggests that agencies reform the public comment process to include opinion polls. I build from a similar intuition that mass comment campaigns currently function like a poll or, more accurately, a petition, capturing the intensity of preferences among the attentive public—i.e., how many people are willing to take the time to engage.14 Self-selection may not be ideal for representation, but opt-in participation—whether voting, attending a hearing, or writing a comment—may often be one of the few heuristics decisionmakers have about public preferences. Mobilizing citizens and generating new political information are key functions of interest groups in a democracy (Mansbridge 1992; Mahoney 2007). Campaigns inform agencies about the distribution and intensity of opinions that are often too nuanced to estimate a priori. Many questions that arise in rulemaking lack analogous public opinion polling questions, making mass commenting a unique source of political information. As with public opinion on many specific policy issues, most members of the public and their elected representatives may only learn about the issue and take a position as a result of a public pressure campaign (Hutchings 2003). I thus consider public demands to be a latent factor in my model of policymaking (Figure 2.4. Public demands shape the decisions of groups who lobby in rulemaking. If they believe the attentive public is on their side, groups may attempt to reveal this political information to policymakers by launching a mass mobilization campaign. The public response to the campaign depends on the extent that the attentive public is passionate about the issue. Figure 2.4: Incorporating Political Information into Models of Bureaucratic Policymaking Figure 2.4 amends the “Classic Model” of interest group lobbying (Figure 2.3) to incorporate political information about the attentive public. In addition to providing technical information through sophisticated comments, an organization may mobilize supporters. The more support a group has, the more successful this mobilization effort will be. Large-scale engagement may produce several types of relevant political information. The most direct and obvious is the expressed “public opinion” that policymakers observe.15 The causal process visualized in Figure 2.4 may only operate under certain conditions. The success of a mobilizing effort depends on whether a group’s perception of latent public demands (the diagonal arrow between “Latent Public Demands” and “Lobbying Strategy”) reflects the public response to a mobilizing effort (the horizontal arrow between “Latent Public Demands” and “Mass Engagement”). The influence of political information on policy (the arrow between “Political Information” and “Policy Response”) depends on the institutional processes by which agencies receive and interpret information. We may only expect to observe mass mobilization influencing a particular policy only if the mobilization effort was aimed at influencing that policy, rather than using the public comment the period to build organizational membership or power more generally (see Carpenter and Moore (2014)). 2.3 Hypotheses About the Drivers of Mass Mobilization 2.3.1 Types of campaigns The outcomes of mass mobilization depend, in part, on the aims of a campaign. I distinguish group campaigns by which of three distinct aims they pursue: (1) to win concessions by going public, (2) to disrupt a perceived consensus, or (3) to go down fighting. Going public and disrupting a perceived consensus are forms of proactive and reactive outside lobbying, respectively. Here, going down fighting describes any situation where the organization does not expect to influence policy but mobilizes for other reasons. Going public. Coalitions “go public” when they believe that expanding the scope of conflict gives them an advantage.16 As these are the coalitions that believe they have more intense public support, mass engagement is likely to skew heavily toward this side.17 Indeed, Potter (2017a) finds that advocacy group-driven campaigns mobilize far more people on average than industry-driven campaigns. Additionally, many people may be inspired indirectly (e.g., through news stories) or to engage with more effort (e.g., writing longer comments) than people mobilized by the side with less public support. This is important because political information may be especially influential if decisionmakers perceive a consensus.18 Hypothesis 1a: Lobbying coalitions mobilize mass engagement when they perceive the attentive public is on their side, have sufficient resources, and perceive an opportunity to influence policy. The key part of this hypothesis is that mobilizing is correlated with existing public support, what might be called “grass-roots” support. The converse, that organizations mobilize when they have less public support, could also be true. For example, business groups who are already advantaged in low salience rulemaking may decide to leverage their superior resources further to mobilize support to alter a bad reputation or bolster claims that they represent more than their private interest. If mobilization most often takes this “astroturf” form, this would be evidence against Hypothesis 1a and Schattschneider’s argument that it is the disadvantaged who seek to expand the scope of the conflict. The latter parts of Hypothesis 1a regarding sufficient resources and political opportunity are scope conditions. Most organizations that are disadvantaged in low-salience rulemaking also lack resources to launch mass mobilization campaigns. If an organization does not perceive a lobbying opportunity, it would be incorrect to call mobilization a lobbying strategy. Many factors may contribute to perceived political opportunities. For example, Moore (2017) finds that agencies that use high levels of expertise (as defined by Selin (2015)) receive fewer comments, possibly because mobilizing organizations perceive these rules to be less open to influence. Disrupting a perceived consensus. I theorize that when coalitions with less public support mobilize, it is a reaction to their opponents. Because the impression of consensus is powerful, when a coalition goes public, an opposing coalition may countermobilize. Because I theorize that these are coalitions with less intense public support and its aim is prevent a perceived consensus, I expect such campaigns to engage fewer people, less effort per person, and yield a smaller portion of indirect engagement. Hypothesis 1b: When a lobbying coalition with more intense public support mobilizes successfully in response to an opportunity to influence policy, opposing coalitions with less public support are more likely to countermobilize, but with proportionally smaller results. The first part of Hypothesis 1b would be undermined if lobbying organizations with less public support are no more likely to engage in outside lobbying when their opponents do so. While Potter (2017a) found industry groups were no more likely to advocate for rules to be strengthened, weakened or withdrawn, this does not mean that they are no more likely to mobilize when their opponents do so. The second part of this hypothesis, that countermobilization is proportionally smaller, rests on the intuition that the scale and intensity of public engagement are moderated by preexisting support for the proposition that people are being asked to support. It is possible that the “potentially mobilized” segments of the public are unrelated to public support before being contacted by the campaign, for example, if mobilization is driven more by partisan identities than issue preferences. Going down fighting. Finally, campaigns may target supporters rather than policymakers. Sometimes organizations “go down fighting” to fulfill supporters’ expectations. For example, Carpenter et al. (2020) finds that anti-slavery petitions were this type of campaign where “the most important readers of a petition are its signatories.” In the context of notice and comment rulemaking, after a draft policy is published, failing to secure one’s demands is always a loss, so I use “going down fighting” as shorthand for campaigns aimed primarily at fulfilling member, donor, or supporter expectations and related logics that are internal to the organization, including member retention or recruitment (Carpenter and Moore (2014), Carpenter et al. (2020)), fundraising, or satisfying a board of directors. For example, as Figure 2.5 shows, the Sierra Club uses campaigns to collect contact information of supporters and potential members. In this case, given the executive-branch transition between 2010 when the rule was initiated and 2017 when it was delayed, the Sierra Club may have had little hope of protecting methane pollution standards, but for members of the public who wanted to voice their opinion, the Sierra Club created an easy way to do so, as long as users consented to “receive periodic communication from the Sierra Club.” Figure 2.5: The Sierra Club Collects Contact Information Through Mass Mobilization Campaign While such campaigns may engage many people, they are unlikely to affect policy or to inspire countermobilization. I expect such campaigns to occur on rules that have high partisan salience (e.g., rules following major legislation passed on a narrow vote), rules that propose large shifts on policy issues dear to member-funded public interest groups, or rulemaking started shortly after presidential transitions when executive-branch agendas shift more quickly than public opinion. When a lobbying coalition with more intense public support successfully mobilizes for reasons other than influencing policy, opposing coalitions with less public support are not more likely to countermobilize. Going public and going down fighting may be difficult to distinguish in the observed public response. Indeed, members of the public may poorly understand the different chances of success in each case. However, lobbying organization do likely know their chances of success and should thus invest less in sophisticated insider lobbying under the going down fighting strategy. By identify cases where coalitions engage in large public campaigns without corresponding investment in sophisticated lobbying, I can assess whether countermobilization and is indeed less likely in these cases. Table 2.1 specifies the general pattern of engagement suggested by each of the three reasons behind mass-comment campaigns. Table 2.1: Observable Differences in Lobbying Strategies Inside lobbying (eg., technical information provided) Outside lobbying (e.g., the number of comments from a public pressure campaign) “Normal” lobbying High None “Going public” High High “Disrupting consensus” High Low “Going down fighting” Low High As Table 2.1 suggests, the relevant statistic distinguishing patterns is the relative number of each type of comment on each side on a given rulemaking docket. Even among rules targeted by campaigns, salience varies significantly and thus “high” and “low” numbers of comments will differ across rules. Importantly, even campaigns that achieve very low public response rates appear in these data. Because campaigns aim to collect thousands of comments, it is implausible that even the most unpopular position would achieve no supportive responses. For example, Potter (2017a) found Poultry Producers averaging only 319 comments per campaign. While this is far from the Sierra Club’s average of 17,325 comments per campaign, it is also far from zero. 2.3.1.1 Public and private goods. While coalitions may form around various material and ideological conflicts, those most likely to be advantaged by going public or going down fighting are public interest groups—organizations primarily serving an idea of the public good rather than the material interests of their members.19 Thus, I theorize that mass mobilization is most likely to occur in conflicts of public versus private interests or public versus public interests (i.e., between coalitions led by groups with distinct cultural ideals or desired public goods), provided they have sufficient resources to run a campaign. If true, one implication is that mass mobilization will systematically run counter to concentrated business interests where they conflict with the values of public interest groups with sufficient resources to mobilize. Hypothesis 1c: Public interest group coalitions mobilize more often than business-driven coalitions. Hypothesis 1c posits a conditional logic in the decision to mobilize. If resources purely determined outside lobbying, business-driven coalitions would often dominate, as they do elsewhere. However, I argue, because outside lobbying can alter the decision environment, those who have the advantage in the usual rulemaking process (where a more limited set of actors participate) have little incentive to expand the scope of the conflict. 2.4 Types of public engagement I classify supporters into three types that help describe key pieces of political information. I illustrate these types in the context of public comments. Comments that are exact copies of a form letter are akin to petition signatures from supporters who were engaged by a campaign to comment with minimal effort. Commenters that also take time to add text indicate more intense preferences. Finally, commenters who express solidarity in similar but distinct phrases indicate they were engaged indirectly, perhaps by a news story or a social media post about the campaign, as campaign messages spread beyond those initially targeted.20 Because the success of a mobilization effort is moderated by public support, broader public interest group coalitions ought to mobilize more people, more effort per person, and more people indirectly for the same amount of mobilization effort (e.g., spending or solicitations). Public interest group coalitions mobilize more successfully than business-driven coalitions. Indicators of success include (1) the number of comments supporting a coalition (2) the effort per comment (3) the number of comments mobilized indirectly. The size of each group thus offers political information to policymakers, including coalition resources, the intensity of sentiment, and the potential for conflict to spread. The first two types signal two kinds of intensity or resolve. First, they show the mobilizers’ willingness to commit resources to the issue. Second, costly actions show the intensity of opinions among the mobilized segment of the public (Dunleavy 1991). The number of people engaged by a campaign is not strictly proportional to an organization’s investment. The less people care, the more it costs to mobilize them. The third type indicates potential contagion. Indications that messages spread beyond those initially targeted may be especially powerful (Kollman 1998). Information about organizational resolve, the intensity of public demands, and contagiousness are thus produced, but such political information will only influence decisions if these signals are processed in a way that captures this information and relays it to decisionmakers. These organizational processes may vary significantly across agencies. 2.5 Methods: Measuring Public Pressure and Political Information In this section, I develop methods to attribute mass comments to the campaigns that mobilized them and measure the intensity of preferences expressed. To link individual comments to the more sophisticated lobbying efforts they support, I use textual similarity to identify clusters of similar comments, reflecting formal and informal coalitions. Comments with identical text (if any) indicate which groups and coalitions ran a mass comment campaign. Within each campaign, I measure the intensity and potential for the movement to grow. To measure intensity, I examine the ratio of high-effort and low-effort comments. To measure the potential to grow, I measure the number of comments mobilized indirectly by the campaign (i.e., those that support a campaign but do not include text provided by the campaign). The result is several new measures of participation in bureaucratic policymaking. 2.5.1 Data. I collected a corpus of approximately 70 million comments via the regulations.gov API. About 50 million of these comments are on proposed rules (over 16,000 proposed rules from 144 agencies from 2005 to 2018). I then linked these comments to other data on the rules from the Unified Agenda and Office of Information and Regulatory Affairs Reports on draft rules sent to them for review. Summary statistics for these data are available in the Appendix. 2.5.2 Who lobbies? Unfortunately, metadata on the authors of comments and their organizational affiliations are inconsistent and incomplete. As this information is key to identifying influential actors, improving these data was a significant data-organization task. 2.5.2.1 Mobilizing organizations. Through an iterative combination of automated search methods and hand-coding, I identify organizations for over 40 million comments, including all organizations responsible for mobilizing 100 or more comments with repeated text–either identical text or partially unique texts that contain shared language. I then searched comment texts for mentions of these organizations’ names to complete missing information on the mobilizing organization. The top 100 mobilizing organizations each mobilized between 55 thousand and 4.2 million comments. Figure 2.6 shows the top organizers of comments posted to regulations.gov. Figure 2.6: Top mobilizers of comments posted to regulations.gov 2.5.3 Who lobbies together? Having identified who is participating in rulemaking, the next step is to determine who is lobbying together. Studies of rulemaking stress the importance of coalitions (J. W. Yackee and Yackee 2006, Dwidar2019). Scholars have measured coalitions of organized groups but have yet to attribute citizen comments to the coalition that mobilized them. 2.5.3.1 I identify coalitions using text re-use and clustering methods. I identify comments that are not identical but share a 10-word (or “10-gram”) string using a moving window function looping over each possible pair of texts to identify matches.21 When actors sign onto the same comment, it is clear that they are lobbying together. However, various businesses, advocacy groups, and citizens often comment separately, even when they are aligned. Thus, in addition to mapping text re-use, for rules with a large number of comments, I use statistical models of text to classify comments into coalitions. I cluster documents by the frequency with which they use different words. Being classified together does not mean that the documents all address exactly the same distribution of substantive issues, just that they use similar words relative to the full set of documents. I start by modeling all comments on each rule (collapsing identical comments to one document) with two and three clusters, which I then inspect to see how well the comments of named organizations were classified. If the two cluster model most sensibly describes the conflict, I label these clusters “pro” and “con” If the three-cluster model more sensibly describes the conflict, I label these clusters as “pro, con, other.” If neither fits well, I increase the number of clusters as needed. Figure 2.7: K-means clustering fails to capture coalitions when nearly all comments oppose a regulation The asymmetry in expressed support for most rules presents challenges for unsupervised clustering because much of the variation in comment texts is within-coalition variation. For example, one of the most common clustering methods, k-means clustering, often captures within-coalition variation. Figure 2.7 shows k-means clusters based on a normalized measure of word frequency (term-frequency/inverse-document-frequency) compared to two principal components of variation. Neither k-means nor principal components analysis is well suited to identifying the small number of comments supporting the Park Service’s proposed restrictions on protests in Washington DC. Two strategies may improve clustering. First, even partial text re-use generally indicates that comments belong to the same coalition. For example, as seen at the top of Figure 2.7, models may be restricted to cluster the large number of comments beginning with “As a citizen who has frequently participated” in the same coalition even if they go on to add different personal anecdotes about why protest rights are important to them. Thus, clustering methods could be restricted to group partially copied texts, as well as entirely copied texts. Second, Bayesian mixture model may better recover pro and con clusters, especially with strong priors comments using positive and negative sentiment words belong together. 2.5.4 Measuring the volume, intensity, and potential contagion of public engagement. I measure variation in engagement in three ways, corresponding to the three types of comments described above. Volume. First, I measure the total number of comments on the rule. As commenting results from multiple processes: a coalition deciding to lobby at all, a coalition deciding to mobilize, and response to the campaign the distribution contains many cases where groups may have had success mobilizing but never reached the choice of whether to mobilize or not. Perhaps they were unaware of the draft rule. Once the decision to mobilize has been reached and made, the response to mobilizing is a count process. Thus, I expect the count of comments across rules to follow a zero-inflated negative binomial distribution. Effort. I measure effort per comment by the number of words people write, omitting any to text longer than ten words that is not unique, usually because a mobilizing organization provided it. For example, the Sierra Club mobilized more than 47,710 people to submit exactly the same text on the delay of the methane pollution rule, but 7,452 people also took the time to write a personalized comment in addition to the text provided (see Figure 2.5). However, we may not observe people who have low levels of passion for the issue because they either do not cross the effort threshold required to comment or opt to write nothing more than the form letter. Thus, while effort measured by the number of words people write may be normally distributed, I assume that the low end of the observed distribution is truncated. Contagion. Mass-comment campaigns have wildly different results. Some submit a clean 10,000 copies of (signatures on) the same comment. Others “go viral”—inspiring a mess of further engagement where the original messages are translated through social media posts and news stories. To identify people who were plausibly mobilized indirectly by a campaign, I count the number of people who use a similar distribution of words to that of the form letter but fewer than ten words matching any other comment. This is a regular count process. 2.6 Results: Patterns of Public Engagement in Rulemaking 2.6.1 Most comments result from mass-comment campaigns. Figure 2.8 shows all comments posted on regulations.gov over time by whether they are exact or partial copies of another comment or not. I call comments that have between 2 and 99 identical copies, “medium batch” because such comments may reflect coordinated efforts among interest groups that do not include a public pressure strategy that involves mobilizing ordinary people. Even relatively unsuccessful public pressure campaigns yield far more than 99 comments. Comments that have either 100 or more identical copies or were uploaded in bulk batches of at least 100 are then “mass comments” that were certainly mobilized by a public pressure campaign. Figure 2.8 shows that public pressure campaigns mobilize the vast majority of comments. Over 80% of the 48 million comments on proposed rules posted to regulations.gov were mobilized by just 100 organizations. In other words, most comments are from ordinary people mobilized by a few public interest organizations. Figure 2.8: Comments on Draft Rules Posted to Regulations.gov 2006-2018 The right pane of Figure 2.8 shows results from a sample of several million comments for which I have digitized texts. Many of these comments appear to support proposed agency rules. A rough measure of support (whether the comment text includes \" support \" or \" oppose “) shows that many more comments mention support, until 2018 when there is a fairly dramatic reversal in the share of comments mentioning”support \" compared to those mentioning “oppose” (Figure 2.8. This may be a function of the changing regulatory agenda due to the change in presidential administration. However, support and oppose are not used in all comments and do not always indicate support for a rule. 2.6.2 Most comments occur on a small number of salient rules. Approximately one-third of public comments posted to regulations.gov were received on just ten regulations shown in Figure 2.9. Figure 2.9: Top 10 Dockets Receiving the Most Comments on regulations.gov and the top 20 Mobilizers 2.6.3 Is civic engagement resulting from public pressure campaigns better understood as “astroturf” or “grassroots” participation? In short, I find much more evidence of grassroots participation than astroturf participation. 2.6.4 A coalition of public-interest organizations mobilize most comments. As Figure 2.9 shows, the most prolific mobilizers are environmental groups. On five out of the top ten dockets (here including rulemaking and non-rulemaking dockets), a similar coalition of groups mobilized the majority of public comments. In part, this is because the Environmental Protection Agency produces a large share of the substantive rules posted to regulations.gov. However, it is notable that, on the top ten dockets, 19 of the top 20 mobilizers generally lobby together. America’s Energy Cooperatives (AEC), an industry association, stands out as the lone mobilizer on behalf of material interest for its members. Notably, it only mobilized significantly on the Clean Power Plan but not on the subsequent Clean Power Plan repeal. If public interest group mobilizing on the Clean Power Plan was an example of “going public” to pressure the Obama administration and then “going down fighting” in the face of the Trump administration’s repeal, industry counter-mobilization responding to the first, but not the second aligns with Hypothesis 1b. If AEC found their policy goals in the Clean Power Plan rulemaking threatened by the political information being generated by environmental groups, it would make sense to devote resources to their own public pressure campaign to disrupt any perceived consensus. Likewise, if AEC was not concerned that environmental group mobilizing would affect the Clean Power Plan repeal, sponsoring a public pressure campaign would be a poor investment. References "],["oversight-do-public-pressure-campaigns-influence-congressional-oversight.html", "Chapter 3 Oversight: Do Public Pressure Campaigns Influence Congressional Oversight?", " Chapter 3 Oversight: Do Public Pressure Campaigns Influence Congressional Oversight? Abstract This chapter examines the effect of public pressure campaigns on congressional oversight. I assess whether legislators are more likely to engage in rulemaking when advocacy groups mobilize public pressure. This involves collecting and coding thousands of comments from Members of Congress on proposed rules with and without public pressure campaigns. These data also allow me to assess congressional oversight as a mediator in policy influence, i.e., the extent to which public pressure campaigns affect agency decisionmakers directly or indirectly through their effects on elected officials’ oversight behaviors. "],["policy-influence-do-public-pressure-campaigns-influence-bureaucratic-policymaking.html", "Chapter 4 Policy Influence: Do Public Pressure Campaigns Influence Bureaucratic Policymaking? 4.1 Introduction 4.2 Data 4.3 Methods 4.4 Modeling the direct relationship 4.5 Examples of hand-coded lobbying success", " Chapter 4 Policy Influence: Do Public Pressure Campaigns Influence Bureaucratic Policymaking? See the preanalysis plan for this chapter here. Abstract I assess whether public pressure campaigns increase lobbying success in agency rulemaking using a mix of hand-coding and computational text analysis methods. To measure lobbying success, I develop computational methods to identify lobbying coalitions and estimate lobbying success for all rules posted for comment on regulations.gov. These methods are validated against a random sample of 100 rules with a mass-comment campaign and 100 rules without a mass comment campaign that I hand-code for whether each coalition got the policy outcome they sought. I then assess potential mechanisms by which mass public engagement may affect policy. Each mechanism involves a distinct type of information revealed to decisionmakers. Of primary interest is the extent to which public pressure campaigns affect agency decisionmakers directly or indirectly through their effects on elected officials’ oversight behaviors. I test this by assessing congressional oversight as a causal mediator using a subset of rules where I collect and code correspondence from Member of Congress to agencies about proposed agency rules. 4.1 Introduction I assess the relationship between the number of public comments and the amount of change between draft and final policy texts. Next, I assess the relationship between the number of people mobilized by each campaign and whether the campaign achieved its policy goals. Finally, I theorize and test four mechanisms by which public input may affect bureaucratic policymaking. Each mechanism involves a distinct type of information that pressure campaigns may relay to policymakers: technical information, information about the likelihood of political consequences, information about the preferences of elected officials, or information about the preferences of the attentive public. Because scholarship on bureaucratic policymaking has focused on the power of technical information, where insider lobbying is most likely to matter and where outside strategies are least likely to matter, political scientists have largely overlooked mass mobilization as a tactic. I find evidence consistent with the observable implications of mass comment campaigns influencing policymaking through \\[non-null results\\] but no evidence that mass engagement affects rulemaking processes or outcomes through \\[null results\\]. 4.2 Data I create an original dataset that combines several sources of data on U.S. federal agency rulemaking. The core data are the texts of draft and final rules and public comments on these proposed rules. This includes all 16 thousand proposed rules from 144 agencies (as defined by regulations.gov) that were open for comment on regulations.gov between 2005 and 2018, that received at least one comment from an organization, and that saw a final agency action between 2005 and 2019. There are over 50 million comments on this set of rules. I scrape draft and final rule texts from federalregister.gov and comments submitted as attachments or by mail from regulations.gov. I retrieve comments submitted directly on regulations.gov and metadata on rules and comments (such as the dates that the proposed rule was open for comment and whether the agency identified the organization submitting the comment) from the regulations.gov API. I add additional metadata on rules (such as whether the rule was considered “significant”) from the Unified Agenda published by the Office of Information and Regulatory Affairs (reginfo.gov). Finally, to better capture positions expressed by Members of Congress on proposed rules, I supplement congressional comments posted on regulations.gov with Freedom of Information Act Requests for all communication from Members of Congress to each agency on proposed rules from 2007 to 2019.22 The combined dataset has over 50 million observations of one public or legislator comment on a proposed rule. I attempt to identify the organization(s) that submitted or mobilized each comment by extracting all organization names from the comment text. For comments that do not reference an organization, I am often able to identify organizations with an internet search using the comment’s text. I then identify lobbying coalitions by clustering comments that use similar phrases or word frequencies. Co-signed comments are always assigned to the same coalition. Likewise, form-letter comments are always assigned to the same coalition.23 Because my hypotheses are about the influence of organizations and coalitions, for analysis, I collapse these data to one observation per organization or coalition per proposed rule and identify the main substantive comment submitted by each organization’s staff or lawyers, which are usually much longer than supporting comments like form letters. For hand-coding, I first select a random sample of 100 proposed rules with a mass-comment campaign and then selecting a matched sample of 100 proposed rules without a mass comment campaign. Matching prioritizes, presidential administration, policy area (following Policy Agendas Project coding), rule significance, department, agency, subagency, and proposed rule length, respectively.24 This hand-coded sample is several times larger than leading studies using hand-coding and includes rules with very large and small numbers of comments that previous studies exclude. The full sample is four hundred times larger.25 4.3 Methods The most direct way to assess the hypothesis that mass engagement increases lobbying success is to assess the magnitude of the relationship between the number of comments that a coalition mobilizes and its lobbying success. However, public pressure campaigns may only be effective under certain conditions. Thus, I first assess the main relationship and then assess evidence for or against different potential causal pathways of influence. 4.3.1 The Dependent Variable: Lobbying Success The dependent variable is the extent to which a lobbying coalition got the policy outcome they sought, which I measure in three ways. First, on a sample of rules, I hand-code lobbying success for each lobbying coalition, comparing the change between the draft and final rule to each organization’s demands on a five-point scale from “mostly as requested” to “significantly different/opposite than requested.” To do this, I first identify organizational comments. For each organization, I identify the main overall demand and the top three specific demands and the corresponding parts of the draft and final rule texts.26 I then code overall lobbying success and lobbying success on each specific demand for each organization and coalition. Both the overall score and average score across specific demands both fall on the interval from -1 (“significantly different”) to 1 (“mostly as requested”). Second, I use methods similar to automated plagiarism detection algorithms to identify changes between a draft and final rule that were suggested in a comment. Specifically, I count the number of words in phrases of at least ten words that appear in the comment and final rule, but not the draft rule. To do this, I first identify new or changed text in the final rule by removing all 10-word or longer phrases retained from the draft rule. I then search each comment for any 10-word or longer phrases shared with the new rule text and count the total number of shared words in these shared phrases. Finally, I normalize this count of “copied” words across shorter and longer comments by dividing it by the total number of words in the comment. This measure falls between 0 (zero percent of words from the comment added to the final rule) and 1 (100 percent of words from the comment added to the final rule). As a robustness check, I also use the non-normalized version of this variable, i.e. the raw number of “copied” words. Third, I capture a broader dimension of lobbying success by modeling the similarity in word frequency distributions between comments and changes to the rule. New or changed text is identified as described above, except that I also include the rule’s preamble and the agency’s responses to comments. Agencies write lengthy justifications of their decisions in response to some comments but not others. By including preambles and responses to comments, this measure captures attention to a comment’s demands and the extent to which the agency adopts a comment’s discursive framing (i.e. the distribution of words it uses). I us cosign similarity to scale the word frequencies used by each comment relative to those in changes between draft and final rule.27 This measure falls between 0 (no common words) and 1 (exactly the same distribution of words). To assess the performance of these automated methods (text-reuse and word-frequency similarity), I calculate the correlation between these scores and my hand-coded 5-point scale for rules in the hand-coded sample where a final rule was published. As the automated methods apply at the organization-level, coalition scores are those from the lead organization–by default, the organization(s) with the longest comment. At the coalition level, the correlation between hand-coded influence is __ with the text-reuse method and __ with the word-frequency method. 4.3.2 The Main Predictor Variable The number of supportive comments generated by a public pressure campaign (the main variable of interest) is a tally of all comments mobilized by each organization or coalition that ran a mass-comment campaign on a proposed rule. Because the marginal impact of additional comments likely diminishes, the number of comments is logged. This does not include the main substantive comments submitted by an organization’s staff or lawyers. Nor does it include comments that are not affiliated with the organization or coalition. If an organization mobilizes more than 1000 comments or 100 identical comments on a proposed rule, I code that organization, its coalition, and the proposed rule as having a mass comment campaign. Where organizational comments are not supported by a mass comment campaign log mass comments takes a value of 0. 4.3.3 Explanatory variables Other predictors of lobbying success in the models below are the length of the (lead) organization’s comment, whether the coalition lobbies unopposed, the size of the lobbying coalition, and whether the coalition is business-led. Comment length is normalized by dividing the number of words in the comment by the number of words in the proposed rule, thus capturing the complexity of the comment relative to the complexity of the proposed rule. The number and type(s) of organization(s) is an attribute of each coalition (e.g. a business-led coalition with N organizational members). Coalition size is the number of distinct commenting organizations in the coalition (including those that co-sign a comment). For organizations lobbying alone, coalition size is 1. A coalition is unopposed when no opposing organizations comments. I code a coalition as business-led if the majority of commenting organizations are for-profit businesses, or if upon investigation, I find it to be primarily led or sponsored by for-profit businesses.28 4.3.4 Limitations The two main limitations of this design both bias estimates of public pressure campaign influence toward zero. First, lobbying success may take forms other than changes in policy texts. Agencies may speed up or delay finalizing a rule, extend the comment period, or delay the date at which the rule goes into effect. Indeed, commentors often request speedy or delayed rule finalization, comment period extensions, or delayed effective dates. I capture these potential outcomes in my hand-coding but not in the two automated methods, which apply only to observations with a final rule text. Likewise, there there is no change between draft and final rule, both automated methods necessarily record lobbying success as 0, even if a comment asks an agency to publish a rule without change.29 Second, bureaucrats may anticipate public pressure campaigns when writing draft rules, muting the observed relationship between public pressure and rule change at the final rule stage of the policy process. 4.4 Modeling the direct relationship For all three measures of lobbying success, I assess the relationship between lobbying success and mass comments by modeling coalition \\(i\\)’s lobbying success, \\(y_i\\) as a combination of the relative length of the (lead) organizations comment, whether the coalition is unopposed, the coalition’s size, whether it is a business coalition, and the logged number of mass comments. I estimate OLS30 regression: \\[ y_i = \\beta_0 + \\beta_1 log(comments_i) + \\beta_2 length_i + \\beta_3 unopposed_i + \\beta_4 size_i + \\beta_5 business_i + \\epsilon_i \\] 4.4.1 Modeling mediated relationships To estimate mediated effects, I estimate the average conditional marginal effect (ACME) and the proportion of the total effect attributed to mediation through congressional support (comments or other communication from Members of Congress supporting the coalition’s position on the proposed rule). As developed by Imai et al. (2010), this involves first estimating a model of the proposed mediator as a combination of covariates, \\(X\\) (length, unopposed, size, and business) and then the outcome as a combination of the mediator, congressional support, and covariates, \\(X\\). Mediator model: \\[ congressional\\ support_i = \\beta_0 + \\beta_1 log(comments_i) + \\beta_{2-n} X_i + \\epsilon_i \\] Outcome model: \\[ y_i = \\beta_0 + \\beta_1 log(comments_i) + \\beta_2 congressional\\ support_i + \\beta_{3-n} X_i + \\epsilon_i \\] 4.5 Examples of hand-coded lobbying success 2015 Waters of the United States Rule: In response to litigation over which waters were protected by the Clean Water Act, the Environmental Protection Agency and Army Corp of Engineers proposed a rule based on a legal theory articulated by Justice Kennedy, which was more expansive than Justice Scalia’s. The Natural Resources Defense Council submitted a 69-page highly technical comment “on behalf of the Natural Resources Defense Council…, the Sierra Club, the Conservation Law Foundation, the League of Conservation Voters, Clean Water Action, and Environment America” supporting the proposed rule: “we strongly support EPA’s and the Corps’ efforts to clarify which waters are protected by the Clean Water Act. We urge the agencies to strengthen the proposal and move quickly to finalize it…” I coded this as support for the rule change, specifically not going far enough. I also coded it as requesting speedy publication. NRDC makes four substantive requests: one about retaining language in the proposed rule (“proposed protections for tributaries and adjacent waters…must be included in the final rule”) and three proposed changes (“we describe three key aspects of the rule that must be strengthened”).31 These demands provide specific keywords and phrases for which to search in the draft and final rule text. A coalition of 15 environmental organizations mobilized over 944,000 comments, over half (518,963) were mobilized by the four above organizations: 2421,641 by Environment America, 108,076 by NRDC, 101,496 by clean water action, and 67,750 by the Sierra Club. Other coalition partners included EarthJustice (99,973 comments) and Organizing for Action (formerly president Obama’s campaign organization, 69,369 comments). This is the upper tail end of the distribution. This coalition made sophisticated recommendations and mobilized a million people. The final rule moved in the direction requested by NRDC’s coalition, but to a lesser extent than requested–what I code as “some desired changs.”\" As NRDC et al. requested, the final rule retained the language protecting tributaries and adjacent waters and added some protections for “other waters” like prairie potholes and vernal pools, but EPA did not alter the exemptions for ditches and waste treatment systems. Comparing the draft and final with text reuse allows us to count the number words that belong to 10-word phrases that appear in both the draft and final, those that appear only in the draft, and those that appear only in the final. For the 2015 Waters Of The U.S. rule, 15 thousand words were deleted, 37 thousand words were added, and 22 thousand words were kept the same. This means that more words “changed” than remained the same, specifically 69% of words appearing in the draft or final were part were either deleted or added. For this coalition, the dependent variable, coalitions success is 1, coalition size is 15, business coalition is 0, comment length is 69/88, 0.78, and log mass comments is log(943,931), 13.76. 2009 Fine Particle National Ambient Air Quality Standards: In 2008, the EPA proposed a rule expanding air quality protections. Because measuring small particles of air pollution was once difficult, measurements of large particulates were allowed as a surrogate measure for fine particles under EPA’s 1977 PM10 Surrogate Policy. EPA proposed eliminating this policy, thus requiring regulated entities and state regulators to measure and enforce limits on much finer particles of air pollution. EPA received 163 comments on the rule, 129 from businesses, business associations such as the American Petroleum Institute and The Chamber of Commerce, and state regulators that opposed the rule. Most of these were short and cited their support for the 63-page comment from the PM Group, “an ad hoc group of industry trade associations” that opposed the regulation of fine particulate matter. Six state regulators, including Oregon’s, only requested delayed implication of the rule until they next revised their State Implementation Plans (SIPs) for Prevention of Significant Deterioration (PSD). EarthJustice supported the rule but opposed the idea that the cost of measuring fine particles should be a consideration. On behalf of the Sierra Club, the Clean Air Task Force, EarthJustice commented: “We support EPA’s proposal to get rid of the policy but reject the line of questioning as to the benefits and costs associated with ending a policy that is illegal.” The EarthJustice-led coalition also opposed delaying implementation: “EPA must immediately end any use of the Surrogate Policy – either by”grandfathered\" sources or sources in states with SIP‐approved PSD programs – and may not consider whether some flexibility or transition is warranted by policy considerations.\" The final rule did eliminate the Surrate Policy but allowed states to delay implementation and enforcement until the next scheduled revision of their Implementation Plans. I code this as the EarthJustice coalition getting most of what they requested, but not a complete loss for the regulated coalition. For the PM Group coalition, the dependent variable, coalitions success is -1, coalition size is 129, business coalition is 1, comment length is 63/85, 0.74, and log mass comments is 0. For the State of Oregon’s coalition, the dependent variable, coalitions success is 2, coalition size is 6, business coalition is 0, comment length is 5/85, 0.06, and log mass comments is 0. For the EarthJustice coalition, the dependent variable, coalitions success is 1, coalition size is 3, business coalition is 0, comment length is 7/85, 0.08, and log mass comments is 0. Many agencies provided records of their congressional correspondence going back to 2005 or earlier.↩︎ The same comment text is attributed to each signatory of a comment. For more on how I identify organizations and coalitions, see Chapter 2, “Why Do Agencies (Sometimes) Get So Much Mail?”.↩︎ For more on policy area coding, see “Trends in U.S. Executive-branch Policymaking 1980-2016” in Chapter 1.↩︎ Except for comment texts and attachments, these data are available separately and combined on github.com/judgelord/rulemaking.↩︎ This does not capture rule changes on which an organization did not comment. The codebook is available here. See examples of coded cases here.↩︎ For the subset of rules with five or more organizational comments, I create a more sophisticated measure of word frequency similarity by averaging the absolute value of differences in topic proportions \\(\\theta\\) between the comment and new rule text across 45 LDA models of all organizational comments estimated with 5 through 50 topics, normalized by the number of topics \\(k_n\\) and the number of models such that \\(y_i\\) falls between 0 (completely different estimated topic proportions) and 1 (exactly the same topic proportions), \\(y_i = \\sum_{5}^{n=50}(\\frac{\\sum|\\theta_{rule\\ change_i|k=n}-\\theta_{comment_i|k=n}|}{n})*\\frac{1}{45}\\). For more on these methods of measuring textual similarity, see “Measuring Change and Influence in Budget Texts”.↩︎ For more on how I identify types of organizations and coalitions, see Chapter 2, “Why Do Agencies (Sometimes) Get So Much Mail?”.↩︎ Time allowing, I will hand-code a larger sample of proposed rules where no final rule was published so that these cases can be included in the analysis. Likewise, I will identify cases where organizations requested rules to be published as-is and recode these cases by hand.↩︎ See OLS model estimates with simulated data. I also estimate hand-coded lobbying success with beta regression and ordered logit, which are more appropriate but less interpretable. For the automated measures of lobbying success, I estimate beta regression models with the same variables.↩︎ These three aspects are: (1) “The Rule Should Categorically Protect Certain “Other Waters” including Vernal Pools, Pocosins, Sinkhole Wetlands, Rainwater Basin Wetlands, Sand Hills Wetlands, Playa Lakes, Interdunal Wetlands, Carolina and Delmarva Bays, and Other Coastal Plain Depressional Wetlands, and Prairie Potholes. Furthermore, “Other ‘Isolated’ Waters Substantially Affect Interstate Commerce and Should be Categorically Protected Under the Agencies’ Commerce Clause Authority.” (2) “The Rule Should Not Exempt Ditches Without a Scientific Basis” (3) “The Rule Should Limit the Current Exemption for Waste Treatment Systems”↩︎ "],["the-environmental-justice-movement-and-technocratic-policymaking.html", "Chapter 5 The Environmental Justice Movement and Technocratic Policymaking 5.1 Introduction 5.2 Theory 5.3 Testing the Theory 5.4 Results 5.5 Conclusion", " Chapter 5 The Environmental Justice Movement and Technocratic Policymaking Abstract Social movements play a critical role in advancing landmark statutes recognizing new rights and social values. Likewise, a lack of movement pressure is a leading explanation for the failure of policy efforts. Yet, we have little systematic evidence about the impact of social movements on policy. To what extent do movements shape the thousands of policies that governments make every year? I examine how social movements affect policymaking by assessing the environmental justice movement’s impact on 25,000 policy documents from 40 U.S. federal agencies from 1993 to 2020. Leveraging a new dataset of 42,000,000 public comments on these policies, I find that when public comments raise environmental justice concerns, these concerns are more likely to be addressed in the final rule. Effect sizes vary across agencies, possibly due to the alignment of environmental justice aims with agency missions., The magnitude of public pressure also matters. When more groups and individuals raise environmental justice concerns, policy texts are more likely to change, even when controlling for overall levels of public attention. These findings suggest that distributive justice claims and levels of public attention and pressure systematically affect policymaking. See the working paper version of this chapter here 5.1 Introduction Social movements like the civil rights movement and the environmental movement are understood to have played a critical role in advancing landmark statutes recognizing new rights and social values. Likewise, a lack of movement pressure is a leading explanation for the failure of policy efforts to address issues like climate change (Skocpol 2013). Yet, we have little systematic evidence about the impact of social movements on modern policymaking. To what extent do movements shape the thousands of policies the government makes every year? I examine how social movements affect policymaking by assessing the environmental justice movement’s impact on 25 thousand policy processes in 40 U.S. federal agencies from 1993 to 2020. Environmental justice concerns focus on unequal access to healthy environments and protection from harms caused by things like pollution and climate change (Bullard 1993). The environmental justice movement illustrates how activists attempt to inject ideas directly into the policymaking process. Systematic data on how policy documents address (or fail to address) environmental justice allow empirical tests of theories about when institutions will address claims raised by activists. I focus on the environmental justice movement because it offers a broad but tractable scope for analysis and illuminates what is at stake in the politics of agency policymaking. Policies have distributive consequences. How policy documents address distributive issues highlights how policy processes construct communities of “relevant” stakeholders and “appropriate” criteria to evaluate policy consequences. Raising environmental justice concerns in policy debates is an example of how social movement organizations mobilize norms and evaluative frameworks that interact with organizational identities, mission, and reputations and, thus, impact policy decisions (Carpenter 2001). Tracing ideas like environmental justice (EJ) through policy processes reveals the mechanisms by which social movements succeed or fail to influence policy. If draft policies do not mention EJ concerns, but activists raise EJ concerns and policymakers then address in the final policy, this may be evidence that public pressure mattered. Likewise, when draft policies do address EJ, if groups comment on it and then policymakers change how the final policy addresses EJ, this may be evidence that public pressure mattered. I assess the impact of the EJ movement qualitatively and quantitatively. Tracing the evolution of EJ analyses through several policy processes shows that the concept is hotly contested and rarely addressed by agencies in ways that activists find acceptable. Activist pressure affected how policies addressed EJ in some cases but failed to affect other policies. Examining all rules published by 40 agencies to regulations.gov between 1993 and 2020, I find that activist mobilization affected policy discourse, even under administrations that were explicitly hostile to their cause. When public comments raise EJ concerns, these concerns are more likely to be addressed in policy documents. Specifically, the number of comments mobilized (both overall and by EJ advocates specifically) is positively correlated with agencies adding language addressing EJ to policies where the draft policy did not mention EJ. When comments raise EJ concerns, sections of policies that do address EJ are also more likely to change. Furthermore, the correlation between EJ activist mobilization and policy changes is largest for agencies with missions focused on “environmental” and distributive policy—the kinds of policymakers we may expect to have institutional and cognitive processes primed to be most responsive to EJ concerns. 5.2 Theory Participatory processes like public comment periods, where policymakers must solicit public input on draft policies, are said to provide democratic legitimacy (Croley 2003; Rosenbloom 2003), new technical information (S. W. Yackee 2006; Nelson and Yackee 2012), and political oversight opportunities (Balla 1998; Mccubbins and Schwartz 1984). While recent scholarship on agency policymaking has shed light on sophisticated lobbying by businesses, we know surprisingly little about the vast majority of public comments on proposed agency rules, which are submitted as part of public pressure campaigns.32 Activists frequently target agency policymaking with letter-writing campaigns, petitions, protests, and mobilizing people to attend hearings, all classic examples of “civic engagement” (Verba and Nie 1987). Yet civic engagement remains poorly understood in the context of bureaucratic policymaking. While practitioners and administrative law scholars have long pondered what to make of activists’ mass comment campaigns, political scientists have had surprisingly little to say about this kind of civic participation. 5.2.1 Social Movements and Policy Change Social movement pressure is a major driver of policy change (Dahl 1956; Piven &amp; Cloward 1977; Lipsky 1968; Tarrow 1994; Andrews 1997; McAdam 1982, 2001; McAdam &amp; Su 2002, McCammon et al. 2011; Cress &amp; Snow 2000; Weldon 2002). This is especially true for policies that redistribute wealth or other social privileges. “From the very beginning, redistributive policies have been associated with social classes and social movements” (Lowi and Nicholson 2015). The organizational forms that mobilize and channel movement pressure (often called social movement organizations by those who study their organization and advocacy organizations or pressure groups by those that study their effects) are essential features of modern politics and lawmaking (Baumgartner and Leech 2001; Coglianese 2001). Conversely, the lack of broad-based support for and movement pressure can be the failure of a policy effort (Skocpol 2013). Scholars have also shown the effect of specific pressure tactics. For example, protests affect policy (Gillion 2013). Petition campaigns can build the organizational capacity to affect policy (Carpenter, n.d.). Activists reshape political parties to enact new policy agendas (Schattschneider 1942; Cohen et al. 2008; Schlozman 2015; Skocpol and Williamson 2016). Studies of social movements tend to explain social movement emergence rather than specific impacts (see reviews by Meyer (2004) and Mcadam (2017)). Reviews of the social movement literature find “limited research on [social movement] influence” (Andrews and Edwards 2004). Studies that do focus on policy influence tend to focus on landmark policies like the Civil Rights Act (Gillion 2013) or case studies of local policy issues (e.g., Bullard 1993; Rochon and Mazmanian 1993). Reviewing the specificity of measures used to assess the impact of advocacy campaigns, Burstein (2020) concludes that “In contrast to those studying opinion and policy, however, researchers studying advocacy and policy rarely discuss levels of specificity.” In addition to measures of advocacy and influence, there are issues with case selection. Leech (2010) argues that the influence of advocacy campaigns is overstated because scholars focus on issues where impact is especially likely–issues characterized by a lot of advocacy and recent or impending policy change. Lowery (2013) voices the opposite concern, that high-salience issues that scholars select are the cases least likely to observe advocacy success. In short, studies often select cases on the dependent variable. While large-scale and longitudinal studies have become more common (Hojnacki et al. 2012), the dependent variable is rarely systematic impact across the thousands of non-landmark policies that governments make every year. To address this gap, I focus on systematic impacts on specific policy documents over time. Specifically, I assess the impact of the environmental justice movement on bureaucratic policymaking. 5.2.2 Technical Information: the Currency of Lobbying Dominant theories of bureaucratic policymaking have little room for social movements and political pressure. Instead, they focus on how agencies learn about policy problems and solutions (Kerwin and Furlong 2011). Leading formal models are information-based models where sophisticated lobbying groups affect policy by revealing information to the agency (Gailmard and Patty 2017; Libgober 2018), and empirical studies support the conclusion that information is the currency of lobbying in rulemaking (Yackee 2012; Cook 2017; Gordon and Rashin 2018; Walters 2019). Agency rulemaking is an especially technocratic and legalistic form of policymaking that explicitly privileges scientific and legal facts as the appropriate basis for decisions. Procedural requirements to consider relevant information create incentives for lobbying groups to overwhelm agencies with complex technical information, making rulemaking obscure to all but the most well-informed insiders (Wagner 2010). As Yackee (2019) notes: “to be influential during rulemaking, commenters may require resources and technical expertise. As Epstein, Heidt, and Farina (2014) suggest, agency rule-writers–who are often chosen because of their technical or policy-specific expertise–privilege the type of data-driven arguments and reasoning that are not common to citizen comments.” (p. 10) The result is that rulemaking is dominated by sophisticated and well-resourced interest groups capable of providing new technical or legal information. Empirical scholarship finds that economic elites and business groups dominate American politics in general (Jacobs and Skocpol 2005; Soss, Hacker, and Mettler 2007; Hertel-Fernandez 2019; Hacker 2003; Gilens and Page 2014) and rulemaking in particular. While some are optimistic that requirements for agencies to solicit and respond to public comments on proposed rules allow “civil society” to provide public oversight (Michaels 2015; Metzger 2010), most studies find that participants in rulemaking often represent elites and business interests (Seifter 2016; Crow, Albright, and Koebele 2015; Wagner, Barnes, and Peters 2011; West 2009; J. W. Yackee and Yackee 2006; S. W. Yackee 2006; Golden 1998; Haeder and Yackee 2015; Cook 2017; Libgober and Carpenter 2018). To the extent that scholars address public pressure campaigns, both existing theory and empirical scholarship suggest skepticism that it matters. For example, Balla et al. (2018) find that “legal imperatives trump political considerations.” 5.2.3 Political Information While social movement organizations do engage in fights over technical reports and scientific studies, the information that activists provide is often more overtly political. Nelson and Yackee (2012) identify political information as a potentially influential result of groups expanding their lobbying coalition. While they focus on mobilizing experts, Nelson and Yackee (2012) describe a dynamic that can be extended to mobilizing public pressure: “strategic recruitment, we theorize, mobilizes new actors to participate in the policymaking process, bringing with them novel technical and political information. In other words, when an expanded strategy is employed, leaders activate individuals and organizations to participate in the policymaking process who, without the coordinating efforts of the leaders, would otherwise not lobby. This activation is important because it implies that coalition lobbying can generate new information and new actors—beyond simply the ‘usual suspects’ —relevant to policy decisionmakers.” I argue that, concerning political information, this logic extends to non-experts in at least two ways. First, mobilizing new actors to participate in the policymaking process may yield information about a policy’s disparate effects. Second, levels of public pressure can be a political resource, allowing groups to change policymakers’ perceptions of their political environment and the political consequences of their decisions. 5.2.3.1 Information About a Policy’s Disparate Effects First, while specific data on disparate impacts of policy may require expertise, anyone can highlight a community of concern and potential distributive effects of a policy. Just as Nelson and Yackee (2012) found regarding the mobilizing of diverse experts, mobilizing diverse communities affected by a policy may introduce new claims from new actors about how the communities that a policy may benefit or harm should be constructed. Indeed, telling a policymaker how a particular set of stakeholders will be affected or what they think is a lobbying tactic. Instead of bolstering scientific claims, such comments focusing on a policy’s disparate impacts bolster political claims about who counts and even who exists as a distinct, potentially affected group that deserves policymakers’ attention. The political construction of policy-relevant groups through the policy process has long interested administrative law scholars. Gellhorn (1972) argues that “individuals and groups willing to assist administrative agencies in identifying interests deserving protection” (p. 403) improve the policy process. Seifter (2016) argues that policymaker’s beliefs about who is lobbying them and who those groups represent ought to be (and likely is) key to how they respond. The politics and outcomes of policymaking depend on how the relevant groups are defined (Lowi 1964). The power of groups to affect policy depends on their recognition by formal and informal institutions. Public comment periods in agency rulemaking are formally more “identity neutral” than policy processes with procedural rights reserved for certain interests (Feinstein 2021). This means that the political construction of relevant groups depends on who participates and the identities they mobilize or claim to represent. As Yackee (2019) and others note, the information costs mean that individuals rarely participate. Instead, groups claim to represent various constituencies. “Because the costs of individualized participation in policy decision making are often excessive, informal representatives are prevalent as a form of participation in agency decisions” (Rossi 1997, pg. 194). Bureaucratic policymaking in the United States is dominated by cost-benefit analysis, which requires defining groups that are benefited or harmed by a policy and may even weigh or prioritize benefits or costs to certain groups. Agencies have many reasons to consider the distributional effects of policy and often do. Thus comments raising distributive concerns provide potentially influential political information. This distributive information raises claims of distributive justice. Public comment periods are celebrated as “a crucial way to ensure that agency decisions are legitimate, accountable, and just” (Bierschbach and Bibas 2012). “Public participation can force agencies to rethink initial inclinations” (Seifter 2016)—for example, which social groups are relevant or deserve special attention. Courts purportedly review policy decisions made through rulemaking with a particular eye toward whether they foster “fairness and deliberation” (United States v. Mead Corp., 533 U.S. 218 2001), though empirical evidence suggests skepticism about the importance of policy processes for judicial review (Judge-Lord 2016). 5.2.3.2 Public pressure as a political resource Second, the number of supporters may matter because it indicates support among relevant communities or the broader public. Again, instead of bolstering scientific claims, perceived levels of public support bolster political claims. Like other forms of political participation, such as protests and letter-writing campaigns, public pressure campaigns provide no new technical information. Nor do they wield any formal authority to reward or sanction bureaucrats. The number on each side, be it ten or ten million, has no legal import for an agency’s response. However, an organization’s ability to expand the scope of conflict by mobilizing a large number of people can be a valuable political resource (Schattschneider 1975). Furlong (1997) and Kerwin and Furlong (2011) identify mobilization as a tactic. The organizations they surveyed believed that forming coalitions and mobilizing large numbers of people were among the most effective lobbying tactics. While Furlong (1997) and Kerwin and Furlong (2011) focused on how organizations mobilize their members, I expand on this understanding of mobilization as a lobbying tactic to include a campaign’s broader audience, more akin to the concept of an attentive public (Key 1961) or issue public (Converse 1964). While scholars have generally distinguished the participation of groups from individual citizens (see Yackee (2019) for a review), “it can be difficult to distinguish an individual’s independent contribution from an interest-group-generated form letter” (Seifter 2016, pg. 1313). I argue that we should view the participation of individuals as a direct result of interest group mobilization. As (Rossi 1997, pg. 194) argues, “individuals are most likely to participate in agency decisions by virtue of their membership in interest groups.” Indeed, nearly all individual comments on proposed policies are mobilized by interest groups (Judge-Lord 2019b). The small number of unaffiliated individuals, disconnected from any organized lobbying effort, can be safely ignored empirically. Interest groups are the unit of analysis, and individual participants are best understood as measuring an amplitude of support for their efforts. Because many politically active groups are “memberless” or run by professionals who lobby with negligible input from their members (Baumgartner and Leech 2001; Skocpol 2003; Schlozman, Verba, and Brady 2012), evidence of an actual constituency is valuable political information. Petition signatures and form letters are among the only ways that a pressure group can demonstrate an engaged and issue-specific constituency on whose behalf they claim to advocate. While lobbying disclosure requirements could provide other information about how well groups represent the constituencies they claim to represent (Seifter 2016), letter-writing campaigns are one of the only strategies currently available to demonstrate issue-specific congruence between the positions of groups and the people they claim to represent (Judge-Lord 2019b). Finally, expanding the scope of conflict by mobilizing public attention to rulemaking may shift policymakers’ attention away from the technical information provided by the “usual suspects” and toward the distributive effects of policy. The “fire alarm” role that interest groups play in the policy process (Mccubbins and Schwartz 1984) may have different effects when sounding the alarm also involves “going public” (Judge-Lord 2019b). 5.2.4 Hypotheses The existing literature on bureaucratic policymaking in general—and EJ advocacy in particular—presents competing intuitions about the effect of EJ activists and the broader public in rulemaking. From the above discussion political information, I distill five hypotheses —three about distributive information and two about public pressure. I posit hypotheses in the direction that these advocacy groups do affect rulemaking while also noting equally plausible intuitions for the opposite conclusions. Because of the general skepticism and empirical work that has found that advocacy groups and public pressure campaigns have little to no effect on rulemaking, I set the empirical bar low: do EJ advocates and public pressure campaigns have any effect at all on policy documents. 5.2.4.1 Distributive Information Hypotheses Distributive Information Hypothesis: Policymakers are more likely to change whether or how policies address distributive justice when commenters raise distributive justice concerns. As discussed above, agency policymakers have incentives to address distributive concerns, especially environmental justice, due to E.O. 12898 and judicial review of compliance with the Administrative Procedures Act. By raising EJ concerns, commenters draw attention to the distribution of policy impacts—who a policy may affect. Asserting definitions and categories of stakeholders and affected groups is one type of policy-relevant information. Repeated Information Hypothesis: Policymakers are more likely to change whether or how policies address concerns when more commenters raise them. Scholarship on lobbying in rulemaking emphasizes the value of repeated information and coalition size (Mendelson 2011; Nelson and Yackee 2012). This implies that the more unique comments raise EJ concerns, the more likely the coalition will influence policy.33 Competing intuitions and other prior studies oppose both the Distributive and Repeated Information Hypotheses. Formal models and empirical scholarship on lobbying in rulemaking emphasize the importance of novel science and technical information—things unknown to agency experts (Wagner 2010). Furthermore, scholarship finds business commenters are influential, and public interest groups are not (J. W. Yackee and Yackee 2006; Haeder and Yackee 2015). Furthermore, policymakers may be more likely to anticipate EJ concerns when they are more salient to interest groups. This would mean that rules where commenters raise EJ concerns may be the least likely to change whether or how EJ is addressed because policymakers are more likely to have already considered these issues and stated their final position in the draft rule. Policy Receptivity Hypothesis: Policymakers that more frequently address concerns like environmental justice will be more responsive to commenters raising those concerns. Bureaucracies are specialized institutions built to make and implement certain kinds of policies based on certain goals and types of facts. Each agency’s distinct norms and epistemic community determine whether policymakers see issues as “environmental” and whether they have disparate impacts that demand consideration of distributive “justice.” Some policymakers may see their policy area as more related to environmental justice than others and thus be more receptive to commenter concerns. The competing intuition to the Policy Receptivity Hypothesis is that policymakers familiar with EJ concerns are the least likely to respond to EJ concerns because they anticipate these concerns—they are not novel to them. If so, agencies that rarely consider EJ may be more easily influenced by commenters who present somewhat novel information and concerns. These policymakers may be less likely to have preempted EJ critiques in the draft policy. 5.2.4.2 Public Pressure Hypotheses General Pressure Hypothesis: Policies are more likely to change when they receive more public attention (e.g., more public comments). If policymakers respond to public pressure, policy should be more likely to change when more people comment on a draft policy. This follows the intuition that policy is most likely to move in high-salience policy processes (Leech 2010). The competing intuition against the General Pressure Hypothesis is again that large numbers of comments indicate policy processes that were already salient before the public pressure campaign. Policymakers anticipate public scrutiny and are thus more likely to have stated their final position in the draft policy. If this is the case, policies with more public comments should be less likely to change. Public attention could also be unrelated to policy change, meaning that policymakers are neither anticipating nor responding to public attention in writing or revising policy documents. Specific Pressure Hypothesis: Policies are more likely to address an issue when they receive more public attention (e.g., more public comments) and at least one comment raises that issue. This hypothesis asserts that the overall level of public attention will condition policy responses to specific claims–it is the interaction between the number of total public comments and at least one of those comments raising EJ concerns that makes policy more likely to address EJ. The competing intuition against the Specific Pressure Hypothesis is again that large numbers of comments indicate high-salience rulemakings where policymakers are more likely to anticipate public scrutiny, including how they did or did not address specific issues like environmental justice. If policymakers anticipate public scrutiny, they may be more likely to preempt EJ concerns and state their final position in the draft policy. 5.3 Testing the Theory 5.3.1 “Environmental Justice” as a Boundary-drawing Tool The politics of environmental justice has several convenient properties for studying the policy impact of social movements. First, discourse around policies framed as “environmental” issues are, unlike issues like civil rights and immigration, inconsistently racialized and, unlike issues like taxes and spending, inconsistently focused on distributions of costs and benefits. This means that policies may or may not be framed in environmental justice terms. Despite policy almost always having disparate impacts, an “environmental” frame often creates a human-environment distinction and shifts attention to non-human objects such as air, water, food, or landscapes and away from the distribution of access to them or protection from them when they are contaminated. By focusing on distributions of costs and benefits, fights over EJ analyses differ from more traditional utilitarian or preservationist analyses. Second, compared to other ideas around which people mobilize, “environmental justice” is a fairly distinctive phrase. Most people who use this phrase share a general definitional foundation. Even attempts to reframe the term (e.g., to focus on class rather than race or jobs rather than health) come about as dialectical moves related to the term’s historical uses. Thus, when “environmental justice” appears in a text, it is rarely a coincidence of words; its appearance is a result of the movement or reactions to it. Third, this phrase appears frequently when the idea is discussed. There are few synonyms. Groups raising equity concerns on “environmental” issues commonly use the phrase “environmental justice.” Those who use narrower, related terms–including the older concept of “environmental racism” and the newer concept of “climate justice”–almost always use “environmental justice” in their advocacy as well. Finally, the term is relevant to rulemaking records in particular because Executive Order 12898 issued in 1994 by President Clinton—“Federal Actions to Address Environmental Justice in Minority Populations and Low-Income Populations”—directs all agencies to consider EJ implications of their actions and policies. Executive Orders from Presidents Obama and Biden and statements from agency heads in every administration have since interpreted and reinterpreted parts of this Order, all with direct implications for rulemaking. This does not mean that all draft or final rules address EJ, but they tend to cite Executive Order 12898 and explicitly discuss environmental justice when they do. For the same reason, commenters who critique draft rules also cite this Executive Order and use this language. Again, this is true both for movement activists and reactionary efforts to redefine the term. While EO 12898 does not itself create a right to sue agencies, courts may strike down rules for failing to comply with procedural requirements of the Administrative Procedures Act (APA) and National Environmental Policy Act (NEPA) if the agency fails to “examine the relevant data” or “consider an important aspect of the problem” (Motor Vehicle Mfrs. Ass’n v. State Farm Mut. Auto. Ins. Co., 1983). This can include an agency’s 12898 EJ analysis: “environmental justice analysis can be reviewed under NEPA and the APA” (Communities Against Runway Expansion, Inc. v. FAA, 2004). The legal salience of the phrase “environmental justice” means that advocates attempting to frame policies in distributive terms tend to use the phrase, and agencies also tend to use it if they respond to these concerns. 5.3.2 Data To examine whether EJ activists and public pressure campaigns shape policy documents, I collect the text of all draft rules, public comments, and final rules from regulations.gov. Then, I select rulemaking documents from agencies that published at least one rule explicitly addressing EJ from 1993 to 2020. This yields over 25,000 rulemaking dockets from 40 agencies. 12,257 of these have both a proposed and final rule.34 Despite E.O. 12898, most rules do not address EJ. Figure 5.1 shows that most draft and final rules (about 90%) do not mention “environmental justice.” Interestingly, the total number of final rules and the percent of the total addressing EJ have remained relatively stable for the period where regulations.gov data are complete (after 2005). From 2006 to 2020, these agencies published between 2000 and 3000 final rules per year, of which between 200 and 300 addressed EJ. Figure 5.1: Proposed and Final Rules by Whether they Address Environmental Justice. Even at the Environmental Protection Agency (EPA), where most policies are clearly framed as “environmental” issues, a consistent minority of rules address EJ. Many agencies that make policy with apparent EJ effects almost never address EJ. These include the Fish and Wildlife Service (FWS), Department of Housing and Urban Development (HUD), National Oceanic and Atmospheric Administration (NOAA), Nuclear Regulatory Commission (NRC), and the Office of Surface Mining (OSM). A majority of rules addressed EJ only in a few years at a few agencies that publish relatively few rules, including the Council on Environmental Quality (CEQ), Army Corps of Engineers (COE), Federal Emergency Management Agency (FEMA), Forest Service (FS), and several Department of Transportation agencies (the Federal High Way Administration (FHWA), Federal Motor Carrier Safety Administration (FMCSA), Federal Railroad Administration (FRA), and Federal Transit Administration (FTA)). Figure 5.2 shows the number of rulemaking projects over time by whether they ultimately addressed EJ at agencies that either published more than ten rules addressing EJ or receiving over 100 comments raising EJ concerns. Figure 5.2: Number of Proposed and Final Rules Addressing Environmental Justice at the Council on Environmental Quality (CEQ), Army Corps of Engineers (COE), Department of Transportation (DOT), Environmental Protection Agency (EPA), Federal Emergency Management Agency (FEMA), Federal High Way Administration (FHWA), Federal Motor Carrier Safety Administration (FMCSA), Federal Railroad Administration (FRA), Forest Service (FS), Federal Transit Administration (FTA), Fish and Wildlife Service (FWS), Department of Housing and Urban Development (HUD), National Highway Transportation Saftey Administration (NHTSA), National Oceanic and Atmospheric Administration (NOAA), Nuclear Regulatory Commission (NRC), and Office of Surface Mining (OSM) 5.3.2.1 Comments Figure 5.3 shows the number of comments on each proposed rule published between 1993 and 2020. Light red circles indicate rules where no commenters raised EJ concerns. Dark blue Triangles indicate rules where they did. The bottom row shows the subset of rules where “environmental justice” appeared in neither the draft nor the final rule. The middle row shows rules where “environmental justice” appeared in the final but not the draft. My first analysis compares these two subsets. The top row shows rules where “environmental justice” appeared in both the draft and final rule. My second analysis assesses change in this subset of rules. Predictably, commenters most often raised EJ concerns on rules in the first row, but many rules that did not initially address EJ still received comments raising EJ concerns. Figure 5.3: Number of Comments on Proposed and Final Rules and Whether Comments Raised Environmental Justice Concerns 5.3.2.2 Interest Groups and Second-order Representation When lobbying during rulemaking, groups often make dubious claims to represent broad segments of the public (Seifter 2016). Thus, to interpret substantive results or the normative import of any findings in this analysis, it is insufficient to know which groups participate. We also need to know who these groups claim to represent and whether those people are actually involved in the organization’s decisions. As Seifter argues: “the expertise a group claims is often based on its ability to convey a particular constituency’s perspective, experience, or concerns…A group that does not have or engage with a membership cannot reliably convey those sorts of constituency-based insights. Moreover, even when a group’s assertions seem independent of a constituency—say, the results of a scientific study—information about second-order participation matters. Understanding the group’s sources, funding, and potential biases is important to assessing the reliability of its information and its contribution to agency expertise” (Seifter 2016, pg. 1306). Examining second-order representation is thus required to assess “what contemporary participation does and does not achieve” (Seifter 2016, pg. 1306)—for example, the extent to which EJ concerns (and any potential policy response) indicate genuine social movement advocacy and influence. Recall that EJ is a contested concept used to evoke different distributive claims by different groups. The prevalence and impact of EJ concerns in the policy process is only meaningful against the backdrop of who exactly is using EJ rhetoric. I examine who is raising EJ concerns in two ways. First, I identify the top organizational commenters such as tribes, businesses, and nonprofits using EJ language and investigate whom these groups represent. Second, for comments where a commenter signed their name, I compare surnames to their racial and ethnic identity propensities in the U.S. Census. Together these two pieces of information allow me to comment on “second-order” representation, i.e., the extent to which public comments are representative of the groups they claim to represent (Seifter 2016). 5.3.2.2.1 Which Organizations Most often Raise EJ Concerns? To explore who raises EJ concerns, I first identify the organization behind each comment through a mix of hand-coding and text analysis. This includes organizational comments on signed letterhead and individuals who use the text of a form letter provided by an organization. I then investigated the top 20 organizations that mobilized the most comments (form letters) mentioning “environmental justice” and all organizations that raised EJ concerns on more than one policy. The top mobilizer of comments mentioning “environmental justice” between 1993 and 2020 was the Sierra Club, with over 340,000 comments mentioning EJ on dozens of rules. The Sierra Club a membership organization whose members pay dues, elect the leaders of local chapters, and have some say in local advocacy efforts. However, its policy work is directed by a more traditional national advocacy organization funded by donations, including over $174 million from Bloomberg Philanthropies that funded several of the public pressure campaigns in these data. The Sierra Club does have a major program arm dedicated to Environmental Justice that works with local partners “to foster the growth of the environmental justice movement so that oppressed communities will find justice and everyone can experience the benefits of a healthy and sustainable future.” The extent to which those individuals have a formal say in the national organization’s lobbying decisions varies across campaigns. The National Board of Directors adopted a statement on social justice in 1993 and principles on environmental justice in 2001. The national website does contain regular Spanish language content. As a federated organization with many local efforts, it is difficult to generalize about second-order representation. The second most prolific organizer of EJ comments was Earthjustice, with over 175,000 comments on many of the same rules that the Sierra Club lobbied on. Earthjustice is primarily engaged in litigation on behalf of environmental causes. Their website boasts 2.2 million supporters, but it is not clear who they are or if they play any role in the advocacy strategy. A search on the website returns 360 results for “Environmental Justice,” with the top results from staff biographies who work on more local or targeted campaigns, such as environmental conditions for the incarcerated. The EJ language used on the main page is relatively vague. For example, “We are fighting for a future where children can breathe clean air, no matter where they live.” (Earthjustice 2017). The website does contain some Spanish language content. The Natural Resources Defense Council is similar to Earthjustice–a national nonprofit funded by donations and focused on litigation–but they also lobby and organize public pressure campaigns, including over 160,000 comments mentioning environmental justice. CREDO Action and MoveOn are more generic progressive mobilizers who lack a systematic focus on EJ issues, but occasionally leverage their vast membership and contact lists to support EJ campaigns led by others. The Alliance for Climate Protection is more of an elite political group founded by former Vice President Al Gore. We Act and Communities for a Better Environment both have environmental justice in their central mission statement. Community leaders founded We Act in Harlem, New York, to advocate against environmental racism and poor air quality (WEACT 2017). Communities for a Better Environment has projects throughout California but is particularly active in Oakland (CBECAL 2017). Much of the content of their website is in both English and Spanish. Both organizations focus primarily on “low-income communities of color” and frame their work primarily in terms of race and class. While both organizations participated in national policymaking, We Act is more focused on communities in Harlem and New York, whereas Communities for a Better Environment casts a broader frame: “CBE’s vision of environmental justice is global–that’s why the organization continues to participate in such international efforts as the Indigenous Environmental Network and the Global Week of Action for Climate Justice” (CBECAL 2017). While not a large portion of EJ comments, companies repeatedly raise research about the unequal impacts of policy to frame these issues as a legitimate but unresolved scientific debate that is not yet conclusive enough to base regulations on, mirroring the way tobacco and fossil fuel companies have emphasized scientific uncertainty in their lobbying efforts.&lt;!-TODO CITE–&gt; For example, in one comment, the Southern Company wrote: “People with lower SES are exposed to almost an order of magnitude more traffic near their homes (Reynolds et al., 2001), and live closer to large industrial sites and are exposed to more industrial air pollution (Jerrett et al., 2001). Legitimate health concerns must be addressed. But adopting standards with a scientific basis so uncertain that health improvement cannot be assured is not sound public health policy.” Like many companies, they claim to represent their customers: “electric generating companies and their customers are expected to bear much of the burden” of regulations (Hobson 2004). Yet, customers have little say in companies’ decisions. Overall, regarding second-order representation, it appears that the groups most often using the language of environmental justice may do so sincerely but generally represent affected communities in a surrogate capacity (Mansbridge 2003). Several groups representing local communities and led by community leaders have participated, but not nearly as often or with the same intensity as the “big greens.” The domination of large advocacy organizations highlights the importance of resources as a condition for lobbying and mobilizing. Not all groups who may benefit from generating political information can leverage it because they lack the resources to fund a campaign or even comment on relevant policies. However, smaller, more member-driven groups may partner with national groups that have more resources to mobilize on their behalf. Finally, a third, much less common type of commenter raises EJ issues to reframe them as ongoing debates and thus undermine their urgency. I call this reason for engaging an attempt to “break a perceived consensus.” In a way, the fact that energy companies felt compelled to acknowledge and question EJ concerns suggests their importance for policy outcomes. 5.3.2.2.2 Commenter Race To estimate the racial distribution of commenters using EJ language, I select commenters who signed with a surname appearing in census records. Figure 5.4 shows a probabilistic racial distribution of commenters who raise EJ concerns in their comments based on the distribution of self-reported racial identities associated with surnames as recorded in the 2010 census.35 I estimate this distribution using the proportion of people with a given surname identified as belonging to each racial category (from this limited set of options). This approach does not assign specific individuals to racial categories. Instead, it represents each commenter as a set of probabilities adding up to 1. The estimated racial distribution of the sample is the sum of individual probabilities. Figure 5.4: Estimated Racial Distribution from Census Surnames of Commenters raising “Environmental Justice” Concerns in Rulemaking Compared to the overall distribution in the 2010 census, this sample of commenters appears to be disproportionately Black and less than proportionately Latinx or Asian, with just slightly fewer Whites relative to the national population. This distribution makes sense given that environmental justice African Americans have led theorizing and activism (Bullard 1993). 5.3.3 Tracing Ideas Through Rulemaking: “Environmental Justice” as a Contested Concept Using an environmental justice frame does not always imply the same communities of concern. Environmental justice emerged from movements against environmental racism, especially the disposal of toxic materials in predominantly Black neighborhoods (Bullard 1993). However, the term quickly took on other meanings, encompassing various marginalized groups. President Clinton’s 1994 Executive Order on Environmental Justice required all parts of the federal government to make “addressing disproportionately high and adverse human health or environmental effects of programs, policies, and activities on minority populations and low-income populations” a core aspect of their mission. This meant considering disproportionate effects of policies by race and income during rulemaking. In 2005, Environmental Protection Agency (EPA) political appointees reinterpreted the Order, removing race as a factor in identifying and prioritizing populations. This move was criticized by activists and two reports by EPA’s own Office of Inspector General. President Obama’s EPA Administrators reestablished race as a factor. They named EJ as one of their top priorities, but they also faced criticism from activists for paying lip service to environmental racism without adequate policy changes. In an October 2017 proposed rule to repeal restrictions on power plant pollution, the Trump EPA acknowledged that “low-income and minority communities located in proximity to [power plants] may have experienced an improvement in air quality as a result of the emissions reductions.” Because the Obama EPA discussed EJ when promulgating the Clean Power Plan rule— stating that “climate change is an environmental justice issue” —, the Trump EPA attempted to reframe rather than ignore environmental justice. The Trump EPA contended that the Obama EPA “did not address lower household energy bills for low-income households [and that] workers losing jobs in regions or occupations with weak labor markets would have been most vulnerable” (EPA 2017). Like regulated industry commenters, these statements frame the distribution of jobs and electricity costs as EJ issues to push back against policies that would equalize the distribution of health impacts from pollution. The central conflict over the role of race in policy analyses is just one of many conflicts that the environmental justice movement has caused to be fought somewhat on its terms. The next section briefly reviews the decades-long policy fight over regulating Mercury pollution to illustrate how these definitional conflicts shape rules and rulemaking. This case and other examples in this article emerged from reading hundreds of rulemaking documents where agencies did and did not respond to comments raising EJ concerns. Their purpose is to assess whether the cases in the quantitative analysis are plausibly what they appear to be: that changes in rule text are, sometimes, causally related to public comments and that non-changes are cases of agencies disregarding comments, not some accident of the data or measures. The qualitative reading also confirmed other key assumptions, such as the fact that advocates do, in fact, use “environmental justice” when they raise distributional concerns, even on many rules that are not about issues traditionally considered “environmental.” 5.3.3.1 The Evolving Distributional Politics of Mercury Pollution Definitions of the public good and minority rights are implicit in most policy documents, including agency rules. The public comment process offers an opportunity to protest these definitions. Protest is one way that marginalized groups can communicate opinions on issues to government officials (Gillion 2013). In the EPA’s Mercury Rules, two definitional issues were decisive. First, as with many forms of pollution, mercury-emitting power plants are concentrated in low-income and non-White communities. Second, some populations consume much more locally-caught freshwater fish, a major vector of Mercury toxicity. Studies inspired by the political controversy around the Mercury Rules found high risk among certain communities, including “Hispanic, Vietnamese, and Laotian populations in California and Great Lakes tribal populations (Chippewa and Ojibwe) active on ceded territories around the Great Lakes” (EPA 2012). Thus the standards that EPA chooses depend on whom the regulation aims to protect: the average citizen, local residents, or fishing communities. This decision has disparate effects based on race and class because of disparate effects based on geography and cultural practices. In December 2000, when the EPA first announced its intention to regulate Mercury from power plants, the notice published in the Federal Register did not address EJ issues, such as the disparate effects of mercury on certain populations; it only discussed anticipated impacts in reference to “the U.S. population” (EPA 2000). When the first draft rule was published, it only discussed the effects of the rule on regulated entities, noting that “Other types of entities not listed could also be affected” (EPA 2002). Commenting on this draft, Heather McCausland of the Alaska Community Action on Toxics (ACAT) wrote: “The amount of methyl-mercury and other bioaccumulative chemicals consumed by Alaskans (especially Alaskan Natives) could potentially be much higher than is assumed… [This could increase] the Alaskan Native mortality rate for babies, which according to the CDC, is 70% higher than the United States average. Indigenous Arctic &amp; Alaskan Native populations are some of the most polluted populations in the world. Global transport &amp; old military sites contaminate us too.” By citing the CDC, McCausland’s comment provided both technical and distributive information. As allies mobilized, public pressure mounted to address the disparate impacts of mercury levels. After receiving hundreds of thousands of comments and pressure from tribal governments and organizations, a revised proposed rule echoed McCausland’s comment noting that “Some subpopulations in the U.S., such as Native Americans, Southeast Asian Americans, and lower-income subsistence fishers may rely on fish as a primary source of nutrition and/or for cultural practices. Therefore, they consume larger amounts of fish than the general population and may be at a greater risk of the adverse health effects from Hg due to increased exposure” (EPA 2004). After nearly a million additional public comments, a further revised proposed rule ultimately included five pages of analysis of the disparate impacts on “vulnerable populations” including “African Americans,” “Hispanic,” “Native American,” and “Other and Multi-racial” groups (EPA 2011). In the final rule, “vulnerable populations” was replaced with “minority, low income, and indigenous populations” (EPA 2012). The EPA had also conducted an analysis of sub-populations with particularly high potential risks of exposure due to high rates of fish consumption as well as additional analysis of the distribution of mortality risk by race. Of this second round of comments, over 200 unique comments explicitly raised EJ issues. The Little River Band of Ottawa Indians expressed the Tribe’s “frustration at trying to impress upon the EPA the multiple and profound impacts of mercury contamination from a Tribal perspective. Not to mention the obligations under treaties to participate with tribes on a ‘Government to Government’ basis. At present, no such meetings have occurred in any meaningful manner with EPA Region V, the EPA National American Indian Environmental Office, nor the State of Michigan’s Department of Environmental Quality…Although EPA purported to consider environmental justice as it developed its Clean Air Mercury Rule, it failed utterly. In this rulemaking, EPA perpetuated, rather than ameliorated, a long history of cultural discrimination against tribes and their members” (Sprague 2011). Did comments like these play a role in EPA’s changed analysis of whom Mercury limits should aim to protect? Given the many potential sources of influence, it may be difficult to attribute causal effects of particular comments on a given policy. However, comments may serve as a good proxy for the general mobilization of groups and individuals around an administrative process, and it is not clear why the EPA would not address EJ in the first draft of a rule and then add it to subsequent drafts in the absence of activist pressure. Electoral politics does not offer an easy explanation. The notice proposing the Mercury Rule was issued by the Clinton administration, the same administration that issued the Executive Order on Environmental Justice, and the subsequent drafts that did address EJ issues were published by the Bush administration, which had a more contentious relationship with EJ advocates, while Republicans controlled both houses of Congress. The expansion of the analysis from one draft to the next seems to be in response to activist pressure. 5.3.4 Measuring Policy Change Having shown how public comments and pressure can influence policy texts, I assess the general relationship between comments and policy change across all rules. I use two indicators of policy change to model the effect of public comments on policy: whether a rule addresses EJ and change in how it addresses EJ, i.e., change in portions of the text discussing EJ. Both measures represent a relatively low bar, indicating whether the agency explicitly paid any attention to EJ. This is appropriate given that prior research shows little to no effect of public comments from advocacy groups and little attention to EJ in particular. Examples in the previous section illustrate how text mentioning “environmental justice” might be added or change. Carefully tracing a few rulemaking processes also helped to avoid analytic pitfalls. For example, one case where an agency did an EJ analysis and then appeared not to respond to a comment discussing EJ was, in fact, due to the fact that the commenter included an annotated version of the draft rule their comment, adding only “no comment” next to the 12898 section. To correct this, I removed text copied from the proposed rule from comments in pre-processing. 5.3.4.1 Measure 1: Adding Text Addressing EJ to Final Rules For the subset of draft rules that did not address EJ, I measure whether agencies added any mention of “environmental justice” in the final rule. Such additions usually take the form of an “E.O. 12898” section where the agency justifies its policy changes with respect to some concept(s) of environmental justice. The next most common addition occurs in the agency’s response to comments, explaining how the rule did not have disparate effects or that they were insignificant. Agencies may both respond to a comment and add a 12898 section. For example, the EPA responded to several commenters, including Earthjustice, the Central Valley Air Quality Coalition, the Coalition for Clean Air, Central California Environmental Justice Network, and Central California Asthma Collaborative: “EPA agrees it is important to consider environmental justice in our actions and we briefly addressed environmental justice principles in our proposal.” As the commenters noted, the EPA had not, in fact, addressed environmental justice in the proposed rule, which approved California rules regulating particulate matter emissions from construction sites, unpaved roads, and disturbed soils in open and agricultural areas. EPA did add a fairly generic 12898 section to the final rule but did not substantively change the rest of the policy. Less frequently, an agency may explicitly dismiss a comment and decline to add a 12898 section. For example, EPA responded to a comment on another rule, “One commenter stated that EPA failed to comply with Executive Order 12898 on Environmental Justice…We do not believe that these amendments will have any adverse effects on…minority and low-income populations…Owners or operators are still required to develop SSM plans to address emissions…The only difference from current regulations is that the source is not required to follow the plan” (71 FR 20445). As these examples illustrate, agencies may add text addressing environmental justice that would not satisfy critics. This measure merely indicates whether the agency engaged with the claims. Most frequently, agencies neither responded to comments nor added a 12898 section. 5.3.4.2 Measure 2: Changing Text Addressing EJ in Final Rules Where draft rules did address EJ, I measured whether a rule changed how it discussed “environmental justice” between its draft and final publication.36 When an agency addresses EJ in the draft rule, it is almost always in a section about how it addressed E.O. 12898. In many cases, much of the text of final rules, including 12898 sections, remain exactly the same between draft and final versions. To measure change, I parse draft and final rules into sentences and identify sentences containing the phrase “environmental justice.” If an agency leaves these sentences unchanged between the draft and final rule and adds no new sentences mentioning EJ, this suggests that the agency did not engage with comments raising EJ concerns.37 5.4 Results 5.4.1 Are final rules more likely to address environmental justice after comments do so? Where environmental justice is not addressed in the draft rule, a higher percent of rules add EJ language when comments raise EJ concerns. Descriptively, there is a large difference in the rate of addressing EJ between rules where commenters and did (33%) and did not raise EJ concerns (4%). However, in most cases (67%), agencies did not respond at all when commenters raised EJ concerns. Rates of adding EJ in rules without EJ comments decreased over time, leveling out at 3% during the Obama and Trump presidencies. Rates of adding EJ when commenters raised EJ concerns are consistently much higher, but it also decreases over time, from 57% under G.W. Bush to 26% under Trump. EPA had a relatively high baseline rate of change (10%), which increased to 52% when comments raised EJ concerns. Most other agencies also added EJ at a higher rate when comments raised EJ concerns; indeed, most agencies almost never do so when comments did not raise EJ concerns. To account for differences across presidents, agencies, and the number of comments, I estimate logit regression. For models 1 and 2 in Table 5.1, the outcome is whether the agency added environmental justice to the final rule. The predictors are whether comments raised EJ concerns, the number of unique (non-form letter) comments addressing EJ, the total number of comments (including form letters), and the interaction between the total number of comments and whether any comments raised EJ concerns. Models 3 and 4 are the same as models 1 and 2, except that the outcome is whether the policy text changed how EJ is discussed (described in the next section). All models include fixed effects for the presidential administration. Models 2 and 4 also include fixed effects for agency. Thus, estimates in Models 1 and 3 include variation across agencies, whereas estimates in models 2 and 4 only rely on variation within agencies. All estimates rely on variation within each presidential administration. All predicted probabilities shown below include agency fixed effects, models 2 and 4. Table 5.1: Logit Regression Predicting Change in Rule Text 1 2 3 4 Dependent Variable EJ Added EJ Added EJ Changed EJ Changed EJ Comment 3.363*** 2.414*** 0.717*** 0.748*** (0.221) (0.240) (0.243) (0.246) Log(Comments+1) 0.068** 0.232*** -0.147*** -0.156*** (0.028) (0.036) (0.032) (0.033) Unique EJ Comments 0.005 0.227*** 0.032** 0.036** (0.006) (0.068) (0.014) (0.014) EJ Comment*Log(Comments+1) -0.227*** -0.226*** 0.071 0.069 (0.052) (0.072) (0.050) (0.051) President FE X X X X Agency FE X X Num.Obs. 11721 11721 1885 1885 AIC 3868.6 3125.6 2180.4 2166.5 BIC 3927.5 3464.6 2224.7 2327.2 Log.Lik. -1926.296 -1516.818 -1082.192 -1054.252 * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01 5.4.1.1 The Predicted Probability of Added Text As logit coefficients are not easily interpretable, Figures 5.5, 5.6, and 5.7 show the predicted probability of a final rule addressing environmental justice when the draft rule did not. Controlling for average rates of policy change per agency and the number of comments, Figure 5.5 shows a large increase in the probability of policy change when comments raise EJ concerns. This supports the Distributive Information Hypothesis. When comments raise distributive justice concerns, they are more likely to be addressed in the final policy. Rates of adding EJ language decrease after the G.W. Bush Administration, but differences between presidents are small compared to the difference between rules that did and did not receive EJ comments. Other variables are held at their modal values: the EPA, zero additional EJ comments, and one comment total.38 Figure 5.5: Probability that “Environmental Justice” is Added Between Draft and Final Rules by President Figure 5.6 shows the probability that an agency will add EJ language given different total numbers of comments. At low numbers of comments, anyone comment raising environmental justice has a strong relationship with policy change. For rules with less than ten comments (most rules), one comment mentioning EJ is associated with a 30% increase in the probability that EJ will be addressed in the final rule. This supports the Distributive Information Hypothesis. However, the probability that an agency will add EJ language is still below 50%—even when comments raise EJ concerns, agencies tend not to address them. As the number of comments increases, the probability that a rule will add text addressing EJ increases. This supports the General Pressure Hypothesis—policy change is more likely when there is more public attention to a policy process. Simultaneously, there is a negative interaction between the number of comments and EJ comments—the more comments, the smaller the relationship between comments raising EJ and agencies addressing EJ in the rule. In the small-portion of highly salient rules with 10,000 or more, the presence of comments raising EJ concerns no longer has a statistically significant relationship with agencies adding EJ to the text. With or without EJ comments, these rules have about the same probability of change as those with just one EJ comment, just under 50%. This is evidence against the Specific Pressure Hypothesis—the number of comments matters (i.e., the scale of public attention) matters regardless of whether these comments explicitly raise EJ concerns. However, as shown in Figure 5.3, few rules with 10,000 or more comments do not have at least one comment mentioning EJ, so we are highly uncertain about estimates of the impact of EJ comments with high levels of public attention. We can be much more confident about the relationship between comments raising EJ concerns and rule change at lower, more typical levels of public attention. The probability of “environmental justice” appearing in the final rule also increases with the number of unique comments mentioning “environmental justice” in models 2, 3, and 4. Overall this supports the Repeated Information Hypothesis. Figure 5.6: Probability Environmental Justice is Added Between Draft and Final Rules by Number of Comments Figure 5.7 shows estimated variation in rates of adding EJ to final rules across agencies. Agencies with the largest average rates of adding EJ language are the agencies we would expect to be more receptive to EJ claims. While many agencies make policies that could be framed as “environmental,” and all policy decisions have distributive consequences, institutions have norms and procedures that lead policymakers to see problems in different ways. For example, some agencies have dedicated staff and prominent internal guidance on EJ analysis in rulemaking, including the Environmental Protection Agency and the Department of Transportation (which includes the Federal Railroad Administration (FRA), Department of Transportation, Federal Motor Carrier Safety Administration (FMCSA), and the Federal Highway Administration (FHWA)). These agencies are among the most responsive to commenters raising EJ concerns. However, differences among agencies are fairly uncertain due to the small number of rules where EJ was added at most agencies. Thus, there is more support for the Policy Receptivity Hypothesis than against it, but differences between agencies with different missions and institutional practices regarding EJ are not clear cut. Figure 5.7: Probability Environmental Justice is Added Between Draft and Final Rules by Agency 5.4.2 Are rules more likely to change how they address environmental justice when comments mention it? Turning to rules that do address EJ in the draft, we also see responsiveness to comments raising EJ concerns, now measured as whether any sentences containing “environmental justice” changed between draft and final rule. Models 3 and 4 in Table 5.1 are the same as Models 1 and 2, except that the dependent variable is now whether any sentences mentioning EJ changed between the draft and final rule. Most rules that addressed EJ in the draft were published by the EPA. The EPA had a high rate of baseline change, which increased when comments raised EJ concerns. Other agencies had too few draft rules mentioning EJ to make strong inferences, but many changed how they discussed EJ 100% of the time when comments raised EJ concerns, while inconsistently doing so when comments did not. 5.4.2.1 The Predicted Probability of Changed Text Controlling for average rates of change per agency and the number of comments, Figure 5.8 shows little difference in baseline rates of changing EJ language across the Bush, Obama, and Trump presidencies. All are significantly lower than the Clinton administration’s rate, which could be related to Clinton’s Executive Order on environmental justice or simply an artifact of the limited sample of rules posted to regulations.gov before the mid-2000s. Figure 5.8: Predicted Change in How Environmental Justice is Addressed Between Draft and Final Rules by President For draft rules that already addressed EJ, the relationship between the total number of comments and policy change is in the opposite direction posited by the General Pressure Hypothesis. The logged total number of comments is inversely related to change in the final rule text. The more comments on a proposed rule, the less likely it is to change. Rules are more likely to change when they receive fewer comments. Thus, the total number of comments has the opposite relationship to how rules that already addressed EJ changed as it did to whether rules added any EJ text. While the General Pressure Hypothesis explained adding EJ text where none existed in the draft, the opposite is true for changing a text that already addressed EJ. Instead, this result supports the competing intuition that more salient rules may be harder to change because the agency has anticipated public scrutiny. Their position stated in the draft is more likely to be the position of the final rule. As shown in Figure 5.9, EJ comments have a small but discernable relationship to the probability of rule change at typical (low) numbers of comments. As the total number of comments increases, the estimated difference between policies that did and did not receive EJ comments increases. When no comments mention EJ, a rule that receives 10,000 comments is much less likely to change than a rule that received 10,000. When comments do raise EJ concerns, more public attention has a smaller impact on the probability of policy change. Figure 5.9: Predicted Change in How Environmental Justice is Addressed Between Draft and Final Rules by Number of Comments 5.5 Conclusion This analysis presents a rare, systematic account of a social movement’s impact on specific policy outcomes across institutions and over time. It illustrates the importance of ideas in policymaking and how social movements can affect policy, even in technocratic processes like rulemaking, where most U.S. law is now made. When activists raise issue frames like environmental justice, there is a higher probability that policymakers engage in discourse that highlights the distributive effects of policy. However, baseline rates of addressing environmental justice in rulemaking are so low that, even when activists raise EJ concerns, most policy documents pay no explicit attention to EJ. We see this general lack of attention across agencies and across the G.W. Bush, Obama, and Trump administrations. Indeed, I find surprisingly small differences across administrations in both baseline rates of considering EJ and the relationship between public pressure and policy change. There is a great deal of variation across agencies, suggesting that policy receptivity and responsiveness to public input are conditional on an institutional factors. The policy outcomes suggested by an environmental justice analysis depend on how the populations of concern are defined. In some cases, those raising environmental justice concerns present it as an economic inequality issue, leading policy to account for disparate impacts on low-income populations. In other cases, groups raise claims rooted in cultural practices, such as fish consumption among certain tribes. As occurred in the Mercury Rule, the analysis in subsequent drafts of the policy used evaluative criteria specific to these communities. Thus, policy outcomes will depend on the specific environmental justice concerns raised. Future research should assess the relationship between specific EJ claims and corresponding policy changes. Which communities and concerns are raised by activist campaigns depend on second-order representation—who makes decisions in the organizations that mobilize public pressure. Examining which groups raise environmental justice concerns and second-order participation in these organizations’ advocacy decisions validates some of the skepticism about who is able to participate and make their voice heard. Elite groups dominate policy lobbying, even for an issue like environmental justice. National advocacy organizations frequently request that regulators protect “all people” or even “low-income communities of color.” However, this more generic advocacy may not lead to the same outcomes as participation b groups that can present more specific local environmental justice concerns unique to a community. In between generic progressive advocacy organizations and community-based organizations are high-capacity organizations like the Sierra Club and Earthjustice, which frequently partner with local organizations for more place-based litigation and campaigns and may be more likely to raise these local concerns in national policymaking. Given the importance of federal policy for local environmental outcomes, and advocacy organizations’ potential to draw policymakers’ attention to environmental justice issues, future research should examine the quality of partnerships between frontline communities and national advocacy organizations. In the end, the above analysis offers some clarity on two poorly understood and rarely linked features of American politics: the policy impact of social movements and the role of public pressure in bureaucratic policymaking. It offers some hope that policymakers may address concerns raised through direct democracy mechanisms like public comment periods. At the same time, it highlights how policymakers rarely explicitly address the disparate impacts of policy, even when directly confronted with distributive justice concerns. Social movements do affect policy, but there are steep odds to overcome. References "],["conclusion-1.html", "Chapter 6 Conclusion", " Chapter 6 Conclusion The legitimacy of bureaucratic policymaking is said to depend on the premise that rulemaking provides for public voice (Croley 2003, @Rosenbloom2003). Yet we lack an empirical base necessary to evaluate whether any legitimacy the public comment process may provide is deserved. If input solicited from ordinary people has little effect on policy outcomes, directly or indirectly, it may be best understood as providing a veneer of democratic legitimacy on an essentially technocratic and/or elite-driven process. I have made a few initial steps toward better understanding actual public engagement in bureaucratic policymaking. If public pressure campaigns do shape agency decisions, a new research program will be needed to investigate who exactly these campaigns mobilize and represent. References "],["references.html", "References", " References "]]
