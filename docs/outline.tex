% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Public Pressure Campaigns and Bureaucratic Policymaking},
  pdfauthor={Devin Judge-Lord},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{Public Pressure Campaigns and Bureaucratic Policymaking}
\author{Devin Judge-Lord}
\date{2021-03-12}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{introduction}{%
\chapter*{Introduction}\label{introduction}}
\addcontentsline{toc}{chapter}{Introduction}

Does civic engagement through public pressure campaigns affect agency rulemaking? I examine who participates in public pressure campaigns and why, whether they affect congressional oversight, and whether they affect policy. Answering these questions informs our understanding of bureaucratic politics and interest group lobbying, organizing, and mobilizing tactics. If ordinary people have a voice in bureaucratic policymaking, I argue, it is through public pressure campaings. Thus, understnding the nature and effects of these campaigns is key to understanding modern democracy.

With the rise of the administrative state, U.S. federal agencies have
become a major site of policymaking and political conflict. By some
estimates, upward of 90\% of legally binding U.S. federal policy is now
written by agencies. Agency rules are revised much more frequently than
statutory law \citep{Wagner2017}. In the years or decades between
legislative enactments, federal agencies make legally-binding rules
interpreting and reinterpreting old statutes to address emerging issues
and priorities. Examples are striking: Many effects of the Dodd-Frank Wall
Street Reform and Consumer Protection Act were largely unknown until the
specific regulations were written, and it continues to change as these
rules are revised. Congress authorizes billions in grants, subsidies, and
leases for public lands, but who gets them depends on agency policy. In
the decades since the last major environmental legislation, agencies
have written thousands of pages of new environmental regulations and
thousands more changing tack under each new administration. These
revisions significantly shape lives and fortunes. For example, in 2006,
citing the authority of statutes last amended in the 1950s, the Justice
Department's Bureau of Prisons proposed a rule restricting eligibility
for parole. In 2016, the Bureau withdrew this rule and announced it
would require fewer contracts with prison companies,
precipitating a 50\% loss of industry stock value. Six months later, a
new administration announced these policies would again be reversed,
leading to a 130\% increase in industry stock value. Agency rulemaking
matters.

Less clear, however, is how the new centrality of agency rulemaking fits
with democracy. In addition to the bureaucracy's complex relationships with
the president and Congress, agencies have complex and poorly understood
relationships with the public and advocacy groups. Relationships with
constituent groups may even provide agencies with a degree of ``autonomy'' from their official principals \citep{Carpenter2001}.

Participatory processes like public comment periods, where government
agencies must solicit public input on draft policies, are said to
provide political oversight opportunities \citep{Balla1998, Mccubbins1984},
democratic legitimacy \citep{Croley2003, Rosenbloom2003}, and new technical
information \citep{Yackee2006JPART, Nelson2012}. While recent scholarship on
agency policymaking has shed light on the sophisticated lobbying by
businesses and political insiders, we know surprisingly little about the
vast majority of public comments which are submitted by ordinary people
as part of public pressure campaigns.\footnote{As I show elsewhere \citep{Judge-Lord2019}, most comments submitted to
  regulations.gov are form comments, more akin to petition signatures
  than sophisticated lobbying. Indeed, approximately 40 million out of
  50 million (80\%) of these public comments mobilized by just 100
  advocacy organizations.} Activists frequently target
agency policymaking with letter-writing campaigns, petitions, protests,
and mobilizing people to attend hearings, all classic examples of ``civic
engagement'' \citep{Verba1987}. Yet civic engagement remains poorly understood
in the context of bureaucratic policymaking.

These occasional bursts of civic engagement in bureaucratic policymaking
raise practical and theoretical questions for the practice of
democracy.\footnote{In 2018, the Administrative Conference of the United States (ACUS)
  identified mass commenting as a top issue in administrative law. In
  their report to ACUS, \citet{SantAmbrogio2018} conclude, ``The `mass
  comments' occasionally submitted in great volume in highly salient
  rulemakings are one of the more vexing challenges facing agencies in
  recent years. Mass comments are typically the result of orchestrated
  campaigns by advocacy groups to persuade members or other
  like-minded individuals to express support for or opposition to an
  agency's proposed rule.'' Mass comment campaigns are known to drive
  significant participation of ordinary people in Environmental
  Protection Agency rulemaking
  \citep{Judge-Lord2019, Potter2017, Balla2018}. \citet{Cuellar2005}, who
  examines public input on three rules, finds that ordinary people
  made up the majority of commenters demonstrating ``demand among the
  mass public for a seat at the table in the regulatory process.''} These questions, in turn, hinge on unanswered empirical
questions: Do these campaigns affect policy? If so, by what mechanisms?
Existing research finds that commenters believe their comments matter
\citep{Yackee2015JPART} and that the number of public comments varies across
agencies and policy processes
\citep{Judge-Lord2019, Libgober2018, Moore2017}, but the relationship
between the scale of public engagement and policy change remains
untested.

\hypertarget{motivation}{%
\section*{Motivation}\label{motivation}}
\addcontentsline{toc}{section}{Motivation}

Leading models of influence in bureaucratic policymaking focus on two key political forces: sophisticated interest group lobbying and political oversight.
As bureaucrats learn about policy problems and balance interest-group demands, public comment processes allow lobbying organizations to provide useful technical information and inform decisionmakers of their preferences on draft policies.
Agencies may then update policy positions within constraints imposed by their political principals.

While this may describe most cases of bureaucratic policymaking, these models do not explain or account for the contentious politics that occasionally inspire millions of ordinary people to respond to calls for public input on draft agency policies. Mass engagement in bureaucratic policymaking has thus largely been ignored by political scientists, leaving a weak empirical base for normative and prescriptive work.
Like other forms of mass political participation, such as protests and letter writing campaigns,
mass public comments on draft agency rules provide no new technical information.
Nor do they wield any formal authority to reward or sanction bureaucrats, as comments from a Members of Congress might.
The number on each side, be it ten or ten million, has no legal import for an agency's response.

How, if at all, should scholars incorporate mass engagement into models of bureaucratic policymaking?

\hypertarget{outline-of-the-book}{%
\section*{Outline of the book}\label{outline-of-the-book}}
\addcontentsline{toc}{section}{Outline of the book}

This dissertation explores the effects of public pressure campaigns on agency rulemaking, a technocratic policy process where ``public participation'' is usually limited to sophisticated lobbying but occasionally includes millions of people mobilized by public pressure campaigns. Public comment periods on proposed policies purport to provide democratic accountability. Yet theories of bureaucratic policymaking largely ignore the occasional bursts of civic engagement that generate the vast majority of public comments on proposed rules. To fill this gap, I build and test theories about the role of public pressure in policymaking. I collect and analyze millions of public comments to develop the first systematic measures of civic engagement and influence in bureaucratic policymaking.

\textbf{Chapter 1 ``Agency Rulemaking in American Politics''} situates agency rulemaking in the context of American politics. Tracing broad trends over the past 40 years, I show that rulemaking has become a major site of policymaking and political conflict.

\textbf{Chapter 2 ``Why Do Agencies (Sometimes) Get So Much Mail?''} addresses who participates in public pressure campaigns and why. Are public pressure campaigns, like other lobbying tactics, primarily used by well-resourced groups to create an ``astroturf'' impression of public support? Or are they better understood as conflict expansion tactics used by less-resourced ``grassroots'' groups? I find that mass comment campaigns are almost always a conflict expansion tactic. Furthermore, I find no evidence of negativity bias in public comments. Indeed, from 2005 to 2017, most comments supported proposed rules. This is because public comments tend to support Democratic policies and oppose Republican policies, reflecting the asymmetry in mobilizing groups.

\textbf{Chapter 3 ``Do Public Pressure Campaigns Influence Congressional Oversight?''} examines the effect of public pressure campaigns on whether legislators are more likely to engage in rulemaking. This involves collecting and coding thousands of comments from Members of Congress on proposed rules with and without public pressure campaigns. These data also allow me to assess congressional oversight as a mediator in policy influence, i.e., the extent to which public pressure campaigns affect policy indirectly through their effects on legislators' oversight behaviors.

\textbf{Chapter 4 ``Do Public Pressure Campaigns Influence Policy?''} leverages a mix of hand-coding and computational text analysis methods to assess whether public pressure campaigns increase lobbying success. To measure lobbying success, I develop computational methods to identify lobbying coalitions and estimate their effect on each rule posted for comment on regulations.gov. I then validate these methods against a random sample of 100 rules with a mass-comment campaign and 100 rules without a mass-comment campaign, hand-coded for whether each coalition got the policy outcome they sought. Finally, I assess potential mechanisms by which mass public engagement may affect policy.

\textbf{Chapter 5 ``The Environmental Justice Movement and Technocratic Policymaking''} examines the discursive effects of environmental justice claims both qualitatively and quantitatively. I write about the role of Native activists and environmental groups in shaping federal environmental regulations. Looking across over 20,000 draft regulations that failed to address environmental justice issues, I find that agencies are more likely to add language addressing environmental justice in their final rules when public comments raise environmental justice concerns.

\hypertarget{agency-rulemaking-in-american-politics}{%
\chapter{Agency Rulemaking in American Politics}\label{agency-rulemaking-in-american-politics}}

See the working paper version of this chapter \href{https://judgelord.github.io/dissertation/MacroRulemaking.pdf}{\emph{here}}

\hypertarget{abstract}{%
\subsubsection*{Abstract}\label{abstract}}
\addcontentsline{toc}{subsubsection}{Abstract}

Large democracies face two big problems. First, they are vulnerable to fleeting passions and demagogues. To combat this, many decisions are left to experts who, ideally, exercise judgment loosely guided by the public. Second, everyone cannot vote on every decision. We thus delegate power to representatives (who then delegate it to deputies), create temporary mini-publics, and solicit input from those most affected or moved by a public decision.\footnote{As imagined by \citet{Dahl1989}, mini-publics are representative, selected at random, and deliberative. Besides juries, however, randomly selected deliberative bodies are rare. Instead, citizens more often engage in government decisions when given opportunities to opt-in, such as hearings, petitions, and public comment periods. These mechanisms of engagement generate a different, more contentious flavor of public input than the discourse imagined by scholars who focus on deliberation.} Most policy is then made by bureaucrats, supposedly guided indirectly through elected representatives and directly by limited public input (mostly limited to more contentious policy debates).

Both of these problems converge in the bureaucracy, run by experts who are deputized by elected officials (or by their deputy's deputy's deputy) and with procedures that create opportunities for public input. It is far from clear how bureaucratic decisions are to balance expertise, accountability to elected officials, and responsiveness to public input in decisionmaking.

\hypertarget{public-pressure-why-do-agencies-sometimes-get-so-much-mail}{%
\chapter{Public Pressure: Why Do Agencies (sometimes) Get So Much Mail?}\label{public-pressure-why-do-agencies-sometimes-get-so-much-mail}}

\hypertarget{abstract-1}{%
\subsubsection*{Abstract}\label{abstract-1}}
\addcontentsline{toc}{subsubsection}{Abstract}

I examine who participates in public pressure campaigns and why. Scholars of bureaucratic policymaking have focused on the sophisticated lobbying efforts of powerful interest groups. Yet agencies occasionally receive thousands or even millions of comments from ordinary people. How, if at all, should scholars incorporate mass participation into models of bureaucratic policymaking? Are public pressure campaigns, like other lobbying tactics, primarily used by well-resourced groups to create an impression of public support? Or are they better understood as conflict expansion tactics used by less-resourced groups? To answer these questions, I collect and analyze millions of public comments on draft agency rules. Using text analysis methods underlying plagiarism detection, I match individual public comments to pressure-group campaigns. I find that most public comments are mobilized by a few public interest organizations. Over 80\% of the 48 million comments on proposed rules posted to regulations.gov were mobilized by just 100 organizations, 87 of which lobby in coalitions with each other. Contrary to other forms of lobbying, I find that mass comment campaigns are almost always a conflict expansion tactic, rather than well-resourced groups creating an impression of public support. Contrary to other forms of political participation, I find no evidence of negativity bias in public comments. Indeed, from 2005 to 2017, most comments supported proposed rules. This is because public comments tend to support Democratic policies and oppose Republican policies, reflecting the asymmetry in mobilizing groups.

See the working paper version of this chapter \href{https://judgelord.github.io/research/whymail/}{\emph{here}}

\hypertarget{oversight-do-public-pressure-campaigns-influence-congressional-oversight}{%
\chapter{Oversight: Do Public Pressure Campaigns Influence Congressional Oversight?}\label{oversight-do-public-pressure-campaigns-influence-congressional-oversight}}

\hypertarget{abstract-2}{%
\subsubsection*{Abstract}\label{abstract-2}}
\addcontentsline{toc}{subsubsection}{Abstract}

This chapter examines the effect of public pressure campaigns on congressional oversight. I assess whether legislators are more likely to engage in rulemaking when advocacy groups mobilize public pressure. This involves collecting and coding thousands of comments from Members of Congress on proposed rules with and without public pressure campaigns. These data also allow me to assess congressional oversight as a mediator in policy influence, i.e., the extent to which public pressure campaigns affect agency decisionmakers directly or indirectly through their effects on elected officials' oversight behaviors.

\hypertarget{policy-influence-do-public-pressure-campaigns-influence-bureaucratic-policymaking}{%
\chapter{Policy Influence: Do Public Pressure Campaigns Influence Bureaucratic Policymaking?}\label{policy-influence-do-public-pressure-campaigns-influence-bureaucratic-policymaking}}

\hypertarget{abstract-3}{%
\subsubsection*{Abstract}\label{abstract-3}}
\addcontentsline{toc}{subsubsection}{Abstract}

I assess whether public pressure campaigns increase lobbying success in agency rulemaking using a mix of hand-coding and computational text analysis methods. To measure lobbying success, I develop computational methods to identify lobbying coalitions and estimate lobbying success for all rules posted for comment on regulations.gov. These methods are validated against a random sample of 100 rules with a mass-comment campaign and 100 rules without a mass comment campaign that I hand-code for whether each coalition got the policy outcome they sought. I then assess potential mechanisms by which mass public engagement may affect policy. Each mechanism involves a distinct type of information revealed to decisionmakers. Of primary interest is the extent to which public pressure campaigns affect agency decisionmakers directly or indirectly through their effects on elected officials' oversight behaviors. I test this by assessing congressional oversight as a causal mediator using a subset of rules where I collect and code correspondence from Member of Congress to agencies about proposed agency rules.

See the preanalysis plan for this chapter \href{https://github.com/judgelord/dissertation/blob/master/04-influence/preanalysis.pdf}{\emph{here}}

I assess the relationship between the number of
public comments and the amount of change between draft and final policy
texts. Next, I assess the relationship between the number of people
mobilized by each campaign and whether the campaign achieved its policy
goals. Finally, I theorize and test four mechanisms by which public
input may affect bureaucratic policymaking. Each mechanism involves a
distinct type of information that pressure campaigns may relay to
policymakers: technical information, information about the likelihood of
political consequences, information about the preferences of elected
officials, or information about the preferences of the attentive public.
Because scholarship on bureaucratic policymaking has focused on the
power of technical information, where insider lobbying is most likely to
matter and where outside strategies are least likely to matter,
political scientists have largely overlooked mass mobilization as a
tactic.

I find evidence consistent with the observable implications of mass
comment campaigns influencing policymaking through \[non-null results\]
but no evidence that mass engagement affects rulemaking processes or
outcomes through \[null results\].

\hypertarget{data}{%
\section{Data}\label{data}}

I create an original dataset that combines several sources of data on U.S. federal agency rulemaking.
The core data are the texts of draft and final rules and public comments on these proposed rules.
This includes all 16 thousand proposed rules from 144 agencies (as defined by regulations.gov) that were open for comment on regulations.gov between 2005 and 2018, that received at least one comment from an organization, and that saw a final agency action between 2005 and 2019.
There are over 50 million comments on this set of rules.
I scrape draft and final rule texts from federalregister.gov and comments submitted as attachments or by mail from regulations.gov.
I retrieve comments submitted directly on regulations.gov and metadata on rules and comments (such as the dates that the proposed rule was open for comment and whether the agency identified the organization submitting the comment) from the regulations.gov API.
I add additional metadata on rules (such as whether the rule was considered ``significant'') from the Unified Agenda published by the Office of Information and Regulatory Affairs (reginfo.gov).

Finally, to better capture positions expressed by Members of Congress on proposed rules, I supplement congressional comments posted on regulations.gov with Freedom of Information Act Requests for all communication from Members of Congress to each agency on proposed rules from 2007 to 2019.\footnote{Many agencies provided records of their congressional correspondence going back to 2005 or earlier.}

The combined dataset has over 50 million observations of one public or legislator comment on a proposed rule. I attempt to identify the organization(s) that submitted or mobilized each comment by extracting all organization names from the comment text. For comments that do not reference an organization, I am often able to identify organizations with an internet search using the comment's text. I then identify lobbying coalitions by clustering comments that use similar phrases or word frequencies. Co-signed comments are always assigned to the same coalition. Likewise, form-letter comments are always assigned to the same coalition.\footnote{The same comment text is attributed to each signatory of a comment. For more on how I identify organizations and coalitions, see \href{https://judgelord.github.io/dissertation/whyMail.pdf}{Chapter 2, ``Why Do Agencies (Sometimes) Get So Much Mail?''}.}

Because my hypotheses are about the influence of organizations and coalitions, for analysis, I collapse these data to one observation per organization or coalition per proposed rule and identify the main substantive comment submitted by each organization's staff or lawyers, which are usually much longer than supporting comments like form letters. For hand-coding, I first select a random sample of 100 proposed rules with a mass-comment campaign and then selecting a matched sample of 100 proposed rules without a mass comment campaign. Matching prioritizes, presidential administration, policy area (following Policy Agendas Project coding), rule significance, department, agency, subagency, and proposed rule length, respectively.\footnote{For more on policy area coding, see \href{https://judgelord.github.io/dissertation/MacroRulemaking.pdf}{``Trends in U.S. Executive-branch Policymaking 1980-2016''} in Chapter 1.} This hand-coded sample is several times larger than leading studies using hand-coding and includes rules with very large and small numbers of comments that previous studies exclude. The full sample is four hundred times larger.\footnote{Except for comment texts and attachments, these data are available separately and combined on github.com/judgelord/rulemaking.}

\hypertarget{methods}{%
\section{Methods}\label{methods}}

The most direct way to assess the hypothesis that mass engagement increases lobbying success is to assess the magnitude of the relationship between the number of comments that a coalition mobilizes and its lobbying success. However, public pressure campaigns may only be effective under certain conditions. Thus, I first assess the main relationship and then assess evidence for or against different potential causal pathways of influence.

\hypertarget{the-dependent-variable-lobbying-success}{%
\subsection{The Dependent Variable: Lobbying Success}\label{the-dependent-variable-lobbying-success}}

The dependent variable is the extent to which a lobbying coalition got the policy outcome they sought, which I measure in three ways.

First, on a sample of rules, I hand-code lobbying success for each lobbying coalition, comparing the change between the draft and final rule to each organization's demands on a five-point scale from ``mostly as requested'' to ``significantly different/opposite than requested.''
To do this, I first identify organizational comments.
For each organization, I identify the main overall demand and the top three specific demands and the corresponding parts of the draft and final rule texts.\footnote{This does not capture rule changes on which an organization did not comment.
  The codebook is available \href{https://docs.google.com/document/d/1o1hi0z9O-G9xsgkspOFG2VWzh0wQKjiezzoVpItaCxU/edit?usp=sharing}{here}. See examples of coded cases \href{https://judgelord.github.io/dissertation/influence_coding_examples.pdf}{here}.}\\
I then code overall lobbying success and lobbying success on each specific demand for each organization and coalition. Both the overall score and average score across specific demands both fall on the interval from -1 (``significantly different'') to 1 (``mostly as requested'').

Second, I use methods similar to automated plagiarism detection algorithms to identify changes between a draft and final rule that were suggested in a comment. Specifically, I count the number of words in phrases of at least ten words that appear in the comment and final rule, but not the draft rule. To do this, I first identify new or changed text in the final rule by removing all 10-word or longer phrases retained from the draft rule. I then search each comment for any 10-word or longer phrases shared with the new rule text and count the total number of shared words in these shared phrases. Finally, I normalize this count of ``copied'' words across shorter and longer comments by dividing it by the total number of words in the comment. This measure falls between 0 (zero percent of words from the comment added to the final rule) and 1 (100 percent of words from the comment added to the final rule). As a robustness check, I also use the non-normalized version of this variable, i.e.~the raw number of ``copied'' words.

Third, I capture a broader dimension of lobbying success by modeling the similarity in word frequency distributions between comments and changes to the rule. New or changed text is identified as described above, except that I also include the rule's preamble and the agency's responses to comments. Agencies write lengthy justifications of their decisions in response to some comments but not others. By including preambles and responses to comments, this measure captures attention to a comment's demands and the extent to which the agency adopts a comment's discursive framing (i.e.~the distribution of words it uses). I us cosign similarity to scale the word frequencies used by each comment relative to those in changes between draft and final rule.\footnote{For the subset of rules with five or more organizational comments, I create a more sophisticated measure of word frequency similarity by averaging the absolute value of differences in topic proportions \(\theta\) between the comment and new rule text across 45 LDA models of all organizational comments estimated with 5 through 50 topics, normalized by the number of topics \(k_n\) and the number of models such that \(y_i\) falls between 0 (completely different estimated topic proportions) and 1 (exactly the same topic proportions), \(y_i = \sum_{5}^{n=50}(\frac{\sum|\theta_{rule\ change_i|k=n}-\theta_{comment_i|k=n}|}{n})*\frac{1}{45}\). For more on these methods of measuring textual similarity, see \href{https://judgelord.github.io/budgets/JudgeLordAPSA2017.pdf}{``Measuring Change and Influence in Budget Texts''}.} This measure falls between 0 (no common words) and 1 (exactly the same distribution of words).

To assess the performance of these automated methods (text-reuse and word-frequency similarity), I calculate the correlation between these scores and my hand-coded 5-point scale for rules in the hand-coded sample where a final rule was published. As the automated methods apply at the organization-level, coalition scores are those from the lead organization--by default, the organization(s) with the longest comment. At the coalition level, the correlation between hand-coded influence is \_\_ with the text-reuse method and \_\_ with the word-frequency method.

\hypertarget{the-main-predictor-variable}{%
\subsection{The Main Predictor Variable}\label{the-main-predictor-variable}}

The number of supportive comments generated by a public pressure campaign (the main variable of interest) is a tally of all comments mobilized by each organization or coalition that ran a mass-comment campaign on a proposed rule. Because the marginal impact of additional comments likely diminishes, the number of comments is logged. This does not include the main substantive comments submitted by an organization's staff or lawyers. Nor does it include comments that are not affiliated with the organization or coalition. If an organization mobilizes more than 1000 comments or 100 identical comments on a proposed rule, I code that organization, its coalition, and the proposed rule as having a mass comment campaign. Where organizational comments are not supported by a mass comment campaign \emph{log mass comments} takes a value of 0.

\hypertarget{explanatory-variables}{%
\subsection{Explanatory variables}\label{explanatory-variables}}

Other predictors of lobbying success in the models below are the length of the (lead) organization's comment, whether the coalition lobbies unopposed, the size of the lobbying coalition, and whether the coalition is business-led. \emph{Comment length} is normalized by dividing the number of words in the comment by the number of words in the proposed rule, thus capturing the complexity of the comment relative to the complexity of the proposed rule. The number and type(s) of organization(s) is an attribute of each coalition (e.g.~a \emph{business-led} coalition with \emph{N} organizational members). Coalition \emph{size} is the number of distinct commenting organizations in the coalition (including those that co-sign a comment). For organizations lobbying alone, coalition \emph{size} is 1. A coalition is \emph{unopposed} when no opposing organizations comments. I code a coalition as \emph{business-led} if the majority of commenting organizations are for-profit businesses, or if upon investigation, I find it to be primarily led or sponsored by for-profit businesses.\footnote{For more on how I identify types of organizations and coalitions, see \href{https://judgelord.github.io/research/whymail/}{Chapter 2, ``Why Do Agencies (Sometimes) Get So Much Mail?''}.}

\hypertarget{limitations}{%
\subsection{Limitations}\label{limitations}}

The two main limitations of this design both bias estimates of public pressure campaign influence toward zero.

First, lobbying success may take forms other than changes in policy texts. Agencies may speed up or delay finalizing a rule, extend the comment period, or delay the date at which the rule goes into effect. Indeed, commentors often request speedy or delayed rule finalization, comment period extensions, or delayed effective dates. I capture these potential outcomes in my hand-coding but not in the two automated methods, which apply only to observations with a final rule text. Likewise, there there is no change between draft and final rule, both automated methods necessarily record lobbying success as 0, even if a comment asks an agency to publish a rule without change.\footnote{Time allowing, I will hand-code a larger sample of proposed rules where no final rule was published so that these cases can be included in the analysis. Likewise, I will identify cases where organizations requested rules to be published as-is and recode these cases by hand.}

Second, bureaucrats may anticipate public pressure campaigns when writing draft rules, muting the observed relationship between public pressure and rule change at the final rule stage of the policy process.

\hypertarget{modeling-the-direct-relationship}{%
\section{Modeling the direct relationship}\label{modeling-the-direct-relationship}}

For all three measures of lobbying success, I assess the relationship between lobbying success and mass comments by modeling coalition \(i\)'s lobbying success, \(y_i\) as a combination of the relative length of the (lead) organizations comment, whether the coalition is unopposed, the coalition's size, whether it is a business coalition, and the logged number of mass comments. I estimate OLS\footnote{See \href{https://judgelord.github.io/dissertation/preanalysis.pdf}{OLS model estimates with simulated data}. I also estimate hand-coded lobbying success with beta regression and ordered logit, which are more appropriate but less interpretable. For the automated measures of lobbying success, I estimate beta regression models with the same variables.} regression:

\[
y_i = \beta_0 + \beta_1 log(comments_i) + \beta_2 length_i + \beta_3 unopposed_i + \beta_4 size_i + \beta_5 business_i + \epsilon_i
\]

\hypertarget{modeling-mediated-relationships}{%
\subsection{Modeling mediated relationships}\label{modeling-mediated-relationships}}

To estimate mediated effects, I estimate the average conditional marginal effect (ACME) and the proportion of the total effect attributed to mediation through congressional support (comments or other communication from Members of Congress supporting the coalition's position on the proposed rule). As developed by Imai et al.~(2010), this involves first estimating a model of the proposed mediator as a combination of covariates, \(X\) (\emph{length}, \emph{unopposed}, \emph{size}, and \emph{business}) and then the outcome as a combination of the mediator, \emph{congressional support}, and covariates, \(X\).

Mediator model:

\[
congressional\ support_i = \beta_0 + \beta_1 log(comments_i) + \beta_{2-n} X_i + \epsilon_i
\]

Outcome model:

\[
y_i = \beta_0 + \beta_1 log(comments_i) + \beta_2 congressional\ support_i + \beta_{3-n} X_i + \epsilon_i
\]

\hypertarget{examples-of-hand-coded-lobbying-success}{%
\section{Examples of hand-coded lobbying success}\label{examples-of-hand-coded-lobbying-success}}

\textbf{2015 Waters of the United States Rule:}
In response to litigation over which waters were protected by the Clean Water Act, the Environmental Protection Agency and Army Corp of Engineers proposed a rule based on a legal theory articulated by Justice Kennedy, which was more expansive than Justice Scalia's.
The Natural Resources Defense Council submitted a 69-page highly technical comment ``on behalf of the Natural Resources Defense Council\ldots, the Sierra Club, the Conservation Law Foundation, the League of Conservation Voters, Clean Water Action, and Environment America'' supporting the proposed rule:

\begin{quote}
``we strongly support EPA's and the Corps' efforts to clarify which waters are protected by the Clean Water Act. We urge the agencies to strengthen the proposal and move quickly to finalize it\ldots{}''
\end{quote}

I coded this as support for the rule change, specifically not going far enough. I also coded it as requesting speedy publication. NRDC makes four substantive requests: one about retaining language in the proposed rule (``proposed protections for tributaries and adjacent waters\ldots must be included in the final rule'') and three proposed changes (``we describe three key aspects of the rule that must be strengthened'').\footnote{These three aspects are: (1) ``The Rule Should Categorically Protect Certain ``Other Waters'' including Vernal Pools, Pocosins, Sinkhole Wetlands, Rainwater Basin Wetlands, Sand Hills Wetlands, Playa Lakes, Interdunal Wetlands, Carolina and Delmarva Bays, and Other Coastal Plain Depressional Wetlands, and Prairie Potholes. Furthermore, ``Other `Isolated' Waters Substantially Affect Interstate Commerce and Should be Categorically Protected Under the Agencies' Commerce Clause Authority.'' (2) ``The Rule Should Not Exempt Ditches Without a Scientific Basis'' (3) ``The Rule Should Limit the Current Exemption for Waste Treatment Systems''} These demands provide specific keywords and phrases for which to search in the draft and final rule text.

A coalition of 15 environmental organizations mobilized over 944,000 comments, over half (518,963) were mobilized by the four above organizations: 2421,641 by Environment America, 108,076 by NRDC, 101,496 by clean water action, and 67,750 by the Sierra Club. Other coalition partners included EarthJustice (99,973 comments) and Organizing for Action (formerly president Obama's campaign organization, 69,369 comments). This is the upper tail end of the distribution. This coalition made sophisticated recommendations and mobilized a million people.

The final rule moved in the direction requested by NRDC's coalition, but to a lesser extent than requested--what I code as ``some desired changs.''" As NRDC et al.~requested, the final rule retained the language protecting tributaries and adjacent waters and added some protections for ``other waters'' like prairie potholes and vernal pools, but EPA did not alter the exemptions for ditches and waste treatment systems.

Comparing the draft and final with text reuse allows us to count the number words that belong to 10-word phrases that appear in both the draft and final, those that appear only in the draft, and those that appear only in the final. For the 2015 Waters Of The U.S. rule, 15 thousand words were deleted, 37 thousand words were added, and 22 thousand words were kept the same. This means that more words ``changed'' than remained the same, specifically 69\% of words appearing in the draft or final were part were either deleted or added.

For this coalition, the dependent variable, \emph{coalitions success} is 1, \emph{coalition size} is 15, \emph{business coalition} is 0, \emph{comment length} is 69/88, 0.78, and \emph{log mass comments} is log(943,931), 13.76.

\textbf{2009 Fine Particle National Ambient Air Quality Standards:} In 2008, the EPA proposed a rule expanding air quality protections. Because measuring small particles of air pollution was once difficult, measurements of large particulates were allowed as a surrogate measure for fine particles under EPA's 1977 PM10 Surrogate Policy. EPA proposed eliminating this policy, thus requiring regulated entities and state regulators to measure and enforce limits on much finer particles of air pollution.

EPA received 163 comments on the rule, 129 from businesses, business associations such as the American Petroleum Institute and The Chamber of Commerce, and state regulators that opposed the rule. Most of these were short and cited their support for the 63-page comment from the PM Group, ``an ad hoc group of industry trade associations'' that opposed the regulation of fine particulate matter. Six state regulators, including Oregon's, only requested delayed implication of the rule until they next revised their State Implementation Plans (SIPs) for Prevention of Significant Deterioration (PSD). EarthJustice supported the rule but opposed the idea that the cost of measuring fine particles should be a consideration. On behalf of the Sierra Club, the Clean Air Task Force, EarthJustice commented: ``We support EPA's proposal to get rid of the policy but reject the line of questioning as to the benefits and costs associated with ending a policy that is illegal.'' The EarthJustice-led coalition also opposed delaying implementation: ``EPA must immediately end any use of the Surrogate Policy -- either by''grandfathered" sources or sources in states with SIP‐approved PSD programs -- and may not consider whether some flexibility or transition is warranted by policy considerations."

The final rule did eliminate the Surrate Policy but allowed states to delay implementation and enforcement until the next scheduled revision of their Implementation Plans. I code this as the EarthJustice coalition getting most of what they requested, but not a complete loss for the regulated coalition.

For the PM Group coalition, the dependent variable, \emph{coalitions success} is -1, \emph{coalition size} is 129, \emph{business coalition} is 1, \emph{comment length} is 63/85, 0.74, and \emph{log mass comments} is 0.

For the State of Oregon's coalition, the dependent variable, \emph{coalitions success} is 2, \emph{coalition size} is 6, \emph{business coalition} is 0, \emph{comment length} is 5/85, 0.06, and \emph{log mass comments} is 0.

For the EarthJustice coalition, the dependent variable, \emph{coalitions success} is 1, \emph{coalition size} is 3, \emph{business coalition} is 0, \emph{comment length} is 7/85, 0.08, and \emph{log mass comments} is 0.

\hypertarget{the-environmental-justice-movement-and-technocratic-policymaking}{%
\chapter{The Environmental Justice Movement and Technocratic Policymaking}\label{the-environmental-justice-movement-and-technocratic-policymaking}}

\hypertarget{abstract-4}{%
\subsubsection*{Abstract}\label{abstract-4}}
\addcontentsline{toc}{subsubsection}{Abstract}

I explore the role of public comments in rulemaking by focusing on their role in the environmental justice movement. Environmental justice concerns focus on unequal access to healthy environments and protection from harms caused by things like pollution and climate change. The ways in which agencies consider environmental justice highlights how rulemaking has distributive consequences, how the public comment process creates a political community, and how claims raised by activists are addressed. Examining thousands of rulemaking processes at agencies known to address environmental justice concerns, I find that when public comments raise environmental justice concerns, these concerns are more likely to be addressed in the final rule. However, baseline rates of addressing environmental justice in rulemaking are so low that even as the probability that agencies will address environmental justice significantly increases when commenters raise these issues, in most rules, even those where commenters raise environmental justice concerns, there is no explicit attention to environmental justice. Furthermore, even when agencies do address environmental justice concerns, they often do not make the substantive policy changes that activists demand. While the number of comments raising environmental justice concerns is positively correlated with change in policy texts, the effect of the general level of public attention is mixed. Rules with more comments are more likely to address environmental justice when they did not address it in the draft rule, but rules with more comments are less likely to change how they addressed environmental justice if they did address it in the draft rule. These results suggest that the politics of rulemaking differs when there is more public attention. Patterns also vary across agencies, possibly due to the alignment of environmental justice aims with agency missions.

See the working paper version of this chapter \href{https://judgelord.github.io/research/ej/}{\emph{here}}

  \bibliography{assets/dissertation.bib}

\end{document}
