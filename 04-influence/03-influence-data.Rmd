## Testing the Theory

### Data: A Census of Public Comments {#influence-data}

```{r influence-data}
load(here::here("data", "rules_metadata.Rdata"))

# alternatively 
#rules <- dbGetQuery(con, "SELECT * FROM rules")

#FIXME move date var to rulemaking repo
rules %<>%
  mutate(comment_start_date = comment_start_date %>% as.Date(),
         comment_due_date = comment_due_date %>% as.Date(),
         date = coalesce(posted_date, comment_start_date, comment_due_date),
         year = str_sub(date, 1,4),
         year2 = str_remove(docket_id, ".*[A-Z]-") %>%
           str_remove("-.*"),
         year = coalesce(year, year2) %>% as.numeric()
                      ) %>%
  select(-year2) 

# d is rules subset to study years
d <- rules %>% 
  filter(year > 2004, year < 2021, document_type %in% c("Proposed Rule", "Rule"))

load(here::here("data", "comments_min.Rdata"))

# add docket_id
comments_min %<>% 
  mutate(docket_id = id %>% str_remove("-[0-9]*$"))

# hand coded 
load(here::here("data", "coalitions_coded.Rdata"))
load(here::here("data", "comments_coded.Rdata"))
#load(here::here("data", "mass_coded.Rdata"))

# common names 
comments_coded %<>% 
  mutate(coalition = coalition_comment,
         agency = str_remove(docket_id, "-.*"))%>%
  mutate(org_name = org_name %>% str_to_title())%>%
  mutate(coalition = coalition %>% str_to_title())

# common names 
coalitions_coded %<>% 
  mutate(coalition = coalition_comment,
         comments = coalition_comments,
         Comments = Coalition_comments,
         agency = str_remove(docket_id, "-.*"))%>%
  mutate(coalition = coalition %>% str_to_title())

# inspect
# coalitions_coded$coalition_comments %>% min()

comments_coded %<>% mutate(across(where(is.character), str_to_title))
coalitions_coded %<>% mutate(across(where(is.character), str_to_title))

# TODO merge in mass comments that were not hand-coded 
```

To examine the relationship between public pressure campaigns and lobbying success, I use an original dataset (introduced in \@ref(whymail-data)) that combines several data sources on U.S. federal agency rulemaking.

Up to 2020, these data include `r unique(rules$docket_id) %>% length()`
dockets,
`r rules %>% filter(docket_type == "Rulemaking") %>% distinct(docket_id) %>% nrow()`
rulemaking dockets. These dockets received
approximately `r sum(rules$number_of_comments_received, na.rm = T)`
comments.

The core data for this analysis are the texts of draft and final rules and public comments on these proposed rules published from 2005 to 2020. 
This includes all proposed rules from `r d %>% filter(number_of_comments_received >0) %>% pull(agency_id) %>% unique() %>% length()` agencies that were open for comment on regulations.gov between 2005 and 2020, received at least one comment from an organization, and saw a final agency action between 2005 and 2020.  These 
`r d %>% filter(docket_type == "Rulemaking") %>% distinct(docket_id) %>% nrow()`
rulemaking dockets received a total of
`r d %>% filter(docket_type == "Rulemaking") %>% pull(number_of_comments_received) %>% sum(na.rm = T)`
comments.


<!--TODO: This should be a short review and addition to the data section in whymail-->

I collected draft and final rule texts from federalregister.gov and comments submitted as attachments or by mail from regulations.gov. 
I retrieve comments submitted directly on regulations.gov and metadata on rules and comments (such as the dates that the proposed rule was open for comment and whether the agency identified the organization submitting the comment) from the regulations.gov API. 
I add additional metadata on rules (such as whether the rule was considered "significant") from the Unified Agenda published by the Office of Information and Regulatory Affairs (reginfo.gov). 

Where a new presidential administration used the same docket number to solicit comments on a proposed rule that a previous administration used, I count these as separate rulemaking dockets. I do so because the second policy usually reverses or goes in the opposite direction as the previous administration's policy solicited comments. The same organizations often comment but with the opposition positions. Support becomes opposition and vice versa.

#### Clustering with text reuse


My theoretical approach requires that I *attribute* form letter comments to the organizations, campaigns, and broader coalitions that mobilized them. To do so, I identify comments that share text. I find that a 10-word phrase repeated across more than a few comments is always either text copied from the proposed policy or a form letter provided by a campaign. Thus, for the text of each comment, I first remove all 10-word phrases that appear in the proposed rule (including the preamble and call for comments). Then, I identify all comments that share ten-word phrases with 99 or more other comments. Finally, I collapse these form letter comments to one representative document for hand-coding. 

I attempt to identify the organization(s) that submitted or mobilized each comment by extracting all organization names from the comment text. For comments that do not reference an organization, I can often identify organizations with an internet search using portions of the comment's text. I then identify lobbying coalitions both by hand and by textual similarity. Co-signed comments are always assigned to the same coalition. Likewise, form-letter comments are always assigned to the same coalition.^[For more on how I identify organizations and coalitions, see \@ref(whymail-methods).]

Because my hypotheses are about the influence of organizations and coalitions, I collapse these data to one observation per organization or coalition per proposed rule for analysis. I then identify the main substantive comment submitted by each organization's staff or lawyers, which are usually much longer than supporting comments like form letters. 
For hand-coding, I first select a random sample of proposed rules with a mass-comment campaign. I then selected all comments that were likely to be from organizations.^[Through an iterative process, I developed software and methods to select comments that were most likely submitted by organizations rather than by individuals. For example, I include all comments submitted as file attachments rather than typed into the textbox.]
The hand-coding process included identifying the organization responsible for each comment submitted by an organization (e.g., a business, nonprofit, or government). 

I then select a sample of proposed rules on which the same organizations commented without a mass comment campaign. <!--Matching prioritizes, presidential administration, policy area (following Policy Agendas Project coding), rule significance, department, agency, subagency, and proposed rule length, respectively.^[For more on policy area coding, see Chapter \@ref(macro).]--> 
This hand-coded sample is several times larger than leading studies using hand-coding and includes rules with very large and small numbers of comments that previous studies exclude.


The most direct way to assess the hypothesis that mass engagement increases lobbying success is to assess the relationship between the number of comments that a coalition mobilizes and its lobbying success. However, public pressure campaigns may only be effective under certain conditions. Thus, I first assess the main relationship and then assess evidence for or against different potential causal pathways of influence. The main indirect pathway by which campaigns may influence agency policymaking is through engaging members of Congress.

Through the iterative combination of automated search methods and hand-coding described above, I also identify comments submitted by elected officials, with special attention to members of the U.S. Congress.



#### Hand-coded sample

To estimate the influence of public comments on policy, I code almost all* comments on a random sample of rules, recording the type of organization, the lobbying coalition to which each belongs, the type of coalition (primarily public or private interests), their policy demands, and the extent to which the change between draft and final rule aligned with their demands. This level of alignment between policy asks and policy outcomes is my measure of lobbying success. It does not identify a causal relationship--true policy influence, but it is state of the art with these kinds of observational data (see @Yackee2006JOP). 

*On each selected rule, I code all comments submitted as file attachments or emails, but only some comments typed in a text box. I include comments typed in a text box if they share text with other comments (see above). This includes nearly all comments on most rules, excluding entirely unique text-box content, which is marginal qualitatively and quantitatively. For comments sharing text, I code one sample document for all versions of the form letter. 

My approach to measuring lobbying success starts with policy demands raised in comments. I code the general regulatory/deregulatory direction of the policy change, but the dimensions of conflict on which I judge lobbying success are those identified by commenters. They do not emerge from a reading of the policy or not any a priori concept. Instead, I read the change between draft and policy with an eye for alignment with commenters' requests (including requests that specific parts of the draft policy do not change.)


My approach of identifying the dimensions of the conflict by comments has benefits and downsides. Compared to other potential measures of success, it is more likely to focus on things that commenters care about. For example, one could measure success by the number of times a comment is mentioned in the agency's response to comments. However, this may capture strategic responsiveness by agencies choosing to discuss some issues more than others. It also counts explicit rejections toward the measure of responsiveness. One could also measure success by focusing on a-priory potential aspects of the policy. @Balla2020 count five factors: (1) the number of regulated entities, (2) number of activities or substances being regulated, (3) the level of pollution standards, (4) the compliance and effective deadlines of the regulation, and (5) the monitoring and reporting requirements. Each takes one value (increasing or decreasing), and each is weighted equally in the analysis. In contrast, starting with comments allows commenters to highlight the issues they care most about.


The hand-coded sample includes `r nrow(comments_coded)` hand-coded documents representing `r sum(comments_coded$comments)` comments. However, many of these comments belong coalitions and are thus not independent. When Friends of Earth and the Sierra Club lobbying together on a rule, the success of each depends on the other. Thus, I group comments into coalitions. The hand-coded sample includes `r nrow(coalitions_coded)` "coalitions," `r coalitions_coded %>% filter(coalition_size == 1) %>% nrow()` of which are single organizations (not really coalitions), leaving `r coalitions_coded %>% filter(coalition_size > 1) %>% nrow()` true coalitions of groups lobbing together. 


The fact that several coalitions may lobby on the same rule creates a less problematic form of dependence among observations. One coalition's lobbying success is correlated with another coalition's lobbying success to the extent that they are asking for the same or contradicting things. Because we have grouped organizations into coalitions, the causally-related asks (those organizations lobbying *because* another organization is) are largely accounted for. 


<!--
Finally, to better capture positions expressed by Members of Congress on proposed rules, I supplement congressional comments posted on regulations.gov with Freedom of Information Act Requests for all communication from Members of Congress to each agency on proposed rules from 2007 to 2019.^[Many agencies provided records of their congressional correspondence going back to 2005 or earlier.]
-->

### Summary Statistics for Hand-coded Data

These hand-coded data include `r nrow(comments_coded)` unique comments, some of which have identical copies for a total of `r sum(comments_coded$number_of_comments_received %>% as.numeric(),na.rm = T )` comments. These comments represent `r nrow(coalitions_coded)` distinct lobbying coalitions ranging in size from 2 to `r max(coalitions_coded$coalition_size)` organizations. Figure \@ref(fig:hist-coalitions) shows that coalitions are fairly balanced between those that succeed and fail to get the changes they seek in the final rule. `r percent( sum(coalitions_coded$coalition_business, na.rm = T)/nrow(coalitions_coded) )` are business-led coalitions. 

Table \@ref(tab:data-coded) shows a sample of coded data, summarized at the coalition level.

```{r data-coded, cache = FALSE}
d <- coalitions_coded %>% 
  drop_na(coalition_business) %>%
  filter(coalition_comment != "FALSE") %>% 
  distinct() %>% 
  dplyr::select(-coalitions)

d %>% group_by(docket_id) %>% 
  slice_max(comments, n = 2) %>%
  dplyr::select(docket_id, starts_with("coalition")) %>% 
  distinct() %>% 
  kable3(caption = "A Sample of Hand-Coded Data Summarized by Coaltion") 
```

\@ref(tab:org-comments) shows a sample of the hand-coded data. 

```{r org-comments}
comments_coded %>% 
  dplyr::select(document_id, comment_type, comments, starts_with(c("org_", "coalition")), -org_name_short) %>% 
  group_by(coalition_comment) %>% 
  slice(n = 2) %>%
  kable3(caption = "Sample of Organzation-Level Hand-Coded Public Comment Data")
```

#### Comments from legislators

One mechanism by which campaigns may influence policy is by mobilizing members of Congress. Thus, I identify comments submitted by members of Congress and count the number of legislators in each lobbying coalition. Figure \@ref(fig:congress) shows the number of comments from members of Congress received during rulemaking by a sample of federal agencies. Oversight letters are frequently co-signed by multiple members from the Senate, House, or both chambers. 

```{r congress, fig.cap = "Number of Rulemaking Comments from Members of Congress per Year, 2005-2020", fig.subcap= "Bureau of Ocean Energy Management (BOEM), Consumer Financial Protection Bureau (CFPB), Department of Education (ED), Office of Energy Efficiency and Renewable Energy (EERE), Federal Aviation Administration (FAA), Federal Railroad Administration (FRA), Fish and Wildlife Servicwe (FWS), Department of Health and Human Services (HHS), Office of the Comptroller of the Currency (OCC), Occupational Safety and Health Administration (OSHA), Social Security Adminisration (SSA), US Trade Representative (USTR)", out.width = "100%", fig.height=6}
load(here::here("data", "comments_congress.Rdata"))

comments_congress$Year %<>% as.numeric()

breaks <- seq(2000, 2020,by = 2)

comments_congress %>% 
  as_tibble() %>%
  filter(Year %>% as.numeric() > 2000,
         Year %>% as.numeric() < 2021) %>% 
  add_count(agency, name = "agency_n") %>%
  filter(agency_n > 88) %>% 
  count(Year, Chamber, agency, sort = TRUE) %>%
  ggplot() +
  aes(x = Year, y = n, fill = Chamber) + 
  geom_col(position = "stack") + 
  facet_wrap("agency", scales = "free") + 
  labs(x = "" ,
       y = "Number of Rulemaking Comments from Members of Congress") + 
  scale_x_continuous(breaks = breaks) + 
  theme(axis.text.x = element_text(angle = 90),
        axis.ticks.x = element_blank(),
        panel.grid.major.x = element_blank())

# table 
# elected comments by type
comments_coded %>% 
  filter(comment_type == "elected") %>%  
  mutate(org_type = str_remove(org_type, "-.*|;.*| .*")) %>%
  count(org_type,  sort =T) %>% 
  rename(elected_type = org_type) %>%
  kable3(caption = " ")
```

