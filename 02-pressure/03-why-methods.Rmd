## Testing the Theory

### Data {#why-data}

<!--
Bring together information on the mass commenting coding in one table with statistics and examples to summarize for the reader.
-->

To assess the competing hypotheses about whether political insiders or outsiders mobilize public participation in bureaucratic policymaking, I collected a corpus of approximately 80 million comments via the
regulations.gov API. About 50 million of these comments were on proposed
rules (over 16,000 proposed rules from 144 agencies from 2005 to 2020). Of these, public pressure campaigns targeted approximately 400 rules from 46 agencies.
I then linked these comments to other data on the rules from the Unified
Agenda and Office of Information and Regulatory Affairs Reports on draft
rules sent to them for review. Summary statistics for these data are
available in the Appendix.

```{r comments-per-year, fig.cap = "Comments per Proposed Rule and Total Comments per Year", out.width = NULL, out.height = "25%", fig.show = "hold"}

knitr::include_graphics(here::here("Figs", "rules-comments-per-year-1.png"))

knitr::include_graphics(here::here("Figs", "comments-mass-vs-unique.pdf"))

```


### Methods: Measuring Public Pressure and Political Information {#why-methods}

To identify the groups mobilizing public pressure campaigns, I develop methods to attribute individual comments to the
campaigns that mobilized them and to measure the intensity of preferences
expressed. To link individual comments to the more sophisticated
lobbying efforts they support, I first use textual similarity to identify
clusters of similar comments, reflecting formal and informal coalitions.
Comments with identical text (if any) indicate a coordinated campaign. Through an iterative process of hand-coding and computational methods, I then identify the organization responsible for mobilizing each comment and group organizations into coalitions. 

For each campaign, I measure
the intensity and potential for the movement to grow. To measure
intensity, I examine the ratio of high-effort and low-effort comments.
To measure the potential to grow, I measure the number of comments mobilized
indirectly by the campaign (i.e., those that support a campaign but do
not include text provided by the campaign). The result is several new
measures of participation in bureaucratic policymaking.




<!--
### Spontaneous or mediated?

### If mediated, who is mobilizing
-->

### The observable implications of various forms of public engagement

The different forms of participation asserted or assumed in the literature have empirically observable patterns. 

#### Individuals 

 The solicitation on regulations.gov--"Let your voice be heard"--suggests that individuals are expressing themselves directly. Indeed, anyone can write a letter or type a comment in the text box on regulations.gov, and many people do. Individuals acting on their own submit content ranging from obscenities and memes to detailed personal accounts of how a policy would affect them and even poetry aimed at changing officials' hearts and minds. 

@Verba1987 distinguish "citizen initiated contacts" from "cooperative activity" (pg. 54).
Administrative law scholarship often discusses individual participants in this light as well.
@Cuellar2005 finds that members of the "lay public" raise important new concerns beyond those raised by interest groups. He advocates for institutional reforms that would make it easier for individuals to participated and increase the sophistication of individual comments on proposed policies. 

The remaining forms of participation are all mediated through an organization's pressure campaign. Comments from people mobilized as part of a campaign differ from those of individuals acting on their own in two ways: they often mention the name of the organization that mobilized them, and the text will often be similar or identical to other comments in the campaign, reflecting coordination. These features eliminate the value that  @Cuellar2005 and others see in individual comments. If comments reference an organization that mobilized them, they likely have more to offer than that the more sophisticated organization has not already provided. If comments are identical, they certainly provide no new information.

#### Membership Organizations

If most commenters are members of membership organizations as @Kerwin2011 suggest, a large campaign of, say one million people, will require a large collection of membership organizations. Very few organizations have a million members, and those that do are unlikely to mobilize all of them, so mobilizing a large number of people will usually require a large coalition of membership organizations. Commenters should identify themselves as members of these many organizations.

For example, if most comments are mobilzed by membership groups, we would expect most comments to look like this comment from the NorthEast Hook Fisherman's Association:
> "We represent a small group of Commercial Fishermen with the Limited Access Handgear HA Permits, employing the use rod and reel, handlines or tub trawls to catch Cod, Haddock and Pollock along with small quantities of other regulated and non-regulated marine fish. Historically and currently our fishermen account for a small percentage of the groundfish landed in New England. However, the monetary gains obtained by the participants in this fishery are very important to us. ([NOAA-NMFS-2013-0050-0025](https://www.regulations.gov/comment/NOAA-NMFS-2013-0050-0025))

Similar groups narrowly concerned about shrimp and hilibut catach limits also commented on behalof of their members. 

#### Policy change organizations

Mobilizing people just for a particular policy fight requires a significant organizing capacity. @McNutt2007 calls these formations "policy change organizations." 
There is a spectrum of organizing the unorganized. The poles might be labeled "grassroots" and "astroturf." On the grassroots end, engagement is driven by a combination of passionate volunteerism and a supportive, attentive public [@Key1961] or issue public [@Converse1964]. In practice, the campaigns that most resemble the grassroots ideal are not pure volunteerism but are organized by policy change organizations like Credo Action and Organizing For American on the left and Americans for Prosperity on the right.



These organizations have large mailing lists and media operations. Membership organizations like the Sierra Club may often mobilize beyond their membership base and thus take the form of a policy change organization as well. 

Like people mobilized through their membership organizations, people mobilized by policy change organizations will often cite the mobilizing organization.  
Unlike those mobilized through membership organizations, mobilization by policy change organizations is more likely to be concentrated in a few large organizations with the specific resources for running campaigns that engage passionate or interested but unaffiliated segments of the public. 

#### Astroturf

Toward the astroturf end of the spectrum of policy change organizations, well-funded efforts gather signatures from a much less passionate and attentive population. Where grassroots organizing relies on existing underlying interests that merely need to be given an opportunity to engage, people engaged by astroturf campaigns are generally disinterested in the policy and engage merely because of paid ads or petition gathering, often involving some deception in order to get people to take action on an issue that they would not take if the issue was presented more clearly. Likewise, the organizations actually collecting the signatures would have no interest in doing so if they were not being paid. The aim is to give an appearance of support. 

One example of an astrotruf campaign is Shell Oil's campaign to open the Arctic Outer Continental Shelf to oil and gas drilling. 
Shell provided a template letter with a place to insert a company or constituency: 
> On behalf of [enter company or constituents], I am writing to demonstrate my strong support of oil and gas development in the Arctic Outer Continental Shelf (OCS).

In a more complex example, Access Financial and other payday lending companies sponsored two campaigns targeting a regulation proposed by Consumer Financial Protection Bureau in 2016. First, Access Financial had their employees solicit comments from customers, which Access then uploaded to regulations.gov. Many customer letters contained some version of "I have been told that payday loans would not exist in my community if the government's proposed regulations went into effect." The customer comments suggest that they had not been told much about the rule, which limited interest rates and the number of times short term loans could be compounded. Most customers wrote some version of "Do not close this store"--a few even complained about exactly the issues that CFPB's regulation aimed to address. One customer wrote "Although some of the fees are a bit high, it should be my choice whether to get a loan or not" (Access Financial Comment 91130). Another wrote "I need to keep recieving my Check'n'Go loans so I can have the time to start paying them back in the next 1 1/2 to 2 years" (Access Financial Comment 91130) indicating that Check'n'Go (a subsidiary of Access Financial) was engged in serial re-lending that put this customer deeper in debt. To the extent that this campaign relied on deception and not the customer's interests (even as the customers understood them), this would count as astroturf. Second, Access sponsored an effort to gather petition signatures at churches. Finally, Access and other payday loan companies uploaded supportive notes from community organizations to which they had given money. Like the churchgoers, these people had no reason to comment except that they had received money from the potentially regulated companies. 

Spotting astroturf in the wild is difficult by design. However, the clear observable result is a large number of comments advocating on behalf of large business interests. These are the organizations with the resources and incentives to sponsor astroturf campaigns, and they do [Lyon2005].



<!--
Astroturf: Interest Group Lobbying and Corporate Strategy
Thomas P. Lyon  John W. Maxwell

- in which the firm covertly subsidizes a group with similar views to lobby when it normally would not;
Lloyd Bentsen, a long‐time senator from Texas, describes the artificial grassroots campaigns created by public relations (PR) firms (Stauber and Rampton, 1995, p. 79)
For example, Lupia and McCubbins (1994) and de Figueiredo et al. (1999) study how administrative procedures can be designed to optimize the flow of information to politicians, and Baron (2001) develops a model in which activists attempt to influence corporate strategy via the threat of consumer boycotts. Kollman (1998) studies the motivations and strategy behind lobbying behavior based on detailed interviews with 90 interest group leaders. Grossman and Helpman (2001) provide an excellent introduction to the recent theoretical literature on interest group politics.



Astroturf, Technology and the Future of
Community Mobilization:
Implications for Nonprofit Theory
JOHN McNutt
University of Delaware
School of Urban Affairs & Public Policy
KATHERINE BOLAND
Astroturf, quite simply, is synthetic grassroots organizing created for manipulative political purposes (see Lyon &
Maxwell, 2004; Allen, 1998; Austin, 2002). In this type of activity, an entity that wishes to affect public policy creates an effort
that gives the appearance of grassroots support
-->

<!--




> CITE STEVES ASTROTURF PAPER AND RELATED LIT

-->

### Who lobbies?

Metadata on the authors of comments and their
organizational affiliations are inconsistent and incomplete. As this
information is key to identifying influential actors, improving these
data was a significant data-organization task.

#### Mobilizing organizations

Through an iterative combination of automated search methods and hand-coding, I identify the organization responsible for over 40 million comments, including all organizations responsible for mobilizing 100 or more
comments with repeated text--either identical text or partially unique texts that contain shared language. I then searched comment texts for
mentions of these organizations' names to complete missing information
on the mobilizing organization. 

### Who lobbies together?

Having identified who is participating in rulemaking, the next step is
to determine who is lobbying together. Studies of rulemaking stress the importance of coalitions [@Yackee2006JOP; @Dwidar2019]. Scholars have measured coalitions of organized groups but have yet to attribute citizen comments to the coalition that mobilized them.

#### Identifying coalitions using text reuse 


I identify comments that are not identical but share a 10-word (or
"10-gram") string using a moving window function looping over each
possible pair of texts to identify matches.^[For more about this method and comparisons with related partial matching methods such as the Smith-Waterman algorithm, see @Casas2017 and @Judge-Lord2017.]
When actors sign onto the same comment, it is clear that they are
lobbying together. However, various businesses, advocacy groups, and
citizens often comment separately, even when they are aligned. Text-reuse (using the exact same ten-word phrases) captures this alignment. 

Figure \@ref(fig:percent-match) shows the percent of shared text for a sample of 50 comments on the Consumer Financial Protection Bureau's 2016 Rule regulating Payday Loans. Comments are arranged by the document identifier assigned by regulations.gov on both axes. 
The black on the diagonal indicates that each document has perfect overlap with itself. Black squares off the diagonal indicate additional pairs of identical documents. For example, 100% of the words from Comment 95976 are part of some tengram that also appears in 95977 because the exact same comment was uploaded twice. 
The block of grey squares indicates a coalition of commenters using some identical text.
Comments [91130](https://www.regulations.gov/document?D=CFPB-2016-0025-91130) through [91156](https://www.regulations.gov/document?D=CFPB-2016-0025-91154) are all partial or exact matches. Most are part of a mass comment campaign by Access Financial. The percent of the identical text is lower than many mass-comment campaigns because these are hand-written comments, but the n-gram method still picks up overlap in the OCRed text in the header and footer. 

```{r percent-match, fig.show = "hold", out.width = "60%", fig.cap="Percent of Matching Text in a Sample of Public Comments"}

knitr::include_graphics("Figs/comment_percent_match_plot-1.png")  
```



<!--  Identifying coalitions using clustering methods
I use statistical models of text to classify comments into coalitions. I cluster
documents by the frequency with which they use different words. Being
classified together does not mean that the documents all address exactly
the same distribution of substantive issues, just that they use similar
words relative to the full set of documents. I start by modeling all
comments on each rule (collapsing identical comments to one document)
with two and three clusters, which I then inspect to see how well the
comments of named organizations were classified. If the two cluster
model most sensibly describes the conflict, I label these clusters "pro" and "con" If the three-cluster model more sensibly describes the
conflict, I label these clusters as "pro, con, other." If neither fits
well, I increase the number of clusters as needed.

```{r kmeans, fig.cap = "K-means clustering fails to capture coalitions when nearly all comments oppose a regulation"}

knitr::include_graphics(here::here("Figs", "kmeans.png"))
```


The asymmetry in expressed support for most rules presents challenges
for unsupervised clustering because much of the variation in comment
texts is within-coalition variation. For example, one of the most common
clustering methods, k-means clustering, often captures within-coalition
variation. Figure \@ref(fig:kmeans) shows k-means clusters based on a normalized
measure of word frequency (term-frequency/inverse-document-frequency)
compared to two principal components of variation. Neither k-means nor
principal components analysis is well suited to identifying the small
number of comments supporting the Park Service's proposed restrictions
on protests in Washington DC.

Two strategies may improve clustering. First, even partial text reuse
generally indicates that comments belong to the same coalition. For
example, as seen at the top of Figure
\@ref(fig:kmeans), models may be restricted to cluster the large number of comments beginning with
"As a citizen who has frequently participated" in the same coalition
even if they go on to add different personal anecdotes about why protest
rights are important to them. Thus, clustering methods could be
restricted to group partially copied texts, as well as entirely copied
texts. Second, a Bayesian mixture model may better recover pro and con
clusters, especially with strong priors comments using positive and
negative sentiment words belong together.
-->

### Measuring the volume, intensity, and potential contagion of public engagement

I measure variation in engagement in three ways, corresponding to the
three types of comments described above.

**Volume.** 
First, I measure the total number of comments on the rule.
Commenting results from multiple processes. First, a group must decide to
lobby. Then, a group must decide to mobilize public pressure. Finally, the resulting number of comments depends on the response to the
campaign. There may be many cases where groups may have had
success mobilizing but never reached the choice of whether to mobilize
or not. For example, relevant groups may have been unaware of the draft rule. Once the decision
to mobilize has been reached and made, the response to mobilizing is a
count process. Thus, I expect the count of comments across rules to
follow a zero-inflated negative binomial distribution.

**Effort.** 
I measure effort per comment by the number of words people
write, omitting any text longer than ten words not unique to that comment,
usually because a mobilizing organization provided it. For example, the Sierra Club mobilized more than 47,710
people to submit exactly the same text on the delay of the methane
pollution rule, but 7,452 people also took the time to write a
personalized comment in addition to the text provided (see Figure \@ref(fig:sierra)). 
Completely unique comments (those that do not copy text from a form letter at all) generally indicated high levels of effort. As @Verba1987 note, signing a form letter requires "some" effort, writing an original letter to a government official requires "a lot" of "initiative" (effort). The longer the letter, the more effort required. 

While effort, as measured by the number of words people write, may be normally distributed, the low end of the observed distribution is truncated.
This is because we will not observe people who have low levels of passion for the issue; they either do not cross the effort threshold required to comment or opt
to write nothing more than the form letter. 

**Contagion.** Mass-comment campaigns have wildly different results.
Some organizations submit a clean 10,000 copies of (signatures on) the same comment.^[For example, Americans For Prosperity's campaign on the XXXX rule.]
Others "go viral"---inspiring a mess of further engagement where the
original messages are translated through social media posts and news
stories. To identify people who were plausibly mobilized indirectly by a
campaign, I count the number of people who use a similar distribution of
words to that of the form letter but fewer than ten words matching any
other comment. This is a regular count process.
