## Testing the Theory

### Data {#why-data}

To assess the competing hypotheses about whether political insiders or outsiders mobilize public participation in bureaucratic policymaking, I collected a corpus of approximately 80 million comments via the
regulations.gov API. About 50 million of these comments were on proposed
rules (over 16,000 proposed rules from 144 agencies from 2005 to 2020). Of these, public pressure campaigns targeted approximately 400 rules from 46 agencies.
I then linked these comments to other data on the rules from the Unified
Agenda and Office of Information and Regulatory Affairs Reports on draft
rules sent to them for review. Summary statistics for these data are
available in the Appendix.

```{r comments-per-year, fig.cap = "Comments per Proposed Rule and Total Comments per Year", out.width = NULL, out.height = "25%", fig.show = "hold"}

knitr::include_graphics(here::here("Figs", "rules-comments-per-year-1.png"))

knitr::include_graphics(here::here("Figs", "comments-mass-vs-unique.pdf"))

```


### Methods: Measuring Public Pressure and Political Information {#why-methods}

To identify the groups mobilizing public pressure campaigns, I develop methods to attribute individual comments to the
campaigns that mobilized them and to measure the intensity of preferences
expressed. To link individual comments to the more sophisticated
lobbying efforts they support, I first use textual similarity to identify
clusters of similar comments, reflecting formal and informal coalitions.
Comments with identical text (if any) indicate a coordinated campaign. Through an iterative process of hand-coding and computational methods, I then identify the organization responsible for mobilizing each comment and group organizations into coalitions. 

For each campaign, I measure
the intensity and potential for the movement to grow. To measure
intensity, I examine the ratio of high-effort and low-effort comments.
To measure the potential to grow, I measure the number of comments mobilized
indirectly by the campaign (i.e., those that support a campaign but do
not include text provided by the campaign). The result is several new
measures of participation in bureaucratic policymaking.




<!--
### Spontanious or mediated?

### If mediated, who is mobilizing
-->

### The observable implications of various forms of public engagment

The different forms of participation asserted or assumed in the literature have empiracally observable patterns. 

#### Individuals 

In civics classrooms and Norman Rockwell paintings, raising concerns to government is an individual affair. The solicitation on regulations.gov "Let your voice be heard" suggests that individuals are expressing themselves directly. Indeed, anyone can write a letter or type a comment in the text box on regulations.gov and many people do. Individuals acting on their own submit content ranging from obsenities and memes to detailed personal accounts of how a policy would affect them and even poetry aimed changing officials' hearts and minds. 

Administrative law scholarship often discusses individual participants in this light as well.
@Cuéllar2015 finds that members of the "lay public" raise important new concerns beyond those raised by interest groups. He advocates for institutional reforms that would make it easeier for individuals to participated and increase the sophistication of individual comments on proposed policies. 

The remaining forms of participation are all mediated through an organization's pressure campaign. Comments from people mobilized as part of a campaign differ from those of individuals acting on their own in two ways: they often mention the name of the organization that mobilized them and the text will often be similar or identical to other comments in the campaing, reflecting coorination. These features eleminate the value that  @Cuéllar2015 and others see in individual comments. If comments reference and organization that mobilized them, they likely have more to offer than that the more sophisticated organization has not already provided. If comments are identical the certianly provide no new information.

#### Membership Organizations

If most commenters are members of membership organizations as @Kerwin2011 suggest, a large campaign of, say one million people, will require a large collection of membership organizations. Very few organizations have a milion memebers and those that do are unlikely to mobilize all of them, so mobilizing a large number of people will usually require a large coalition of membership organizations. Commenters should identify themselfs as members of these many organizations.

#### Policy change organizations

Mobilizing people just for a particular policy fight requires a significant organizing capacity. @McNutt2007 calls these formations "policy change organizations." 
There is a spectrum of organizing the unorganized. The poles might be labled "grassroots" and "astroturf." On the grassroots end, engagment is driven by a combination of passionate volunteerism and a supportive attentive public [@Key1961] or issue public [@Converse1964]. In practice, the campaings that most resemble the grassroots ideal are not pure volunteerism, but are organized by policy change organizations like Credo Action and Organizing For American on the left and Americans for Prosperity on the right. These organizations have large mailing lists and media operations. Membership organizations like the Sierra Club may often mobilize beyond their membership base and thus take the from of a policy change organization as well. 

Like people mobilized throught their membership organizations, people mobilized by poicy change organizations will often cite the mobilzing organization.  
Unlike those mobilized though membership organiztions, mobilization by policy change organizations is more likely to be concentrated in a few large organization with the specific resources for running campaings that engage passionate or interested but unaffiliated segments of the public. 

#### Astroturf

Toward the astroturf end of the spectrum of policy change organizations, well-funded efforts gather signatures from a much less passionate and attentive population. Where grassroots organizing relies on existing underlying interests that merely need to be given an opportunity to engage, people engaged by astroturf campaigns are generally disintersted in the policy and engage merely because of paid ads or petition gathering, often involving some deception in order to get people to take action on an issue that they would not take if the issue was presented more clearly. Likewise, the organizations actually collecting the signatures would have no interst in doing so if they were not being paid. The aim is to give an appearance of support. 

For example Access Fininanical and other payday lending companies sponsored two campaigns targeting a regulation proposed by Consumer Financial Protection Bureau in 2016. Fist, Access Fnanncial had their employees solicit comments from customers, which Access then uploaded to regulations.gov. The customer comments suggest that they had not been told much about the rule, which limited interest rates and XXXXX. Most customers wrote some version of "Do not close this store"--a few even complained about exactly the issues that CFPB's regulation aimed to address. XXXXXX To the extent that this campaign relied on deception and not the customer's interests (even as the customers understood them), this would count as astroturf. Second, Access sponsored an effort to gather petition signatures at churches. Finally, Access and other payday loan companies uploaded supportive notes from commmunity organizations to which they had given money. Like the churchgoers, these people had no reason to comment except that they had recieved money from the potentially regulated companies. 

Spotting astroturf in the wild is difficult by design. However, the clear observable result is comments advoding on behalof of large business intersts. These are the organizations with the resources and incentives to sponsor astroturf campaigns and they do [@Lyon2005].



<!--
Astroturf: Interest Group Lobbying and Corporate Strategy
Thomas P. Lyon  John W. Maxwell

- in which the firm covertly subsidizes a group with similar views to lobby when it normally would not;
Lloyd Bentsen, long‐time senator from Texas, to describe the artificial grassroots campaigns created by public relations (PR) firms (Stauber and Rampton, 1995, p. 79)
For example, Lupia and McCubbins (1994) and de Figueiredo et al. (1999) study how administrative procedures can be designed to optimize the flow of information to politicians, and Baron (2001) develops a model in which activists attempt to influence corporate strategy via the threat of consumer boycotts. Kollman (1998) studies the motivations and strategy behind lobbying behavior based on detailed interviews with 90 interest group leaders. Grossman and Helpman (2001) provide an excellent introduction to the recent theoretical literature on interest group politics.



Astroturf, Technology and the Future of
Community Mobilization:
Implications for Nonprofit Theory
JOHN McNuTT
University of Delaware
School of Urban Affairs & Public Policy
KATHERINE BOLAND
Astroturf, quite simply, is synthetic grassroots organizing created for manipulative political purposes (see Lyon &
Maxwell, 2004; Allen, 1998; Austin, 2002). In this type of activity, an entity that wishes to affect public policy creates an effort
that gives the appearance of grassroots support
-->

<!--




> CITE STEVES ASTROTURF PAPER AND RELATED LIT

-->

### Who lobbies?

Metadata on the authors of comments and their
organizational affiliations are inconsistent and incomplete. As this
information is key to identifying influential actors, improving these
data was a significant data-organization task.

#### Mobilizing organizations

Through an iterative combination of automated search methods and hand-coding, I identify the organization responsible for over 40 million comments, including all organizations responsible for mobilizing 100 or more
comments with repeated text--either identical text or partially unique
texts that contain shared language. I then searched comment texts for
mentions of these organizations' names to complete missing information
on the mobilizing organization. 

### Who lobbies together?

Having identified who is participating in rulemaking, the next step is
to determine who is lobbying together. Studies of rulemaking stress the importance of coalitions [@Yackee2006JOP; @Dwidar2019]. Scholars have measured coalitions of organized groups but have yet to attribute citizen comments to the coalition that mobilized them.

#### Identifying coalitions using text reuse 


I identify comments that are not identical but share a 10-word (or
"10-gram") string using a moving window function looping over each
possible pair of texts to identify matches.^[For more about this method and comparisons with related partial matching methods such as the Smith-Waterman algorithm, see @Casas2017 and @Judge-Lord2017.]
When actors sign onto the same comment, it is clear that they are
lobbying together. However, various businesses, advocacy groups, and
citizens often comment separately, even when they are aligned. Text-reuse (using the exact same ten-word phrases) captures this alignment. 

Figure \@ref(fig:percent-match) shows the percent of shared text for a sample of 50 comments on the Consumer Financial Protection Bureau's 2016 Rule regulating Payday Loans. Comments are arranged on by the document identifier assigned by regulations.gov on both axes. 
The black on the diagonal indicates that each document has perfect overlap with itself. Black squares off the diagional indicate additional pairs of identical documents. For example, 100% of the words from Comment 95976 are part of some tengram that also appears in 95977 because the exact same comment was uploaded twice. 
The block of grey squres indicate a coalition of commenters using some idential text.
Comments [91130](https://www.regulations.gov/document?D=CFPB-2016-0025-91130) through [91156](https://www.regulations.gov/document?D=CFPB-2016-0025-91154) are all partial or exact matches. Most are part of a mass comment campaign by Access Financial. The percent of the identical text is lower than many mass-comment campaigns because these are hand-written comments, but the n-gram method still picks up overlap in the OCRed text in the header and footer. 

```{r percent-match, fig.show = "hold", out.width = "60%", fig.cap="Percent of Matching Text in a Sample of Public Comments"}

knitr::include_graphics("Figs/comment_percent_match_plot-1.png")  
```


<!--  Identifying coalitions using clustering methods
I use statistical models of text to classify comments into coalitions. I cluster
documents by the frequency with which they use different words. Being
classified together does not mean that the documents all address exactly
the same distribution of substantive issues, just that they use similar
words relative to the full set of documents. I start by modeling all
comments on each rule (collapsing identical comments to one document)
with two and three clusters, which I then inspect to see how well the
comments of named organizations were classified. If the two cluster
model most sensibly describes the conflict, I label these clusters "pro" and "con" If the three-cluster model more sensibly describes the
conflict, I label these clusters as "pro, con, other." If neither fits
well, I increase the number of clusters as needed.

```{r kmeans, fig.cap = "K-means clustering fails to capture coalitions when nearly all comments oppose a regulation"}

knitr::include_graphics(here::here("Figs", "kmeans.png"))
```


The asymmetry in expressed support for most rules presents challenges
for unsupervised clustering because much of the variation in comment
texts is within-coalition variation. For example, one of the most common
clustering methods, k-means clustering, often captures within-coalition
variation. Figure \@ref(fig:kmeans) shows k-means clusters based on a normalized
measure of word frequency (term-frequency/inverse-document-frequency)
compared to two principal components of variation. Neither k-means nor
principal components analysis is well suited to identifying the small
number of comments supporting the Park Service's proposed restrictions
on protests in Washington DC.

Two strategies may improve clustering. First, even partial text reuse
generally indicates that comments belong to the same coalition. For
example, as seen at the top of Figure
\@ref(fig:kmeans), models may be restricted to cluster the large number of comments beginning with
"As a citizen who has frequently participated" in the same coalition
even if they go on to add different personal anecdotes about why protest
rights are important to them. Thus, clustering methods could be
restricted to group partially copied texts, as well as entirely copied
texts. Second, a Bayesian mixture model may better recover pro and con
clusters, especially with strong priors comments using positive and
negative sentiment words belong together.
-->

### Measuring the volume, intensity, and potential contagion of public engagement

I measure variation in engagement in three ways, corresponding to the
three types of comments described above.

**Volume.** 
First, I measure the total number of comments on the rule.
Commenting results from multiple processes. First, a group must decide to
lobby. Then, a group must decide to mobilize public pressure. Finally, the resulting number of comments depends on the response to the
campaign. There may be many cases where groups may have had
success mobilizing but never reached the choice of whether to mobilize
or not. For example, relevant groups may have been unaware of the draft rule. Once the decision
to mobilize has been reached and made, the response to mobilizing is a
count process. Thus, I expect the count of comments across rules to
follow a zero-inflated negative binomial distribution.

**Effort.** 
I measure effort per comment by the number of words people
write, omitting any text longer than ten words that is not unique to that comment,
usually because a mobilizing organization provided it. For example, the Sierra Club mobilized more than 47,710
people to submit exactly the same text on the delay of the methane
pollution rule, but 7,452 people also took the time to write a
personalized comment in addition to the text provided (see Figure \@ref(fig:sierra)). However, we may
not observe people who have low levels of passion for the issue because
they either do not cross the effort threshold required to comment or opt
to write nothing more than the form letter. Thus, while effort measured
by the number of words people write may be normally distributed, the low end of the observed distribution is truncated.

**Contagion.** Mass-comment campaigns have wildly different results.
Some organizations submit a clean 10,000 copies of (signatures on) the same comment.^[For example, Americans For Prosperity's campaign on the XXXX rule.]
Others "go viral"---inspiring a mess of further engagement where the
original messages are translated through social media posts and news
stories. To identify people who were plausibly mobilized indirectly by a
campaign, I count the number of people who use a similar distribution of
words to that of the form letter but fewer than ten words matching any
other comment. This is a regular count process.
