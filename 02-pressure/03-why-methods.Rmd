## Testing the Theory {#why-data-methods}

To assess my theory about which groups should mobilize public participation in bureaucratic policymaking, I use public comments in federal agency rulemaking. However, my theories and methods should also apply to other kinds of political engagement such as through social media or protests as well as to other political decisions, including state-level rulemaking.^[Social media
    engagement may be especially important if agencies implement the
    recommendations of @ACUS2018 that "Agencies should consider using
    social media before or in connection with direct final rulemaking to
    quickly identify whether there are significant or meaningful
    objections" (p. 34).]
    
### Data {#why-data}

<!--
Bring together information on the mass commenting coding in one table with statistics and examples to summarize for the reader.

TODO: CODE
-->



```{r}
load(here::here("data","rules_metadata.Rdata"))

# min(rules$posted_date, na.rm = T)
# max(rules$posted_date, na.rm = T)

dockets <- rules %<>% 
    filter(docket_title != "EPA Training Docket") %>%
    group_by(docket_id) %>%
  mutate(year = str_sub(posted_date, 1, 4) %>% as.numeric(),
         comments = sum(number_of_comments_received),
         open = !is.na(comment_start_date)|!is.na(comment_due_date)|number_of_comments_received > 0,
         open = sum(open, na.rm = T) > 0
)

rules %<>% filter(year >2004, year <2021, docket_type == "Rulemaking")

mass <- filter(rules, comments > 100)

top10 <- slice_max(mass %>% ungroup() %>% distinct(docket_id, comments), order_by =  comments, n = 10) 
```

I collected a corpus of over `r dockets$number_of_comments_received %>% sum() %>% {./1000000} %>% round()` million public comments via the
regulations.gov API. `r rules$number_of_comments_received %>% sum() %>% {./1000000} %>% round()` million of these comments are on rulemaking dockets.
I then linked these comments to other data on the rules from the Unified
Agenda and Office of Information and Regulatory Affairs Reports. Summary statistics for these data are
available in the Appendix.

From 2005 to  2020, agencies posted `r nrow(distinct(rules, docket_id))` rulemaking dockets to regulations.gov. and solicited public comments on `r nrow(distinct(rules %>% filter(open), docket_id))`. Only `r nrow(distinct(mass, docket_id))` of these rulemaking dockets received more than 100 comments, but this small share of rules garnered `r percent(sum(mass$number_of_comments_received)/sum(rules$number_of_comments_received), accuracy = .01)` (`r sum(mass$number_of_comments_received)`) of the comments. The top 10 rulemaking dockets account for `r percent(sum(top10$comments)/sum(rules$number_of_comments_received), accuracy = .01)` (`r sum(top10$comments)`), of the comments.




Figure
\@ref(fig:comments-density) shows a sample of rules matched to Office of Information and Regulatory Affairs coding for major and non-major rules. The modal number of comments for all types of rules, including major and economically significant rules, is less than ten. Indeed, the majority of rules that are open for public comment received no comments. 

```{r comments-density, out.width = "99%", fig.cap = "Comments on Posted to Regulations.gov on Rules Reviewed by OIRA 2005-2020"}

knitr::include_graphics(here::here("Figs", "major-comments-density-1.png"))
```


Table \@ref(tab:dockets) shows the rules that received the most comments on regulations.gov.

```{r dockets}
# Include plot of draft and final rules over time, report number of pairs
rules %>%  
  filter(open) %>% 
    distinct(docket_title, comments) %>%
    ungroup() %>%
    group_by(docket_id) %>% 
    slice(n = 1, with_ties = FALSE) %>% 
    ungroup() %>%
    arrange(-comments) %>% # filter(comments < 1)
    head(100) %>%
    mutate(docket_title = docket_title %>% #str_replace_all(";|:|â€“|--", ";\n") %>% 
               str_sub(0,70)) %>%
    mutate(docket_title = ifelse(nchar(docket_title) == 70, str_c(docket_title, "..."), docket_title) ) %>%# pull(docket_title)
    # ggplot() +
    # aes(x = docket_id, y = comments) +
    # geom_col() + 
    # coord_flip()
    #kablebox()
    kable3(caption = "Rulemaking Dockets by Number of Comments on regulations.gov, 2005-2020")
```


Figure \@ref(fig:comments-per-year) shows an exponential increase in the number of comments per rule over time. Note that comments per rule are on a
logarithmic scale on the y-axis. Proposed rules that have attracted the most public attention have
    been published by the Federal Communications Commission (FCC,
    omitted from this plot), the Environmental Protection Agency (EPA),
    the Department of Interior (DOI), the Bureau of Ocean Energy
    Management (BOEM), the Consumer Financial Protection Bureau (CFPB),
    and Fish and Wildlife Service (FWS). Increasingly, a large number of people are
paying attention to agency policymaking.

```{r comments-per-year, fig.cap = "Number of Comments (log scale) per Proposed Rule 2005-2020", out.width = "55%", fig.show = "hold"}
# TODO alpha = .5, shape = "-", facet_wrap("president")
knitr::include_graphics(here::here("Figs", "rules-comments-per-year-1.png"))
```


#### Policy Advocacy Organizations: From Grassroots to Astroturf

Testing my hypotheses requires that I classify campaigns as driven primarily by public or private interest groups. This is a challenge because appeals to the government are almost always couched in the language of
public interest, even when true motivations are private
[@Schattschneider1975]. Public pressure campaigns are no exception, and mobilizing organizations almost always evoke some version of the public interest. Classifying thus involves judgment calls. 
I describe my classification methods in section \@ref{classify-public-private}. To provide empirical context, this subsection sketches out the range of public and private campaigns with some concrete examples of "public" pressure campaigns that primarily advance private interests.

There is a spectrum of organizing the unorganized. The poles might be labeled "grassroots" and "astroturf." On the grassroots end, engagement is driven by a combination of passionate volunteerism and a supportive, attentive segment of the public. In practice, most campaigns on the grassroots end of the spectrum in federal rulemaking are not pure volunteerism but are organized by policy change organizations like MoveOn and Organizing For American on the left and Americans for Prosperity on the right.
These organizations have large mailing lists and media operations, providing the capacity to mobilize large numbers of people for a particular policy fight. Both public and private interest groups pay for mobilizing services and software. Some providers are non-profits (e.g. Care2); others are for-profit lobbying and campaign consultants (e.g. Nationbuilder, SoftEdge, Mandate Media). Most of these services have strong partisan ties, as is generally the case with lobbying firms [@Furnas2017].
Membership organizations like the Sierra Club often mobilize "members and supporters" beyond their official membership base, thereby taking the form of a policy change organization as well. 

Like people mobilized through their membership organizations, people mobilized by policy change organizations will often cite the mobilizing organization.
Unlike those mobilized through membership organizations, mobilization by policy change organizations is more likely to be concentrated in a few large organizations with the specific resources for running campaigns that engage passionate or interested but unaffiliated or loosely affiliated segments of the public. 


Toward the astroturf end of the spectrum, well-funded efforts gather signatures from a much less passionate and attentive population. Where grassroots organizing relies on existing underlying interests that merely need to be given an opportunity to engage, people engaged by astroturf campaigns are generally disinterested in the policy and engage merely because of paid ads or petition gathering, often involving some deception (e.g., intentionally misled about the policy or its likely effects) to get people to take action on an issue that they would not take if the issue were presented more clearly. Likewise, the organizations collecting the signatures would have no interest in doing so if they were not paid. The aim is to give an appearance of support.
To the extent they mobilize real people, astroturf campaigns are thus a form of outside lobbying intended to create a deceptive appearance of public support. In the extreme, astroturf campaigns may use the names of fake or non-consenting individuals---inside lobbying discussed as outside lobbying. 

For example, in 2016, the Bureau of Ocean Energy Management received several USB drives with hundreds of thousands of comments on its National Outer Continental Shelf Oil and Gas Leasing Program from Joe Jansen. Jansen did not disclose who he worked for. These form letters, each identical except for the signature, resembled press releases from the American Petroleum Institute (API), the main industry association for oil and gas companies. According to a LinkedIn profile and [Congressional Directory](https://www.govinfo.gov/content/pkg/CDIR-2011-12-01/pdf/CDIR-2011-12-01-OH-H-1.pdf), Joe Jansen was a former legislative director for a Republican member of Congress who now worked in Government Relations.  Unlike more "grassroots" campaigns, no information was provided about who the signatories were or why they cared about oil and gas leasing. Joe Jansen, however, is also associated with other campaigns targeting the EPA and Department of State, several of which identified themselves as organized by the groups "Energy Citizens" and "Energy Nation." These organization's websites are paid for by the American Petroleum Institute. The photos they post on social media almost exclusively show employees handing out shirts, hats, and water at fairs, bars, and conferences in exchange for signatures.^[https://www.flickr.com/photos/energycitizens/18274218500/in/photostream/] Though Energy Citizens and Energy Nation submitted slightly different comments as separate organizations, most of the individual signatories were the same on both sets of comments, and many were submitted twice in order to inflate the number of pro-API comments on the rule. Energy Citizens has attracted media attention for bussing in paid protesters and attendees at town halls,^[https://www.nytimes.com/2009/08/19/business/energy-environment/19climate.html] paying actors to pose as concerned citizens, and skirting Facebook's policy against deceptive advertising.^[https://www.propublica.org/article/how-big-oil-dodges-facebooks-new-ad-transparency-rules]

In a more complex example, Axcess Financial and other payday lending companies sponsored several campaigns targeting a regulation proposed by Consumer Financial Protection Bureau in 2016. First, Axcess Financial had storefront employees solicit comments from customers, which Axcess then uploaded to regulations.gov.  The customer comments suggest that they had not been told much about the rule, which limited interest rates, fees, and the number of times short-term loans could be compounded. Most customers wrote some version of "Do not close this store" or "I have been told that payday loans would not exist in my community if the government's proposed regulations went into effect."---a few even complained about exactly the issues that CFPB's regulation aimed to address. One customer wrote, "Although some of the fees are a bit high, it should be my choice whether to get a loan or not" (Access Financial Comment 91130). Another wrote, "I need to keep receiving my Check'n'Go loans so I can have the time to start paying them back in the next 1 1/2 to 2 years" (Axcess Financial Comment 91130), indicating that Check'n'Go (a subsidiary of Axcess Financial) was engaged in serial re-lending that put this customer deeper in debt. In their own comments, Axcess claimed that it did not do this kind of serial re-lending. To the extent that this campaign relied on deception and not the customer's genuine interests (even as the customers understood them), this would count as astroturf. Second, Axcess sponsored an effort to gather signatures at churches. Finally, Axcess and other payday loan companies uploaded supportive notes from community organizations to which they had given money. These people had no reason to comment except that they had received money from the regulated companies. 

As the American Petroleum Institute and Axcess Financial examples demonstrate, spotting astroturf in the wild can be difficult by design and involve complex judgment calls about the level of deception involved. However, the clear observable result is often a large number of comments advocating on behalf of narrow private interests. Large businesses or industry associations are the organizations with the resources and incentives to sponsor astroturf campaigns, and they do [@Lyon2005].

Not all campaigns on behalf of private interests fall decisively on the astroturf side of the spectrum. In a cover letter to a batch of comments opposing the regulation of glyphosate herbicides, major glyphosate manufacture, Monsanto, described how they collected the letters:

> "These letters were collected during the 2016 Farm Progress Show from US farmers, agriculture professionals, and general consumers who use glyphosate and value its benefits. We think it is important that these voices be heard as part of EPA's review of glyphosate." ([EPA-HQ-OPP-2009-0361-0891](https://www.regulations.gov/comment/EPA-HQ-OPP-2009-0361-0891))

Monsanto may have, like Energy Citizens, given out shirts in exchange for many of these signers, but the context and transparency make it more plausible that the signators genuinely opposed regulation on glyphosate. Similarly, Shell Oil sponsored a campaign to open the Arctic Outer Continental Shelf to oil and gas drilling and provided a template letter with a place to insert a company or group: 

> "On behalf of [enter company or constituents], I am writing to demonstrate my strong support of oil and gas development in the Arctic Outer Continental Shelf (OCS)...I support Shell's plan to explore its leases in the Chukchi Sea in 2015. The company has invested significant time and resources in the advancement of safe and prudent Arctic exploration. Shell should be allowed to realize the promise of the leases it purchased, and I encourage the BOEM to expeditiously approve its Exploration Plan."^[Some of Shell's supporters neglected to fill in the blanks in the template letter ([BSEE-2013-0011-0033](https://www.regulations.gov/comment/BSEE-2013-0011-0033)).]

Though Shell's private interests stood to benefit from the rule, the signers of this form letter were mostly companies and workers in the oil and gas sector. Several elected officials also used Shell's form letter (e.g. [BSEE-2013-0011-0033](https://www.regulations.gov/comment/BSEE-2013-0011-0033) and [BSEE-2013-0011-0094](https://www.regulations.gov/comment/BSEE-2013-0011-0094)). I found no evidence of deception or payments from Shell. These companies and workers plausibly had a genuine interest in Shell's access to offshore oil. The form letter's transparency about who stood to benefit further increases the plausibility that signers genuinely supported Shell's lobbying effort.


<!--
CITE STEVES ASTROTURF PAPER AND RELATED LIT IN THEORY SECTION
-->


<!-- ACTUAL METHODS SECTION-->

### Methods: Measuring Public Pressure and Political Information {#why-methods}

<!--
In section \@ref(why-theory), I argued that we should observe different patterns of public
participation depending on whether an organization launches a public pressure
campaign as an outside lobbying tactic ("going public"), as a reaction to such a campaign ("breaking a perceived consensus"), or
for reasons other than influencing policy ("credit claiming" or "going down fighting").-->

In this section, I develop methods to identify public pressure campaigns and measure the kinds of political information they create. These measures
capture similar statistics to questions posed by @Verba1987 [p. 9]: "How
much participation is there, what kind is it, and from what segments of
society does it come?"
Specifically, I assess the extent to which public comments are mobilized by pressure campaigns, which organizations are behind these campaigns, which campaigns are more successful in mobilizing, and which campaigns go unopposed. 


#### Identifying Organizations and Coalitions using Text Reuse {#reuse}

The primary unit of analysis is a lobbying coalition--a group of organizations advocating for the same policy changes in their comments on a draft rule. 
Advocacy organizations work together on campaigns. For example, "Save our Environment" submitted both sophisticated comments and collected signatures from hundreds of thousands of people on several rulemaking dockets. Save our Environment is a small nonprofit with a simple WordPress website almost entirely dedicated to mobilizing public comments. It is run by The Partnership Project, a coalition of 20 of the largest environmental advocacy organizations in the US, including the Sierra Club, Natural Resources Defense Council, Greenpeace, and the World Wildlife Fund, with the aim of "harnessing the power of the internet to increase public awareness and activism on today's most important environmental issues" (SaveOurEnvironment.org). Several Partnership Project members, including the Sierra Club, EarthJustice, and NRDC, also submitted technical comments and mobilized hundreds of thousands of their own supporters to comment separately on the same rules.  These lobbying and mobilizing activities are not independent campaigns. These organizations and the people they mobilize are a coalition.

To mobilize broader support, advocacy organizations often engage smaller organizations to mobilize their members as well. For example, in a campaign targeting fishing regulations, in addition to mobilizing thousands of individuals, the Pew Charitable Trusts mobilized members of the New York Underwater Photography Society and hundreds of restaurants that serve sustainable seafood. These smaller organizations did not identify themselves as part of Pew's campaign, but their letters used almost identical language.

<!-- step 1 portion from campaigns-->
Identifying which people and organizations belong to which coalition is thus a crucial first task for any study of public pressure campaigns.
To identify whether a pressure campaign mobilizes a given comment, I use several strategies.
 I first use textual similarity to identify
clusters of similar comments, reflecting formal and informal coalitions.
Comments with identical text indicate a coordinated campaign. 

To link individual comments and public pressure campaigns to the more sophisticated lobbying efforts that they support (if any), I identify the lobbying coalition(s) (if any) to which each comment belongs. Some individual commenters and organizations are unaffiliated with a broader lobbying coalition, but, as I show below, most people and organizations lobbying in broader coalitions.

Importantly, even
campaigns that achieve very low public response rates appear in these
data. Because campaigns aim to collect thousands of comments, it is
implausible that even the most unpopular position would achieve no
supportive responses. For example, @Potter2017 found Poultry Producers
averaging only 319 comments per campaign. While this is far from the
Sierra Club's average of 17,325 comments per campaign, it is also far
from zero.^[These numbers are from Potter's sample; the Sierra Club's average is even larger in my sample; see Table \@ref(tab:toporgs).] 


For each comment on a rulemaking docket^[Where a new presidential administration used the same docket number to solicit comments on a proposed rule that a previous administration used, I count these as separate rulemaking dockets. I do so because the second policy is usually reversing or going in the opposite direction as the policy on which the previous administration solicited comments. The same organizations often comment but with the opposition positions. Support becomes opposition and vice versa.], I identify the percent of words it shares with other comments using a 10-word (or
"10-gram") moving window function, looping over each
possible pair of texts to identify matches.^[For more about n-gram window functions and comparisons with related partial matching methods such as the Smith-Waterman algorithm, see @Casas2017 and @Judge-Lord2017.]
When actors sign onto the same comment, it is clear that they are
lobbying together. However, various businesses, advocacy groups, and
citizens often comment separately, even when they are aligned. Text-reuse (using the same ten-word phrases) captures this alignment. 

Figure \@ref(fig:percent-match) shows the percent of shared text for a sample of 50 comments on the Consumer Financial Protection Bureau's 2016 Rule regulating Payday Loans. Comments are arranged by the document identifier assigned by regulations.gov on both axes. 
The black on the diagonal indicates that each document has a perfect overlap with itself. Black squares off the diagonal indicate additional pairs of identical documents. For example, 100% of the words from Comment 95976 are part of some tengram that also appears in 95977 because the exact same comment was uploaded twice. 
The cluster of grey tiles indicates a coalition of commenters using some identical text.
Comments [91130](https://www.regulations.gov/document?D=CFPB-2016-0025-91130) through [91156](https://www.regulations.gov/document?D=CFPB-2016-0025-91154) are all partial or exact matches. All are part of a mass comment campaign by Access Financial. The percent of the identical text is lower than many mass-comment campaigns because these are hand-written comments, but the n-gram method still picks up overlap in the OCRed text in the header and footer. Tengrams that appear in 100 or more comments indicate a mass comment campaign. Some agencies use similar "de-duping" software [@Rinfret2021] and only provide a representative sample comment. In these cases, my linking method assumes that the example comment is representative, and I link these comments to others based on the text of the sample comment provided.

```{r percent-match, fig.show = "hold", out.width = "100%", fig.cap="Percent of Matching Text in a Sample of Public Comments"}

knitr::include_graphics("Figs/comment_percent_match_plot.png")  
```



#### Hand-coded Organizations and Coalitions

<!-- step 2 org type and coalitions-->
Second, I hand-code several samples of comments. One sample contains at least one comment from each cluster (coalition) of 100 or more similar comments. This census of form-letter comments allows me to make valid observations about public pressure campaigns across agencies and over time. A second sample includes nearly all comments on a random sample of rules.  A third sample includes nearly all comments on another random sample of rules, weighted by the number of comments they received. These last two samples allow me to make inferences about lobbying coalitions that do and do not use public pressure campaigns. 

Through an iterative process of hand-coding and computational methods, I then identify the organization submitting or responsible for mobilizing each comment (if any) in all three samples of comments. I identify the organizations responsible for over `r 40` million comments, including all organizations responsible for mobilizing 100 or more comments with repeated text--either identical text or partially unique texts that contain shared language. I then searched all remaining comment texts for
mentions of these organizations' names to complete missing information
on the mobilizing organization.  

I classify all organizations that appear in the hand-coded samples as businesses, industry associations, other nonprofits, governments, or individual elected officials and a range of sub-types within these broader categories. 



#### Classifying Public and Private Interests {#classify-public-private}

<!--TODO: NAIL DOWN MY NOMENCLATURE.-->
Classifying coalitions as primarily driven by private or public interest provides analytic leverage, but scholars have not converged on an approach to do so. @Potter2017 distinguishes "advocacy groups" from "industry groups." @Berry1999 calls these groups "citizen groups" and emphasizes conflict over cultural issues. Some public interest groups focus on conservative or progressive cultural issues, like religious education, immigration, or endangered species. Others are more focused on the public provision or protection of public goods such as national parks, consumer product safety standards, air quality, drinking water, and public safety. Types of membership organizations that are both broad and focused on material outcomes for their members (such as labor unions) are especially difficult to classify. @Potter2017 puts unions in the "Industry" category. I take a different approach based on the coalition with whom such groups lobby. If a union lobbies alongside businesses [see @Mildenberger2020], I classify this as a private interest-driven coalition. If a union lobbies with public interest groups on public health or safety issues, I classify this as a public interest group coalition.

<!-- step 3 public vs private coalitions-->
I code each coalition as primarily advancing an idea of the public interest or more narrow private interests. Public interest coalitions are almost always entirely nonprofits and governments, and private interest coalitions tend to be companies and industry associations. Still, some nonprofits lobby on behalf of companies, and some companies join forces with public interest groups. These can create "hard" cases. For example, a coalition of environmental groups mobilized recreational fishing businesses ([NOAA-NMFS-2012-0059-0185](https://www.regulations.gov/comment/NOAA-NMFS-2012-0059-0185)) and sustainable seafood restaurants to help push for stricter commercial fishing regulations. We know environmental groups mobilized the restaurants because they used a form letter from a nonprofit called the Gulf Restoration Network. I coded this as a public interest coalition. If, instead, the businesses had led this lobbying effort and enlisted a few nonprofits to help protect their business interests, I would have coded this as a private interest coalition. The vast majority of coalitions were much more straightforward to code as public or private.

<!-- DOES ASTROTURF SECTION BELONG HERE?-->

#### Coding Policy Positions

To assess whether organizations and their broader coalitions lobby in opposition to other interests or unopposed, I code the position of each organization on each proposed policy given the direction of change from the current policy. In Figure \@ref(fig:spatial-coding), $x_1$ is the current policy $x_2$ is the new proposed policy. Let $p_i$ be commenter $i$'s ideal policy. In spatial models, whether an organization supports or opposes a proposed policy change often depends on whether it is moving closer or further from its ideal policy. For example, if the ideal point of the commenter $i$ is the current policy ($p_i = x_1$) or close to it, they will oppose any change. If the ideal point of commenter $i$ is the new proposed policy ($p_i = x_1$) or closer to it, they likely support the proposal. While incompatible with an assumption of single-peaked preferences assumed by most models, commenters do occasionally oppose a policy change for moving insufficiently in their preferred direction (e.g., describing the proposal as "too little" or "insufficient" to gain their support). For example, if a commenter's prefers a more extreme change ($p_i = x_1$), they may oppose $x_2$ as "insufficient." This is likely a result of the repeated game nature of policymaking, where commenters believe that rejecting a small change in their preferred direction ($x_2$) now is likely to result in a more extreme change ($x_3$) later.



```{r spatial-coding, fig.cap= "Coding the Spatial Position of Comments on Proposed Policy Changes", fig.height=1}
library(latex2exp)

tibble(x = c(1,2,3,4,5,6, 7),
       position = c(1,2,3.5,4,5,NA, 7),
       code = c(1,2,3,4,5,NA, 6),
       label = c("Oppose","Oppose",  "Support","Support","Support","Support","Oppose")) %>%
 ggplot() +
    aes(y = 0, yend = 0,  x = x) +
  geom_point(shape = "|", aes(y = 2)) +
    geom_segment(x = 0, xend = 8, y = 2, yend = 2, arrow = arrow(ends = "both", type = "closed", length = unit(0.1, "cm"))) +
    geom_segment(aes(color = label), x = 0, xend = 8, arrow = arrow(ends = "both", type = "closed", length = unit(0.1, "cm"))) +
   geom_line(aes(color = label)) +
annotate("text", x=2, y=2.5, label=TeX("$x_1$"), parse=TRUE) +
annotate("text", x=2, y= .5, label=TeX("$p_i = x_1$"), parse=TRUE) +
annotate("text", x=4, y=2.5, label=TeX("$x_2$"), parse=TRUE) +
annotate("text", x=4, y= .5, label=TeX("$p_i = x_2$"), parse=TRUE) +
annotate("text", x=7, y=2.5, label=TeX("$x_3$"), parse=TRUE) +
annotate("text", x=7, y= .5, label=TeX("$p_i = x_3$"), parse=TRUE) +
geom_point(x = 2, y = 2) +
   geom_point(x = 4, y = 2) +
geom_point(x = 7, y = 2, shape = 21) +
  geom_point(x = 2, aes(color = label)) +
  geom_point(x = 4, aes(color = label[4])) +
geom_point(x = 7, aes(color = label)) +
  geom_point(x = 3, fill = "white", color = "white") + #, shape = 21) +
   geom_point(x = 6, fill = "white", color = "white") + #, shape = 21) +
  scale_x_continuous(limits = c(-1,8))+
  scale_y_continuous(limits = c(-2,3))+
  theme_void() +
labs(color = "",
     #title = "Spatial Positions of Public Comments",
     subtitle = TeX("Coding the Position (p) of Commenter $i$ on Proposed Policy $x_2$ Given Existing Policy $x_1$"),
     shape = "")
```

Having identified the coalition lobbying on each proposed rule and the position of each organization, I assign the position of each coalition as the position of the lead organization. For robustness, I also calculate the coalition's average position as the average position of its members. Coalition members usually have nearly identical positions, but occasionally, some take more extreme positions than others. For example, while all coalition members may have the same policy demands, some may ask for additional changes. I consider diverging interests to be one coalition only if the asks are entirely compatible with the position of organizations that did not ask for them. Incompatible policy demands indicate different coalitions.

<!-- step 4 success TODO-->

<!--
#### Measuring Intensity of Preferences

Finally, I develop computational methods to measure the intensity of preferences
expressed by those mobilized by public pressure campaigns. 
To measure the mobilizing success of each campaign, I measure
the scale and intensity of support and potential for the movement to grow. To measure
intensity, I examine the ratio of high-effort and low-effort comments.
To measure the potential to grow, I measure the number of comments mobilized
indirectly by the campaign (i.e., those that support a campaign but do
not include text provided by the campaign). The result is several new
measures of participation in bureaucratic policymaking.

-->

#### Differences with Prior Studies

<!-- not the same as Balla et al.-->
This approach is significantly different than that employed in previous studies of mass comment campaigns in at least two ways. First, my methods allow me to identify coalitions consisting of multiple organizations. Previous studies measure mass comment campaigns at the organization level. For example, @Balla2020 analyzes "1,049 mass comment campaigns that occurred during 22 EPA rulemakings"---an average of nearly 50 "campaigns" per rule. By "campaign," @Balla2020 mean an organization's campaign rather than a coalition's campaign. Especially on EPA rules, there are rarely more than two or three coalitions engaging in public pressure campaigns--one of the environmental advocacy groups and their allies, another of regulated industry groups and their allies. 

This is important because many comments nominally submitted by a small business, nonprofit, or membership organization are part of a campaign sponsored by a larger coalition led by industry associations or public interest groups. It would be inaccurate to credit a small organization with little capacity for organizing a campaign when they merely allowed their name and mailing list to be used by a larger group. For example, campaigns by industry associations are often officially submitted by much smaller nonprofit coalition partners. Using organizations as the unit of analysis means that observations are far from independent. An analysis that counts one coalition's campaign as 40 smaller "campaigns" with the same policy demands would count this one campaign as 40 observations. My methods allow me to measure levels of public pressure per organization *and* per coalition. 

The second major difference between my approach and previous research is that I do not compare sophisticated comments to mass comments. Rather, I *attribute* mass comments to organizations and coalitions that also submit sophisticated technical comments. By measuring comments per coalition, both through hand-coding and text reuse, I capture different levels of public pressure than we would see if we were to look only at comments per organization. 









<!-- TODO (some or all of this needs to go to the influence chapter)

### Measuring the Volume, Intensity, and Potential Contagion of Public Engagement

I measure variation in engagement in three ways that provide estimates of the three types of comments described above.

**Volume.** 
First, I count the total number of comments per organization, coalition, and rule. This captures the number of supporters who invested at least the minimal level of effort.
The process that generates mass comments involves several steps. First, a group must decide to
lobby. Then, a group must decide to mobilize public pressure. Finally, the resulting number of comments depends on the response to the
campaign. There may be many cases where groups may have had
success mobilizing but never reached the choice of whether to mobilize
or not. For example, relevant groups may have been unaware of the draft rule or lacked the resources to launch a campaign. Once the decision
to mobilize has been reached and made, the response to mobilizing is a
count process. I thus expect the count of comments across rules to
follow a zero-inflated negative binomial distribution.

**Effort.** 
I measure effort per comment by the number of words people
write, omitting any text longer than ten words that is not unique to that comment. When text is not unique, it is usually because a mobilizing organization provided it. For example, the Sierra Club mobilized more than 47,710
people to submit the same text on the delay of the methane
pollution rule, but 7,452 people also took the time to write a
personalized comment in addition to the text provided (see Figure \@ref(fig:sierra)). Organizations often encourage "personalized notes" because the number of additional words shows the individual was willing to exert additional effort.
 As @Verba1987 note, signing a form letter requires "some" effort, whereas writing an original letter to a government official requires "a lot." Adding a personal note to a form letter is somewhere in between. The longer the letter, the more effort required. 

While effort, as measured by the number of words people write, may be normally distributed, the low end of the observed distribution is truncated.
This is because we will not observe people who have low levels of passion for the issue; they either do not meet the threshold required to participate or opt
to write nothing more than the form letter. 

**Contagion.** Public pressure campaigns have wildly different results.
Some organizations submit a clean 10,000 copies of (signatures on) the same comment.^[For example, Americans For Prosperity's campaign on the XXXX rule. TODO]
Other campaigns "go viral"---inspiring a mess of further engagement where the
original messages are translated through social media posts and news
stories. To identify people who were plausibly mobilized indirectly by a
campaign, I count the number of people who use a similar distribution of
words to that of the form letter but fewer than ten words matching any
other comment. This is a regular count process. In the hand-coded sample, these people are coded as "individual" members of the coalition. Though perhaps officially unaffiliated, they were clearly inspired by the campaign indirectly.

> TODO: Align this with my terminology in the theory section.

-->