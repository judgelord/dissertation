---
# rmarkdown::render("02-pressure/pressure-appendix.Rmd")
title: "Public Pressure: Why Do Agencies (sometimes) Get So Much Mail?"
subtitle: "Appendix and Replication Code" 
author: "Devin Judge-Lord"
output:
    # pdf_document:
    #   toc: true
    #   keep_tex: true
    bookdown::html_document2:
      highlight: zenburn
      toc: true
      toc_float: true
      code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r global.options, include=FALSE}
# load defaults
source(here::here("code", "setup.R")) ### #

# overide defaults
knitr::opts_chunk$set(echo = TRUE, 
                      cache = TRUE,
                      fig.path = "../figs/")
```

<!-- 02-pressure-data.Rmd-->

# Data: A Census of Public Pressure Campaigns {#pressure-data}

```{r data-hand-code, cache=FALSE}
source(here::here("code", "setup.R")) ### #

# overide defaults
knitr::opts_chunk$set(echo = TRUE, 
                      cache = TRUE,
                      fig.path = "../figs/")
# hand coded 
load(here::here("data", "coalitions_coded.Rdata"))
load(here::here("data", "comments_coded.Rdata"))
load(here("data", "mass_raw.Rdata"))
```
```{r data-rules, cache=TRUE}
# rules metadata is raw from rulemaking repo API pull
load(here::here("data","rules.Rdata"))

# FIXME ID WHERE CODE for rules_metadata to rules is---I THINK THIS IS IT, MOVE TO RULEMAKING REPO
# for paper data, add vars to rules, then d is subset to 2005-2020
# rules %<>% mutate(open = !is.na(comment_start_date)|!is.na(comment_due_date)|number_of_comments_received > 0)
# min(rules$posted_date, na.rm = T)
# max(rules$posted_date, na.rm = T)

# inspect example - clean power plan 
# look <- rules %>% filter(docket_id == "EPA-HQ-OAR-2013-0602")


#FIXME move date var to rulemaking repo
# rules %<>%
#   mutate(comment_start_date = comment_start_date %>% as.Date(),
#          comment_due_date = comment_due_date %>% as.Date(),
#          date = coalesce(posted_date, comment_start_date, comment_due_date),
#          year = str_sub(date, 1,4),
#          year2 = str_remove(docket_id, ".*[A-Z]-") %>%
#            str_remove("-.*"),
#          year = coalesce(year, year2) %>% as.numeric()
#                       ) %>%
#   select(-year2) 

# SUBSET TO ONE OBS PER DOCUMENT 
rules %<>% ungroup() %>%
  group_by(id) %>% 
  slice_max(number_of_comments_received, with_ties = F) %>% 
  ungroup()

  
# SUBSET TO NEEDED VARS
rules %<>% 
  distinct(docket_title, posted_date, docket_id, docket_type, document_type, id, number_of_comments_received, open, date, year) %>% 
    filter(docket_title != "EPA Training Docket") %>%
    group_by(docket_id) %>%
  mutate(agency = docket_id %>% str_remove("-.*|_.*"),
         agency_id = agency,
         docket_comments = sum(number_of_comments_received), # comments on docket!
         open = sum(open, na.rm = T) > 0 # if any item on docket was open
) %>% 
  ungroup()


# trim rules to rulemaking dockets
d <- rules  %>% filter(year >2004, year <2021, 
                   docket_type == "Rulemaking",
                   document_type %in% c("Rule", "Proposed Rule"))
```

```{r data-comments, cache = TRUE}
# mass campaign 
# all comment data from ______
#if(!exists("comments_min")){
load(here("data", "comments_min.Rdata"))


#FIXME MOVE THIS CLEANING OF COMMENTS MIN TO RULEMAKING REPO
# comments_min %<>% 
#   group_by(id) %>%
#   slice_max(order_by = number_of_comments_received, n = 1) %>% 
#   ungroup()
#}

#save(comments_min, file =  here("data", "comments_min.Rdata"))


comments_min %<>% mutate(docket_id = id %>% str_remove("-[0-Z]*$"),
                         year = str_sub(date, 1,4),
                         #indicator for rulemaking
         rulemaking = docket_id %in% d$docket_id)

mass_coded <- comments_coded %>% filter(str_dct(comment_type, "mass"))

comments_min %<>% mutate (mass = number_of_comments_received > 99 | docket_id %in% mass_coded$docket_id | docket_id %in% mass_raw$docket_id )

comments_tally <- comments_min %>% 
  ungroup() %>% 
  group_by(year, mass, rulemaking) %>% 
  summarise(comments = sum(number_of_comments_received)) %>% 
  ungroup() %>% 
  mutate(mass = ifelse(mass, "Mass Comments", "Other Comments"))

# comments on rulemaking dockets
comments_rulemaking <- filter(comments_min, docket_id %in% d$docket_id)

# step 1
comments_mass <- comments_min %>% filter(number_of_comments_received > 99)

rules %<>% 
    mutate(campaign = docket_id %in% unique(comments_mass$docket_id),
           campaign = campaign | number_of_comments_received > 999)

rules_mass <- filter(rules,campaign)

# second step
comments_mass <- comments_min %>%
  filter(docket_id %in% rules_mass$docket_id | number_of_comments_received > 99)
#FIXME


# SUBSET TO ONE OBS PER DOCUMENT 
rules %<>% ungroup() %>%
  group_by(id) %>% 
  slice_max(number_of_comments_received, with_ties = F) %>% 
  ungroup()

# RULES DATA FOR PAPER 
#FIXME ME THIS SHOULD NOT BE IN THIS SCRIPT MOVE TO RULEMAKING REPO
#save(rules, file =  here("data", "rules.Rdata"))


# trim rules
d <- rules  %>% filter(year >2004, year <2021, 
                   docket_type == "Rulemaking",
                   document_type %in% c("Rule", "Proposed Rule"))

# remake mass
mass <- filter(d,campaign)


# DOCKETS 
topdockets <- slice_max(mass %>% ungroup() %>% distinct(docket_id, docket_comments), order_by =  docket_comments, n = 10) 

#save(topdockets, file =  here("data", "topdockets.Rdata"))

# AGENCIES 
topagencies1 <-  mass %>% 
  ungroup() %>% 
  count(agency, sort = T) %>%
  head(6) %>%
  pull(agency)



topagencies2 <-  d %>% 
  filter(open) %>% 
  ungroup() %>% 
  count(agency, sort = T) %>%
  head(6) %>%
  pull(agency)

topagencies = tibble(agency = unique(c(topagencies1, topagencies2) ))

topagencies  %<>% 
  mutate(Agency =
           case_when(
             agency == "CMS" ~ 'Medicare & Medicaid\n  Services (CMS)',
             agency == "FAA" ~ "Federal Aviation\n  Adminisration (FAA)",
             agency == 'EPA' ~'Environmental Protection\n  Agency (EPA)',
             agency == 'FCC' ~'Federal Communications\n  Commission (FCC)',
             agency == 'FDA'  ~'Food and Drug\n  Administration (FDA)',
             agency =='FNS' ~'Food and Nutrition\n  Service (FNS)', 
             agency =='FWS'  ~ 'U.S. Fish & Wildlife\n  Service (FWS)', 
             agency == 'IRS'~ 'Internal Revenue\n  Service (IRS)', 
             agency == "NOAA" ~'National Oceanic &\n  Atmospheric Admin. (NOAA)', 
             agency == 'USCG' ~ 'U.S. Coast Guard (USCG)'
           ))

#topagencies %<>% mutate(Agency = Agency %>%str_replace("\n", " ") %>% str_squish())

topagencies %>% kablebox()

save(topagencies, file =  here("data", "topagencies.Rdata"))
```




To examine the relationship between public pressure campaigns and lobbying success, I use an original dataset (introduced in \@ref(whymail-data)) that combines several data sources on U.S. federal agency rulemaking.

Up to 2020, these data include `r unique(rules$docket_id) %>% length()`
dockets,
`r rules %>% filter(docket_type == "Rulemaking") %>% distinct(docket_id) %>% nrow()`
rulemaking dockets. These dockets received
approximately `r sum(rules$number_of_comments_received, na.rm = T)`
comments.

The core data for this analysis are the texts of draft and final rules and public comments on these proposed rules published from 2005 to 2020. 
This includes all proposed rules from `r d %>% filter(number_of_comments_received >0) %>% pull(agency_id) %>% unique() %>% length()` agencies that were open for comment on regulations.gov between 2005 and 2020, received at least one comment from an organization, and saw a final agency action between 2005 and 2020.  These 
`r d %>% filter(docket_type == "Rulemaking") %>% distinct(docket_id) %>% nrow()`
rulemaking dockets received a total of
`r d %>% filter(docket_type == "Rulemaking") %>% pull(number_of_comments_received) %>% sum(na.rm = T)`
comments.

<!--TODO: This should be a short review and addition to the data section in whymail-->

I collected draft and final rule texts from federalregister.gov and comments submitted as attachments or by mail from regulations.gov. 
I retrieve comments submitted directly on regulations.gov and metadata on rules and comments (such as the dates that the proposed rule was open for comment and whether the agency identified the organization submitting the comment) from the regulations.gov API. 
I add additional metadata on rules (such as whether the rule was considered "significant") from the Unified Agenda published by the Office of Information and Regulatory Affairs (reginfo.gov). 

Where a new presidential administration used the same docket number to solicit comments on a proposed rule that a previous administration used, I count these as separate rulemaking dockets. I do so because the second policy usually reverses or goes in the opposite direction as the previous administration's policy solicited comments. The same organizations often comment but with the opposition positions. Support becomes opposition and vice versa.



## Dockets

```{r dockets}
rules %>% 
  filter(year > 2005, year < 2022, document_type != "Notice") %>%
  distinct(docket_id, year, document_type, docket_type) %>% 
  count(year, docket_type, document_type) %>%
  ggplot() +
  aes(x = year, y = n, fill = document_type) +
  geom_col(position = "dodge")+
  facet_wrap("docket_type", scales = "free_y") + 
  labs(fill = "",
       x = "") + 
  scale_x_continuous(breaks = seq(2006, 2020, by = 2)) +
  theme(axis.text.x = element_text(angle = 45,
                                   hjust = 1))


d %>% 
  distinct(docket_id, year, docket_type, agency_id) %>% 
  count(year, docket_type, agency_id) %>%
  group_by(docket_type, agency_id) %>% 
  mutate(agency_total = sum(n)) %>% 
  ungroup() %>%
  slice_max(order_by =  agency_total, n = 160) %>% 
  ggplot() +
  aes(x = year, y = n, fill = docket_type) +
  geom_col() +
  facet_wrap("agency_id", scales = "free_y")
```

## Proposed and Final Rules

```{r rules-by-campaign, fig.height= 3.5, fig.width = 5.5, fig.cap= "Proposed Rules Open for Comment on Regulations.gov 2005-2020"}
#rules-by-campaign
d %>% 
  ungroup() %>% 
  left_join(topagencies) %>% 
  filter(open, document_type  == "Proposed Rule") %>% 
  distinct(docket_id, year, campaign, Agency) %>%
  mutate(campaign = ifelse(campaign, "Targeted by a\nPressure Campaign",
                           "Not Targeted by a\nPressure Campaign"),
         Agency = Agency %>% replace_na("All other agencies")) %>% 
  ggplot(  ) +
  aes(x = year, fill = Agency) + 
  geom_bar() + 
  labs(y = "Number of Proposed Rules", 
       x = "",
       caption = "") + 
  facet_grid(campaign ~ ., scale = "free_y") +
  scale_x_continuous(breaks = seq(2006, 2020, by = 2)) +
  theme(axis.text.x = element_text(angle = 45,
                                   hjust = 1) ,
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank()) +
  scale_fill_viridis_d(option = "turbo")


d %>% 
  ungroup() %>% 
  left_join(topagencies) %>% 
  filter(open, document_type  == "Proposed Rule") %>% 
  distinct(docket_id, year, campaign, Agency) %>%
  mutate(campaign = ifelse(campaign, "Targeted by a\nPressure Campaign",
                           "Not Targeted by a\nPressure Campaign"),
         Agency = Agency %>% replace_na("All other agencies")) %>% 
  ggplot(  ) +
  aes(x = year, fill = Agency) + 
  geom_bar() + 
  labs(y = "Number of Proposed Rules", 
       x = "",
       caption = "") + 
  facet_wrap("campaign", scale = "free_y") +
  scale_x_continuous(breaks = seq(2006, 2020, by = 2)) +
  theme(axis.text.x = element_text(angle = 45,
                                   hjust = 1)) +
  scale_fill_viridis_d(option = "turbo")
```

#### Comments per rule

```{r comments-per-rule, fig.width=4.5, fig.height=3.5}
# comments per docket 
n <- d %>% ungroup() %>%  filter(open) %>% count(docket_comments, sort = T)

# proposed rules
pr <- d %>% 
  ungroup() %>%  
  filter(open, document_type == "Proposed Rule") %>% 
  distinct(docket_id, docket_comments, year, sort = T) %>% 
  arrange(docket_comments) %>% 
  mutate(x = as_factor(docket_id) %>% as.numeric(),
         ten = docket_comments %in% c(10),
         max = docket_comments == max(docket_comments)) 

# plot by number of comments 
p <- pr %>% 
  ggplot() +
  aes(x = x, 
      color = max | ten,
      y = docket_comments  + 1, 
      label = ifelse(max|ten, 
                     docket_id %>% str_c("\n (", pretty_num(docket_comments), " comments)"), 
                     NA)) +
  geom_point()+
  theme_minimal() + 
  theme(#axis.text.x = element_blank(),
        #panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        legend.position = "none") +
  scale_color_manual(values=c("black","red"), 
                     na.value= NA)  +
  scale_y_log10(labels = comma) +
  labs(x = "Proposed Rules\n(Arranged by Number of Comments)",
       y = "Comments Received")  
  
#1 overall
p +  geom_col(alpha = .02, position = "identity", 
           aes(color = ifelse(max | ten, max | ten, NA)))+#, color = "grey") +  +
  geom_text(hjust = 1.1,vjust = 0,check_overlap = T, size = 3)  +
    expand_limits(x = c(-100, nrow(pr)), 
                  y = c(10000000))

#2 by year 
pr %>% 
  ungroup() %>% 
  group_by(year) %>%
  mutate(x = row_number(),
         max = docket_comments == max(docket_comments)) %>%
  ggplot() +
  aes(x = x, 
      color = max | ten,
      y = docket_comments  + 1, 
      label = ifelse(max|ten, 
                      pretty_num(docket_comments), 
                     NA)) +
  geom_point()+
  geom_text(hjust = 1,vjust = 0,check_overlap = T, size =2)  +
  geom_col(alpha = .02, position = "identity", 
           aes(color = ifelse(max | ten, max | ten, NA)))+
  theme_minimal() + 
  theme(#axis.text.x = element_blank(),
        #panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        legend.position = "none") +
  scale_color_manual(values=c("black","red"), 
                     na.value= NA)  +
  scale_y_log10(labels = comma) +
  labs(x = "Proposed Rules\n(Arranged by Number of Comments",
       y = "Comments Received")   + 
  facet_wrap("year")+
    expand_limits(y = c(10000000),
                  x = c(-1000, 120)) +
  scale_x_continuous(breaks = c(1000))

#3 plot by year 
pr %>% 
  ggplot() +
  aes(x = year, 
      color = max,
      y = docket_comments,
      label = ifelse(max, 
                     docket_id %>% str_c("\n (", docket_comments, " comments)"), 
                     NA)) +
  geom_jitter(alpha = .5) +
  #geom_smooth() + 
  theme_minimal() + 
  theme(legend.position = "none") +
  scale_color_manual(values=c("black","red")) + 
  scale_y_log10(labels = comma) +
  labs(x = "",
       y = "Comments Received") + 
    expand_limits(y = c(0, 10000000)) +
  scale_x_continuous(breaks = seq(2006, 2020, by = 1)) +
  theme(axis.text.x = element_text(angle = 45,
                                   hjust = 1)) +   geom_text(hjust = 1.05, check_overlap = T, size = 3) 
```



Figure
\@ref(fig:comments-density) shows the relative number of comments received on a sample of rules matched to data from the White House Office of Information and Regulatory Affairs (OIRA), which reviews rules that it or the agency identify as "significant."  Under the Congressional Review Act, the OIRA Administrator then determines if each "significant" rule is "major" (in general, having an annual economic effect of over \$100,000,000), and thus subject to special provisions of that Act. Figure
\@ref(fig:comments-density) shows average number of comments "major" rules in red and "non-major" rules in blue. The top part of Figure \@ref(fig:comments-density) shows the distribution of proposed rules over the number of comments they received (the x-axis). The grey lines show the density and mean of the overall sample of rules reviewed by OIRA, including those that did not get a classification. The lower part of Figure \@ref(fig:comments-density) shows a scatterplot of the number of rules with a given number of comments. The key takeaway is that there is a great deal of diversity in commenting, with most rules receiving very few comments. Indeed, overall (including non-significant proposed rules), the majority (`r n$n[1]` of `r nrow(rules %>% filter(open))`) of proposed rules that are open for public comment received no comments.  Nearly 8,000 (37%)  of the 20,000 significant but non-major rules reviewed by OIRA received no comments. Even a quarter of "major" rules receive no comments. The modal number of comments for all types of rules, including major and economically significant rules, is less than ten. 

```{r comments-density, out.width = "99%", fig.cap = 'Comments Posted to Regulations.gov on "Significant" Rules Reviewed by OIRA 2005-2020'}

knitr::include_graphics(here::here("Figs", "major-comments-density-1.png"))
```


```{r comments-per-year}
d %>% 
  group_by(year) %>% 
  summarise(n = sum(number_of_comments_received)) %>%
  ggplot() +
  aes(x = year, y = n) +
  geom_col()

d %>% 
  group_by(docket_type, agency_id, year) %>% 
  summarise(n = sum(number_of_comments_received, na.rm = T)) %>% 
  group_by(docket_type, agency_id) %>% 
  mutate(agency_total = sum(n, na.rm = T)) %>% 
  ungroup() %>%
  slice_max(order_by =  agency_total, n = 160) %>% 
  ggplot() +
  aes(x = year, y = n, fill = docket_type) +
  geom_col() +
  facet_wrap("agency_id", scales = "free_y") #+  scale_y_log10()
```

#### Comments

```{r comments-mass, fig.height= 2.5, fig.width = 4.2, fig.cap= "Public Comments on Proposed Rules on Regulations.gov 2005-2020"}
n <- comments_tally$comments %>% sum() %>% {./1000000} %>% round(1)
  
#mass non-mass
comments_tally %>% 
  filter(year != 2021) %>% 
  ggplot(  ) +
  aes(x = as.numeric(year), y = comments, fill = mass) + 
  geom_col() + 
  labs(y = str_c("Comments Per Year\nN = ", n, " Million"), 
       x = "",
       fill = "",
       caption = "") + 
  theme_minimal() +
  scale_y_continuous(label = comma) + 
  scale_x_continuous(breaks = seq(2006, 2020, by = 2)) +
  theme(axis.text.x = element_text(angle = 45,
                                   hjust = 1.2,
                                   vjust =1.7) ,
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank()) +
  scale_fill_viridis_d()
```

Figure \@ref(fig:comment-from) shows the sources of incoming comments

```{r, comments-from, out.width = "69%", fig.cap = "Comments on Draft Rules Posted to Regulations.gov 2006-2018"}
knitr::include_graphics(here::here("Figs", "comments-from.pdf"))
```

#### Organizations

Organizations Mobilizing the Most Public Comments 2005-2020

```{r orgs-top}
#orgs-top
load(here("data", "org_comments.Rdata"))

org_comments %<>% mutate(org_name = organization %>% 
                           str_rm_all("\\(.*| Action Fund|^The |of the United States| - .*|:.*|Mass Comment Campaign of the |/.*| USA$|\\.com") %>%
                           str_squish() %>%
                           str_to_title() %>%
                           str_replace(".*Sierra.*", "Sierra Club")%>% 
                           str_replace(".*Nrdc.*|Natural Resources Defense Council.*", "NRDC")%>% 
                           str_replace(".*Center For Biological Diversity.*|Cneter For Biological Diversity", "Center For Biological Diversity")%>% 
                           str_replace(".*World Wildlife Fund.*|.WWF", "World Wildlife Fund")%>%
                           str_replace(".*Greenpeace.*", "Greenpeace")%>%
                           str_replace(".*Pew .*","Pew") %>% 
                           str_replace(".*Audubon.*", "Audubon") %>% 
                           str_replace(".*Credo.*", "Credo")%>%
                           str_replace(".*Defenders Of Wildlife.*", "Defenders Of Wildlife")%>%
                           str_replace(".*Friends Of The Earth.*", "Friends Of The Earth")%>%
                           str_replace(".*Earthjustice.*", "Earthjustice")%>%
                           str_replace(".*Defenders Of Wildlife.*", "Defenders Of Wildlife")%>%
                           str_replace(".*American Heart Association.*", "American Heart Association")%>%
                           str_replace(".*Audubon.*", "Audubon")%>%
                           str_replace(".*Wildlife Conservation Society.*", "Wildlife Conservation Society")%>%
                           str_replace(".*Oceana.*", "OCEANA")%>%
                                                      str_replace(".*Planned Parenthood.*", "Planned Parenthood")%>%

                           str_replace(".*Moveon.*|.*Move On.*", "credo")%>%
                           str_replace("Nat'l", "National")%>% 
                           str_replace(".*Ifaw.*", "INTERNATIONAL FUND FOR ANIMAL WELFARE")%>% 
                           str_replace(".*Humane Society.*|HSUS.*|.*\\bHSI\\b.*", "Humane Society")%>%
                           str_replace("Moms Rising|Momsrising|Mom's Rising|Momsrisiing", "Moms Rising")%>%
                           str_replace("Care 2|Care2", "Care2")%>%
                           str_replace("Preventobesity.*", "American Heart Association")%>%
                           str_replace("Axess.*|.*Axcess\\b.*", "AXCESS FINANCIAL")%>%
                           str_replace(".*American Petroleum Institute.*|.*\\bApi\\b.*", "American Petroleum Institute") %>%
                           str_replace(".*Consumer Energy Alliance.*", "Consumer Energy Alliance") %>%
                           str_squish() %>%
                           str_to_title(),
                         org_name = ifelse(nchar(org_name)<10, str_to_upper(org_name), org_name) )

# On non-rulemaking dockets 
#org_comments %>% filter(str_dct(organization, "Electric Cooperatives"))

save(org_comments, file =  here::here("data", "org_comments.Rdata"))


org_comments_summary <- org_comments %>% 
  group_by(org_name, docket_id) %>% 
  summarise(comments = sum(number_of_comments_received, na.rm = T) ) %>%
  ungroup() %>% 
  mutate(campaign = comments > 10) %>% 
  group_by(org_name) %>% 
  summarise(comments = sum(comments, na.rm = T),
            rules = n(),
            campaigns = sum(campaign)) %>% 
  ungroup() %>%
  mutate(percent = percent(campaigns/rules, accuracy = .1),
         average = round(comments/campaigns)) %>% 
  filter(!str_dct(org_name, "^NA$|unknown|individuals|n/a|^N$")) %>%
  arrange(-comments)  %>% 
  filter(comments > 100)

# need to do better
nrow(org_comments_summary)
org_comments_summary$comments %>% sum()

# org_comments_summary$org_name

#org_comments_summary$org_name[1:20]

org_comments_summary %>% 
  kablebox() 
#kable3(caption = "Organizations Mobilizing the Most Public Comments 2005-2020")

# Pretty up for presentation
org_comments_summary %<>%
  rename(Organization = org_name,
         Comments = comments,
         `Rules Lobbied On` = rules, 
         `Pressure Campaigns` = campaigns,
         `Percent (Campaigns /Rules)` = percent, 
         `Average per Campaign` = average)

#TODO IMPROVE PAPER SUMMARY WITH HAND CODED DATA 
# save(org_comments_summary, file =  here::here("data", "org_comments_summary.Rdata"))
```

##### The American Petroleum Institute

```{r}
org_comments %>% 
  filter(str_dct(organization, "American Petroleum Institute|\\bAPI\\b")) %>% group_by(docket_id) %>% 
  summarise(comments = sum(number_of_comments_received, na.rm = T)) %>% 
  arrange(-comments) %>% kablebox()
```


---


# Methods

## Clustering with text reuse

My theoretical approach requires that I *attribute* form letter comments to the organizations, campaigns, and broader coalitions that mobilized them. To do so, I identify comments that share text. I find that a 10-word phrase repeated across more than a few comments is always either text copied from the proposed policy or a form letter provided by a campaign. Thus, for the text of each comment, I first remove all 10-word phrases that appear in the proposed rule (including the preamble and call for comments). Then, I identify all comments that share ten-word phrases with 99 or more other comments. Finally, I collapse these form letter comments to one representative document for hand-coding. 

For each comment on a rulemaking docket, I identify the percent of words it shares with other comments using a 10-word (or
"10-gram") moving window function, looping over each
possible pair of texts to identify matches.^[For more about n-gram window functions and comparisons with related partial matching methods such as the Smith-Waterman algorithm, see @Casas2017 and @Judge-Lord2017.]
When actors sign onto the same comment, it is clear that they are
lobbying together. However, various businesses, advocacy groups, and
citizens often comment separately, even when they are aligned. Text-reuse (using the same ten-word phrases) captures this alignment. 

Figure \@ref(fig:percent-match) shows the percent of shared text for a sample of 50 comments on the Consumer Financial Protection Bureau's 2016 Rule regulating Payday Loans. Comments are arranged by the document identifier assigned by regulations.gov on both axes. 
The black tiles on the diagonal indicates that each document has a perfect overlap with itself. Black tiles off the diagonal indicate additional pairs of identical documents. For example, 100% of the words from Comment 95976 are part of some tengram that also appears in 95977 because the exact same comment was uploaded twice. 
The cluster of grey tiles indicates a coalition of commenters using some identical text.
Comments [91130](https://www.regulations.gov/document?D=CFPB-2016-0025-91130) through [91156](https://www.regulations.gov/document?D=CFPB-2016-0025-91154) are all partial or exact matches. All are part of a mass comment campaign by Access Financial. The percent of the identical text is lower than many mass-comment campaigns because these are hand-written comments, but the n-gram method still picks up overlap in the OCRed text in the header and footer. Tengrams that appear in 100 or more comments indicate a mass comment campaign. Some agencies use similar "de-duping" software [CITE] and only provide a representative sample comment. In these cases, my linking method assumes that the example comment is representative, and I link these comments to others based on the text of the sample comment provided.

```{r percent-match, fig.show = "hold", out.width = "100%", fig.cap="Percent of Matching Text in a Sample of Public Comments"}

knitr::include_graphics(here::here("Figs", "comment_percent_match_plot.png")  )
```


<!-- step 4 success TODO-->

##Measuring Intensity of Preferences

> TODO 

<!--
Finally, I develop computational methods to measure the intensity of preferences
expressed by those mobilized by public pressure campaigns. 
To measure the mobilizing success of each campaign, I measure
the scale and intensity of support and potential for the movement to grow. To measure
intensity, I examine the ratio of high-effort and low-effort comments.
To measure the potential to grow, I measure the number of comments mobilized
indirectly by the campaign (i.e., those that support a campaign but do
not include text provided by the campaign). The result is several new
measures of participation in bureaucratic policymaking.

-->

## Oganization types

Membership organization comments to look like this comment from the
NorthEast Hook Fisherman's Association:

> "We represent a small group of Commercial Fishermen with the Limited
> Access Handgear HA Permits, employing the use rod and reel, handlines
> or tub trawls to catch Cod, Haddock, and Pollock along with small
> quantities of other regulated and non-regulated marine fish.
> Historically and currently, our fishermen account for a small
> percentage of the groundfish landed in New England. However, the
> monetary gains obtained by the participants in this fishery are very
> important to us."
> ([NOAA-NMFS-2013-0050-0025](https://www.regulations.gov/comment/NOAA-NMFS-2013-0050-0025))

Similar groups, narrowly concerned about shrimp and halibut catch
limits, also commented on this rule on behalf of their members.

#### Membership Organizations

Membership organizations exist to serve their members interests. Unions
frequently lobbying rulemaking.

> "The American Federation of State, County and Municipal Employees
> ("AFSCME") represents 1.6 million state and local government, health
> care and child care workers and we write to express our strong support
> of the proposed rule"
> ([IRS-2016-0015-0133](%5Bhttps://www.regulations.gov/comment/IRS-2016-0015-0133))](<https://www.regulations.gov/comment/IRS-2016-0015-0133>)))

Some membership organizations join to form larger federations.

> "The Coalition on Human Needs, which represents more than 100 national
> member organizations and maintains a network of tens of thousands of
> individuals and groups nationwide, strongly supports the proposed
> rule"
> ([IRS-2016-0015-0131](%5Bhttps://www.regulations.gov/comment/IRS-2016-0015-0131))](<https://www.regulations.gov/comment/IRS-2016-0015-0131>)))

Membership organizations often claim to represent more than their
membership.

> "As a leading representative of the nation's 28 million small business
> owners, Small Business Majority is writing to comment on the U.S.
> Department of the Treasury's proposed rule on Inversions and Related
> Transactions."
> ([IRS-2016-0015-0127](%5Bhttps://www.regulations.gov/comment/IRS-2016-0015-0127))](<https://www.regulations.gov/comment/IRS-2016-0015-0127>)))

## Hand-coding 

```{r spatial-coding, fig.cap= "Coding the Spatial Position of Comments on Proposed Policy Changes", fig.height=4, fig.width=5.5}
library(latex2exp)

tibble(x = c(1,2,3,4,5,6, 7),
       position = c(1,2,3.5,4,5,NA, 7),
       code = c(1,2,3,4,5,NA, 6),
       label = c("Oppose","Oppose",  "Support","Support","Support","Support","Oppose")) %>%
 ggplot() +
    aes(y = 0, yend = 0,  x = x) +
  # Rule 
  geom_point(shape = "|", aes(y = 2)) +
    geom_segment(x = 0, xend = 8, y = 2, yend = 2, arrow = arrow(ends = "both", type = "closed", length = unit(0.1, "cm"))) +
  geom_segment(y = 2.5, yend = 2.5, x = 2.5, xend = 3.5, arrow = arrow(ends = "last", type = "closed",length = unit(0.1, "cm")), alpha = .2) +

annotate("text", x=2, y=2.5, label=TeX("$x_1$"), parse=TRUE) +
  annotate("text", x=4, y=2.5, label=TeX("$x_2$"), parse=TRUE) +
annotate("text", x=6, y=2.5, label=TeX("$x_3$"), parse=TRUE) +
  geom_point(x = 6, y = 2, shape = 21) +
    geom_point(x = 2, y = 2) +
   geom_point(x = 4, y = 2) +
    # plot-level
  geom_vline(xintercept = 2, alpha = .2, linetype = 2) + 
  geom_vline(xintercept = 4, alpha = .2) + 
  scale_x_continuous(limits = c(0,8))+
  scale_y_continuous(limits = c(-5.1,2.6))+
  scale_color_viridis_d(option = "plasma", begin = 0, end = .6, direction = -1) + 
  theme_void() +
labs(color = "",
     #title = "Spatial Positions of Public Comments",
     subtitle = TeX("Position of Commenter $i$ ($p_i$) on Proposed Policy $x_2$, Given Current Policy $x_1$"),
     shape = "") +
  # commenter  2
annotate("text", x=4, y= .5, label=TeX("Comment asks for no change from current policy, $p_i = x_1$:"), parse=TRUE) +
      geom_segment(aes(color = label), x = 0, xend = 8, arrow = arrow(ends = "both", type = "closed", length = unit(0.1, "cm"))) +
  geom_line(aes(color = label)) +
   geom_point(x = 2, aes(color = label)) +
        # 1
annotate("text", x=4, y= 1.5, label=TeX("Comment asks for policy to move in the opposite direction, $p_1 < x_1$:"), parse=TRUE) +
  geom_point(x = 1, y = 1, aes(color = label)) +
  geom_segment(aes(color = label), y = 1, yend = 1, x = 0, xend = 8, arrow = arrow(ends = "both", type = "closed", length = unit(0.1, "cm"))) +
   geom_line(aes(color = label), y = 1, yend = 1,) +
  #geom_point(x = 3, fill = "white", color = "white") + #, shape = 21) +
   #geom_point(x = 6, fill = "white", color = "white") + #, shape = 21) +
  # NA
annotate("text", x=4, y= -.5, label=TeX("Comment asks for policy much closer to current policy, $x_1 > p_i > x_2$:"), parse=TRUE) +
  geom_point(x = 2.5, y = -1, aes(color = label)) +
  geom_segment(aes(color = label), y = -1, yend = -1, x = 0, xend = 8, arrow = arrow(ends = "both", type = "closed", length = unit(0.1, "cm"))) +
   geom_line(aes(color = label), y = -1, yend = -1,) +
      # 3
annotate("text", x=4, y= -1.5, label=TeX("Comment asks for policy slightly closer to current policy, $x_1 > p_i > x_2$:"), parse=TRUE) +
  geom_point(x = 3.5, y = -2, aes(color = label[4])) +
  geom_segment(aes(color = label), y = -2, yend = -2, x = 0, xend = 8, arrow = arrow(ends = "both", type = "closed", length = unit(0.1, "cm"))) +
   geom_line(aes(color = label), y = -2, yend = -2,) +
    # 4
annotate("text", x=4, y= -2.5, label=TeX("Comment asks for the proposed policy as is, p_i = x_2$:"), parse=TRUE) +
  geom_point(x = 4, y = -3, aes(color = label[4])) +
  geom_segment(aes(color = label), y = -3, yend = -3, x = 0, xend = 8, arrow = arrow(ends = "both", type = "closed", length = unit(0.1, "cm"))) +
   geom_line(aes(color = label), y = -3, yend = -3,) +
      # 5
annotate("text", x=4, y= -3.5, label=TeX("Comment asks for more change than the proposed policy, $p_i > x_2$:"), parse=TRUE) +
  geom_point(x = 5, y = -4, aes(color = label[4])) +
  geom_segment(aes(color = label), y = -4, yend = -4, x = 0, xend = 8, arrow = arrow(ends = "both", type = "closed", length = unit(0.1, "cm"))) +
   geom_line(aes(color = label), y = -4, yend = -4,) +
        # 6
annotate("text", x=4, y= -4.5, label=TeX("Comment rejects policy as an insufficient change, $p_i > x_3$:"), parse=TRUE) +
  geom_segment(aes(color = label), y = -5, yend = -5, x = 0, xend = 8, arrow = arrow(ends = "both", type = "closed", length = unit(0.1, "cm"))) +
   geom_line(aes(color = label), y = -5, yend = -5,) +
  geom_point(x = 7, y = -5, aes(color = label)) 
```

## Classifying comments with text reuse

Figure \@ref(fig:comments-classified) shows all comments posted on
regulations.gov over time by whether they are exact or partial copies of
another comment on the same rule or not. I call comments that have
between 2 and 99 identical copies, "medium batch" because such comments
may reflect coordinated efforts among interest groups that do not
include a public pressure strategy that involves mobilizing ordinary
people. Even relatively unsuccessful public pressure campaigns yield far
more than 99 comments. "Mass comments" are comments with 100 or more
identical copies or comments that were uploaded in bulk batches of at
least 100. These were almost certainly mobilized by a public pressure
campaign. Figure \@ref(fig:comments-mass) shows that public pressure
campaigns mobilize the vast majority of comments.

```{r comments-classified, out.width = "49%", fig.cap = "Comments on Draft Rules Posted to Regulations.gov 2006-2018"}

knitr::include_graphics(here::here("Figs", "comments-mass-1.png"))
```

```{r toporgs, fig.cap = "Top mobilizers of comments posted to regulations.gov", fig.width = 7, eval=FALSE}
#FIXME Colors, replace NA with "other"
knitr::include_graphics(here::here("Figs", "toporgs.png"))
```

---

# Results

The hypotheses set out in [Chapter 2](https://judgelord.github.io/dissertation/whymail.html) are largely descriptive. 

```{hypothesis, meditated, echo = TRUE}
Most people engage in national policy processes as a result of organized public pressure campaigns.
```

> Yes, large majorities of both the hand-coded sample of comments and full dataset are form letters.

The hand-coded sample generally excludes individuals who are not clearly associated with a mass comment campaign. However, these excluded comments are a minority of the `r comments_min %>% filter(docket_id %in% comments_coded$docket_id) %>%  tally(number_of_comments_received)` comments on the hand-coded rules. Even without looking at the excluded comments (many of which may also be part of pressure campaigns), most commenters are part of organized campaigns. 

```{r}
comments_coded %>% 
  # split out mass comments submitted with org comments
  mutate(comment_type = ifelse(comment_type == "org" & comments > 99,
         "org;mass", 
         comment_type) %>% 
  str_split(";")) %>% 
  unnest(comment_type) %>% 
  mutate(comments = ifelse(comment_type == "org",
                           1, 
                           comments)) %>% 
  group_by(comment_type) %>% 
  tally(comments) %>% 
  kable3(caption = " ")
```

---

Comments that I have thus far attributed to mass comment campaigns are also a majority of the full data. In addition, many of the comments that I have yet to classify are also part of mass comment campaigns.

```{r}
# massive undercount of mass
#TODO include new, further collapsed data
comments_min %>% 
  mutate(mass = number_of_comments_received > 99) %>% 
  group_by(mass) %>% 
  tally(number_of_comments_received)%>% 
  kable3(caption = " ")
```

---


```{hypothesis, coalitions, echo = TRUE}
Public pressure campaigns are organized by *coalitions* that include groups that engage in sophisticated technical lobbying.
```

>Nearly all mass comments in the hand-coded rules were mobilized by a group that also engaged in sophisticated lobbying.

Organizations (if any) affilitated with different types of comments in the hand-coded data:

```{r}
comments_coded %>% 
  group_by(docket_id, coalition, coalition_comments, coalition_type) %>% 
  mutate(comment_type = comment_type %>% as.factor()) %>%
  count(comment_type) %>%
  ungroup() %>% 
  drop_na(comment_type) %>% 
  filter(!comment_type %in% c("NA", "coalition", "mass")) %>% 
  pivot_wider(names_from =  comment_type, values_from = n) %>%
  arrange(-coalition_comments) %>% 
  kable3(caption = " ")
```

---


```{hypothesis, public, echo = TRUE}
Public interest group coalitions mobilize *more often* than private interest group (e.g., business-led) coalitions.
```

> Yes, public interest coalitions use public pressure campaigns more often, both in the absolute number of campaigns and the share of lobbying efforts that involve a pressure campaign.

```{r campaign-type-frequency, fig.height=1.7, fig.width=4}
#campaign-type (inspired by potter)

coalitions_coded %>% 
  drop_na(coalition_type, Coalition_Position) %>% 
  filter(president != "Bush") %>% 
  mutate(epa = ifelse(agency == "EPA", "EPA", "All Other Agencies")) %>% 
  count(coalition_type, Coalition_Position, president) %>% 
  ggplot() +
  aes(y = n, 
      x = coalition_type, 
      fill = Coalition_Position) + 
  geom_col(position = "dodge") + 
  coord_flip() + 
  labs(x = "Coalition Type",
       y = "Number of Coalitions",
       fill = "") + 
  scale_y_continuous(labels = comma) + scale_fill_viridis_d(begin = 0, end = .7) + 
  facet_wrap("president") + 
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45))
```

```{r coalition-type-campaigns}
coalitions_coded %>%
  count(coalition_type, campaign_) %>% 
  drop_na(coalition_type) %>%
  pivot_wider(id_cols = coalition_type, names_from = campaign_, values_from = n) %>% 
  rename(`Mass Comment Campaign` = `TRUE`,
         `No Mass Comment Campaign` = `FALSE`) %>%
    rename(`Coalition Type` = coalition_type) %>% 
  kable3(caption = " ")
```

---


```{hypothesis, public-success, echo = TRUE}
Public interest group coalitions mobilize *more successfully* than private interest group (e.g., business-led) coalitions. 
```

> Yes, public interest coalitions mobilize far more comments and far more comments on average.

```{r campaign-type-scale, fig.height=1.7, fig.width=4}
#campaign-type-scale

coalitions_coded %>% 
  drop_na(coalition_type, Coalition_Position) %>% 
  filter(president != "Bush") %>% 
  mutate(epa = ifelse(agency == "EPA", "EPA", "All Other Agencies")) %>% 
  ggplot() +
  aes(y = coalition_comments/1000000, 
      x = coalition_type, 
      fill = Coalition_Position) + 
  geom_col(position = "dodge") + 
  coord_flip() + 
  labs(x = "Coalition Type",
       y = "Number of Comments (Millions)",
       fill = "") + 
  scale_y_continuous(labels = comma) + scale_fill_viridis_d(begin = 0, end = .7) + 
  facet_wrap("president") + 
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45))
```

```{r coalition_type_totals}
coalitions_coded %>% group_by(coalition_type) %>% 
  summarise(`Total Comments` = sum(coalition_comments),
            `Average Comments` = mean(comments) %>% round) %>% drop_na(coalition_type) %>%
  rename(`Coalition Type` = coalition_type) %>% 
kable3(caption = " ")
```

---


```{hypothesis, resources, echo = TRUE}
Public pressure campaigns targeting national policy are most often run by large national policy advocacy organizations.
```

> Yes.

```{hypothesis, disrupt, echo = TRUE}
If narrow private interest groups (e.g., businesses) launch public pressure campaigns, it is a response to an opposing campaign. 
```

> TBD: In these data (high salience rules), almost all coalitions are opposed. 

```{r}
coalitions_coded %>% 
  count(coalition_type, coalition_unopposed) %>% drop_na(coalition_type) %>% 
  kable3(caption = " ")
```


## Partisanship 


```{r support, fig.height=2.1, fig.width=4.3}
# support
p <- comments_coded %>% 
  drop_na(Position) %>% 
  mutate(year = date %>% 
           str_sub(1,4) %>% 
           as.numeric() ) %>% 
  mutate(president2 = case_when(
    year < 2013 ~ "Obama 1",
    year >2012 & year < 2017 ~ "Obama 2", year > 2016 ~ "Trump"
  )) %>% 
  group_by(year, Position, president2) %>% 
  summarise(comments = sum(comments)) %>% 
  filter(president2 != "Bush",
         year > 2008, year < 2021) %>%
  ggplot() +
  aes(x = year, 
      y = comments,
      fill = Position) + 
  theme_minimal() + 
  geom_col(position = "dodge")  + 
  scale_fill_viridis_d(begin = 0, end = .7) + 
  scale_x_continuous(breaks = seq(2010, 2020, by = 1)) +
  scale_y_continuous(labels = comma) + 
  theme(panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        axis.text.x = element_text(angle = 45,
                                   hjust = 1)) + 
    labs(x = "", 
         y = "Comments per Year",
         fill = "")

p + facet_wrap("president2", scales = "free_x")

p 
```