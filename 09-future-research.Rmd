## Future research {#future}

### Interest Group Representation

To the extent that public pressure campaigns shape agency decisions, a broader research program is needed to investigate who exactly these campaigns mobilize and represent. My analysis of second-order representation in comments raising environmental justice concerns shows that the large national advocacy groups that dominate public pressure organizing often claim to represent groups that tend to be excluded from policymaking. Sometimes this is done in collaboration with disenfranchised groups, and sometimes it is not. Much more research is needed to assess the quality of second-order representation in coalition lobbying. 

Unlike classic pluralist assumptions about how interest group representation operates---where an organization represents a defined class or membership---pressure campaigns mobilize an open-ended list of potential supporters that theoretically includes most of the public. Indeed, a key piece of political information that campaigns generate is signals about the potential for a movement to grow and further expand the scope of conflict. For example, a large public pressure campaign may signal impending letter-writing campaigns targeting members of Congress. Pressure campaigns are also associated with protests and increased media attention.  Expanding the scope of conflict often comes with a threat to further expand the scope of conflict.  Policymakers know that their policy decisions shape the political conflicts in which they are embedded. 

### Networks and Lobbying Coalitions

In Chapter \@ref(whymail), I show that most public pressure campaigns are coordinated by a relatively small number of organizations that repeatedly lobby both with and without pressure campaigns. Lobbying coalitions range from two organizations to hundreds.
These data are flush with opportunities for network analysis using organizations as nodes and coalitions as edges.  Simple measures like node centrality may tell us a great deal about the structure of advocacy coalitions and how they change over time and across policy areas. Because every comment is linked to a specific policy and has a timestamp, there may be opportunities to study the evolution of networks over time. For example, do small, local, or specialized groups comment first and then recruit more general national advocacy group allies to amplify their message?  Or do large national advocacy organizations more often recruit smaller groups to grow their coalition's size and diversity?  One could observe trends over time both within a given comment period on one proposed rule and over decades across rules.

Anecdotes from my data pose questions for network research.
For example, large environmental organizations increasingly use environmental justice rhetoric; is this related to the number of ties they have to frontline activist groups? If so, did the ties or the rhetoric come first? By observing the same organizations lobbying in different coalitions over time, these data allow time-variant network analysis. Another example: environmental groups often supported the Obama administration's policies but occasionally opposed them. When they did, one of their key progressive allies in mobilizing efforts, Organizing For America (formerly President Obama's campaign organization, Obama For America), was conspicuously absent from the coalition. These data allow network analysis with lobbying coalition and policy-level covariates (e.g., supporting or opposing a given president's agenda). 

Organizations' use of different social aggregation technologies offers one specific opportunity for studying issue networks and lobbying networks. Public comments are often generated through third-party nonprofit advocacy platforms that usually serve either the political left (e.g., Care2, MandateMedia, DemandProgress, and Daily Kos) or political right (Americans for Prosperity). Additionally, there are for-profit petition platforms like change.org and companies that serve a variety of political and corporate causes (e.g., SalesForce and VoterVoice).  VoterVoice, for example, is a product of the government relations firm FiscalNote. FiscalNote specializes in lobbying on legislation, while VoterVoice specializes in "grassroots" advocacy services. VoterVoice states on their webpage:

> Founded in 2000, VoterVoice, our flagship advocacy solution, was designed to fill a gap in the market for a robust tool that would provide high value to users and keep innovating to meet the needs of modern digital communication. As the market leader, we continue to set the trends and prioritize the features that drive results for you.
Our vision remains simple: Deliver a seamless, powerful platform that lets you inspire advocates to action, so you can impact policy through actionable insights.
We strive every day to honor our commitment to the 2,400 associations, nonprofits, and corporations who rely on us." [@VoterVoice].


Relatedly, there are a large number of front groups for corporate lobbying campaigns, many of which are run by government relations firms under multi-year contracts from industry associations. For example,  I discuss the Energy Citizens and Energy Nation front groups for the American Petroleum Institute in \@ref(why-data). 

The constellation of nonprofit and for-profit advocacy tools that different organizations use provides a distinct layer of nodes and edges (in addition to the policies on which they are lobbying and the coalitions they lobby with). For example, many of the national progressive advocacy organizations seemed to pay less attention to some issues  (e.g., immigration) than others (e.g., climate change). The result was that immigrant advocates more often generated comments through change.org petitions rather than the nonprofit social aggregators that other progressive causes tended to use. These patterns of lobbying, mobilizing, and organizing behavior offer rich information about evolving issue structures and political alliances. 

### Public Pressure and Congressional Oversight

Members of Congress engage in agency policymaking in a variety of ways, only some of which are systematically captured in the data used to estimate the relationship between public pressure and legislator behavior in Section \@ref(influence-results). Comparing the dataset on congressional behavior that I have assembled through this dissertation to other data on congressional engagement in bureaucratic policymaking could yield insights about both legislative behavior and bureaucratic policymaking. For example, when members of Congress submit official "comments" on an agency rule or forward their constituent comments (often, legislators do both), they are almost certainly logged in the public record on regulations.gov. However, if legislators do not want their communications to appear in the public record, they may contact a different office (for example, the secretary's office rather than the program office issuing the rule). @Judge-Lord2018APSA find systematic variation in how members contact agencies and sub-bureaus, and @Powell2020 show that legislators often advocate on behalf of campaign donors. 


### Endogeneity

Assessing the impact of pressure campaigns is difficult because an organization's decision is endogenous to their perceived probability of success and correlated with other factors we care about (for example, whether the organization is a business or nonprofit).
Future research might disentangle different motivations for launching campaigns by measuring the amount of effort that organizations put into sophisticated lobbying. While different types of organizations have different capacities for sophisticated lobbying (e.g., the ability to hire lawyers and scientists), organizations also vary in the amount of effort they put into such lobbying. <!--cite finreg-->
Small investments in sophisticated lobbying relative to the scale of public organizing may indicate that the organization was mobilizing supporters for reasons other than affecting policy. (It could also indicate that the organization perceives the policy fight to be more political than technical). This approach does not fully address the problem that lobbying behavior depends on the expected probability of success, but it may at least capture the extreme cases where organizations mobilize primarily for reasons other than influencing the policy at hand. 

### Mechanisms of Influence

As theorized in \@ref(why-theory) and \@ref(influence-theory), the causal process potentially linking public pressure and policy decisions depends on how institutions filter and process the information they receive. When agencies receive large amounts of public comments, they often hire private-sector consultants to process and summarize public input. The instructions that agencies give to their consultants and the summaries that consultants produce offer a rich and systematic way to study the processing of political information. Researchers should be able to obtain these through Freedom of Information Act (FOIA) requests. 

Another way to study how agencies process comments and the political information they contain would be to study the information that agencies (or their consultants) do and do not record about comments. For example, when a commenter fails to identify their name or organization when submitting comments, agencies occasionally fill this information in with "Unknown." Agencies do this for mass comments as well, tagging a comment "Mass comment - organization unknown." Comments that my methods identified as nearly identical were sometimes tagged as mass comments and sometimes not. This variation may offer a way to observe the extent to which an agency is processing---and thus capable of reacting to---political information. For example, recall the astroturf campaigns sponsored by the American Petroleum Institute (API) in \@ref(astroturf). While all of these form letters resembled API press releases, some were identified as being associated with API-sponsored campaigns while others were not, suggesting that the agency may have been aware that API was mobilizing in some cases and not in others. This variation may provide leverage to assess whether public pressure campaigns are more likely to increase lobbying success (e.g., of API) if the agency explicitly associates them with an organization or coalition. 

### Methods of Measuring Policy Influence

Chapters \@ref(influence) and \@ref(ej) offer three methods to assess the impact of public pressure on bureaucratic policymaking: large-scale hand-coded lobbying success, detailed case studies, and computational methods that measure change between draft and final policy documents. Each of these methods could be improved upon. 

The measures of lobbying success, position, and opposition used in Chapter \@ref(influence) do not distinguish different dimensions of conflict within each policy. For example, tribal governments and advocacy organizations often lobby in coalitions with environmental groups against extractive industries on public lands but raise distinct objections related to tribal sovereignty. While I distinguish tribal sovereignty interests as a distinct and overlapping lobbying coalition, I do not distinguish which of their multiple interests are opposed. My data currently reduce support and opposition to a single spatial dimension, meaning that all reasons for supporting a policy are considered to be "opposed" if another coalition opposes the rule (even if for a different reason). This coding could be refined by disaggregating policies into multiple issues (dimensions of conflict) and assessing coalition lobbying dynamics on each dimension of conflict.

While I do not explicitly engage the vast literature on "process tracing" methods in the qualitative parts of Chapter \@ref(ej), these methods informed my approach. Because notice-and-comment rulemaking under the Administrative Procedure Act is an unusually structured policy process, it is an excellent candidate for these methods. Compared to almost any other political phenomenon, rulemaking has clear inputs, outputs, and critical junctures that can be aligned and compared across multiple observations. Cases where rules span multiple administrations (like the Mercury rule discussed in \@ref(ej)) and rules that reverse rules published under previous administrations may be especially good candidates for process tracing. While atypical and inconvenient for the present research, the fact that the Trump administration published new rules on many of the same rulemaking dockets on which the Obama administration published rules presents clear criteria for selecting rules that are obviously related to previous rules. 

There are opportunities to improve computational measures of policy change and lobbying success [@Carpenter2020]. Using the same methods that I use to group comments into coalitions (outlined in \@ref(why-methods)) and assess change in how policy documents discussed environmental justice (\@ref(ej-methods)), we can systematically capture which words (and thus the percent of words) changed between draft and final policy text. The challenge is linking these changes to commenter demands, which may also be done through my text reuse methods or a combination of other text similarity measures [@Rashin2017].

We may also combine hand-coding and computational text analysis tools. I will focus on two of the many opportunities on this front: using hand-coded data as training data for machine learning tools and using computational methods to analyze hand-selected parts of the text. First, hand-coded lobbying coalitions provide a corpus of related texts that may be used to train classifiers to automatically detect lobbying coalitions. Trained classifiers may perform much better than unsupervised clustering methods (models not trained on coded data). 

Second, human coders are particularly adept at identifying and classifying important parts of texts. For example, humans can easily identify sentences where commenters suggest policy changes.  Once identified, computational tools that rely on similar words and phrases to link comments with changes in policy text may provide much better measures of lobbying success than they would if using the entire text of a comment. Additionally, hand-coded metadata, such as the pro/con position of a comment, may help avoid challenges that natural language processing tools have with sematic features like negation. For example, we will be much more confident in whether an organization is asking an agency to make a change or not to make a change. Finally, hand-coded lobbying coalitions can allow inferences about lobbying success to leverage larger pools of texts that we know are asking for similar policy changes. 
